from flask import Flask, render_template, request, send_file, jsonify, session, redirect, url_for, make_response
from werkzeug.utils import secure_filename
from flask_limiter import Limiter
from flask_limiter.util import get_remote_address
import pandas as pd
from io import BytesIO
from datetime import datetime, date, time as dt_time, timedelta, timezone
import calendar
import os
import json
from collections import defaultdict, OrderedDict
import numpy as np
import time
import secrets
from functools import wraps

app = Flask(__name__)
app.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024  # 16MB
app.secret_key = os.environ.get('SECRET_KEY', 'playauto-secret-key-2024')

# ==================== Rate Limiting ì„¤ì • ====================
limiter = Limiter(
    get_remote_address,
    app=app,
    default_limits=["200 per minute"],
    storage_uri="memory://"
)

# ==================== Supabase ì„¤ì • (ì„ íƒì ) ====================
SUPABASE_URL = os.environ.get('SUPABASE_URL', '')
SUPABASE_KEY = os.environ.get('SUPABASE_KEY', '')

supabase = None
DB_CONNECTED = False

# Supabase ì—°ê²° ì‹œë„ (ì‹¤íŒ¨í•´ë„ ì•±ì€ ì •ìƒ ì‘ë™)
if SUPABASE_URL and SUPABASE_KEY:
    try:
        from supabase import create_client, Client
        supabase = create_client(SUPABASE_URL, SUPABASE_KEY)
        # ì—°ê²° í…ŒìŠ¤íŠ¸
        supabase.table('workers').select('id').limit(1).execute()
        DB_CONNECTED = True
        print("âœ… Supabase ì—°ê²° ì„±ê³µ - DB ëª¨ë“œë¡œ ì‘ë™")
    except Exception as e:
        print(f"âš ï¸  Supabase ì—°ê²° ì‹¤íŒ¨ ({e}) - JSON íŒŒì¼ ëª¨ë“œë¡œ ì‘ë™")
        supabase = None
        DB_CONNECTED = False
else:
    print("â„¹ï¸  Supabase í™˜ê²½ë³€ìˆ˜ ì—†ìŒ - JSON íŒŒì¼ ëª¨ë“œë¡œ ì‘ë™")

# ==================== ë¡œê·¸ì¸ ì„¤ì • ====================
LOGIN_ID = os.environ.get('LOGIN_ID', 'abc')
LOGIN_PW = os.environ.get('LOGIN_PW', '1234')
ADMIN_ID = os.environ.get('ADMIN_ID', LOGIN_ID)
ADMIN_PW = os.environ.get('ADMIN_PW', LOGIN_PW)

# [ìˆ˜ì •ë¨] í•œêµ­ ì‹œê°„(KST) ê¸°ì¤€ ì˜¤ëŠ˜ ë‚ ì§œ êµ¬í•˜ê¸°
def get_kst_today():
    return datetime.now(timezone(timedelta(hours=9))).date()

def login_required(f):
    """ë¡œê·¸ì¸ í•„ìˆ˜ ë°ì½”ë ˆì´í„°"""
    @wraps(f)
    def decorated_function(*args, **kwargs):
        if not session.get('logged_in'):
            return redirect(url_for('login'))
        return f(*args, **kwargs)
    return decorated_function

def admin_required(f):
    """ê´€ë¦¬ì ì „ìš© ë°ì½”ë ˆì´í„°"""
    @wraps(f)
    def decorated_function(*args, **kwargs):
        if not session.get('logged_in'):
            return redirect(url_for('login'))
        if session.get('user_role') != 'admin':
            return jsonify({'error': 'ê´€ë¦¬ì ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤'}), 403
        return f(*args, **kwargs)
    return decorated_function

ALLOWED_EXTENSIONS = {'xls', 'xlsx'}
SETTINGS_FILE = 'playauto_settings_v4.json'
MARGIN_DATA_FILE = 'margin_data.json'

# ì„ì‹œ ì €ì¥ì†Œ (ì„¸ì…˜ë³„ ë¶„ë¥˜ ê²°ê³¼)
TEMP_RESULTS = {}

def cleanup_old_sessions(max_age_hours=1):
    """ì˜¤ë˜ëœ ì„¸ì…˜ ìë™ ì •ë¦¬ (ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€)"""
    now = datetime.now()
    expired_sessions = []
    for session_id, data in TEMP_RESULTS.items():
        created_at = data.get('created_at')
        if created_at:
            if isinstance(created_at, datetime):
                age_seconds = (now - created_at).total_seconds()
            else:
                age_seconds = time.time() - created_at
            if age_seconds > max_age_hours * 3600:
                expired_sessions.append(session_id)
    for session_id in expired_sessions:
        del TEMP_RESULTS[session_id]
    if expired_sessions:
        print(f"ğŸ§¹ ë§Œë£Œëœ ì„¸ì…˜ {len(expired_sessions)}ê°œ ì •ë¦¬ë¨")

# ==================== íŒë§¤ì²˜ë³„ ìˆ˜ìˆ˜ë£Œìœ¨ ====================
PLATFORM_FEES = {
    'ì¿ íŒ¡': 0.12,           # 12%
    'ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´': 0.067,   # 6.7%
    '11ë²ˆê°€': 0.18,         # 18%
    'Gë§ˆì¼“': 0.15,          # 15%
    'ì˜¥ì…˜': 0.15,           # 15%
    'ìœ„ë©”í”„': 0.15,         # 15%
    'í‹°ëª¬': 0.15,           # 15%
    'í† ìŠ¤ì‡¼í•‘': 0.12,       # 12%
    'ê¸°íƒ€': 0.10            # 10%
}

# ==================== ì„¤ì • ê´€ë¦¬ (ê¸°ì¡´ ë°©ì‹ ìœ ì§€) ====================

def load_settings_from_file():
    """JSON íŒŒì¼ì—ì„œ ì„¤ì • ë¡œë“œ"""
    if os.path.exists(SETTINGS_FILE):
        with open(SETTINGS_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
    return None

def save_settings_to_file(settings):
    """JSON íŒŒì¼ì— ì„¤ì • ì €ì¥"""
    with open(SETTINGS_FILE, 'w', encoding='utf-8') as f:
        json.dump(settings, f, ensure_ascii=False, indent=2)

def load_settings():
    """ì„¤ì • ë¡œë“œ (ê¸°ì¡´ ë°©ì‹ ìœ ì§€)"""
    return load_settings_from_file()

def save_settings(settings):
    """ì„¤ì • ì €ì¥ (ê¸°ì¡´ ë°©ì‹ ìœ ì§€)"""
    save_settings_to_file(settings)

# ì´ˆê¸° ì„¤ì • ë¡œë“œ
try:
    CURRENT_SETTINGS = load_settings()
    if not CURRENT_SETTINGS:
        print("âš ï¸  ê²½ê³ : playauto_settings_v4.json íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")
        CURRENT_SETTINGS = {
            "work_order": ["ì†¡ê³¼ì¥ë‹˜", "ì˜ì¬ì”¨", "ê°•ë¯¼ì”¨", "ë¶€ëª¨ë‹˜", "í•©ë°°ì†¡", "ë³µìˆ˜ì£¼ë¬¸", "ë¶„ë¥˜ì‹¤íŒ¨"],
            "work_config": {
                "ì†¡ê³¼ì¥ë‹˜": {"type": "product_specific", "products": [], "enabled": True},
                "ì˜ì¬ì”¨": {"type": "product_specific", "products": [], "enabled": True},
                "ê°•ë¯¼ì”¨": {"type": "product_specific", "products": [], "enabled": True},
                "ë¶€ëª¨ë‹˜": {"type": "product_specific", "products": [], "enabled": True},
                "í•©ë°°ì†¡": {"type": "mixed_products", "products": [], "enabled": True},
                "ë³µìˆ˜ì£¼ë¬¸": {"type": "multiple_quantity", "products": [], "enabled": True},
                "ë¶„ë¥˜ì‹¤íŒ¨": {"type": "failed", "products": [], "enabled": True}
            },
            "quantity_threshold": 2,
            "auto_learn": True,
            "min_confidence": 1.0
        }
    else:
        print(f"âœ… ì„¤ì • ë¡œë“œ ì™„ë£Œ: {len(CURRENT_SETTINGS.get('work_order', []))}ëª…ì˜ ë‹´ë‹¹ì")
except Exception as e:
    print(f"âŒ ì„¤ì • ë¡œë“œ ì˜¤ë¥˜: {e}")
    CURRENT_SETTINGS = None

def allowed_file(filename):
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS

# ==================== ì›ê°€ ë§ˆì§„í‘œ (ê¸°ì¡´ ë°©ì‹ ìœ ì§€) ====================

MARGIN_DATA = []

def load_margin_data():
    """ì›ê°€ ë§ˆì§„í‘œ ë°ì´í„° ë¡œë“œ (JSON íŒŒì¼)"""
    global MARGIN_DATA
    if os.path.exists(MARGIN_DATA_FILE):
        with open(MARGIN_DATA_FILE, 'r', encoding='utf-8') as f:
            MARGIN_DATA = json.load(f)
        print(f"âœ… ì›ê°€ ë§ˆì§„í‘œ ë¡œë“œ ì™„ë£Œ: {len(MARGIN_DATA)}ê°œ ìƒí’ˆ")
    else:
        print("âš ï¸  ê²½ê³ : margin_data.json íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")

def save_margin_data():
    """ì›ê°€ ë§ˆì§„í‘œ JSON íŒŒì¼ ì €ì¥"""
    with open(MARGIN_DATA_FILE, 'w', encoding='utf-8') as f:
        json.dump(MARGIN_DATA, f, ensure_ascii=False, indent=2)

# ì‹œì‘ ì‹œ ë¡œë“œ
load_margin_data()

# ==================== ì›ê°€ ë§¤ì¹­ ë° ìˆ˜ìˆ˜ë£Œ ê³„ì‚° í•¨ìˆ˜ ====================

def find_matching_cost(product_name):
    """ìƒí’ˆëª…ìœ¼ë¡œ ì›ê°€ ì°¾ê¸° (Fuzzy Matching)"""
    if not product_name or not MARGIN_DATA:
        return 0

    product_name = str(product_name).strip()

    # 1. ì •í™•íˆ ì¼ì¹˜
    for item in MARGIN_DATA:
        if item.get('ìƒí’ˆëª…') == product_name:
            return item.get('ì¸ìƒí›„_ì´_ì›ê°€') or item.get('ì¸ìƒí›„ ì´ ì›ê°€', 0)

    # 2. í¬í•¨ ê²€ìƒ‰ (ê¸´ ê²ƒ ìš°ì„ )
    matches = []
    for item in MARGIN_DATA:
        margin_name = item.get('ìƒí’ˆëª…', '')
        if margin_name in product_name or product_name in margin_name:
            matches.append((item, len(margin_name)))

    if matches:
        matches.sort(key=lambda x: x[1], reverse=True)
        return matches[0][0].get('ì¸ìƒí›„_ì´_ì›ê°€') or matches[0][0].get('ì¸ìƒí›„ ì´ ì›ê°€', 0)

    # 3. í•µì‹¬ ë‹¨ì–´ ë§¤ì¹­ (ê³µë°± ê¸°ì¤€ ì²« 2-3ë‹¨ì–´)
    keywords = product_name.split()[:3]
    for item in MARGIN_DATA:
        margin_name = item.get('ìƒí’ˆëª…', '')
        if len(keywords) >= 2 and all(kw in margin_name for kw in keywords[:2]):
            return item.get('ì¸ìƒí›„_ì´_ì›ê°€') or item.get('ì¸ìƒí›„ ì´ ì›ê°€', 0)

    return 0


def get_platform_fee_rate(site_name):
    """íŒë§¤ì²˜ë³„ ìˆ˜ìˆ˜ë£Œìœ¨ ë°˜í™˜"""
    if not site_name:
        return PLATFORM_FEES['ê¸°íƒ€']

    site_name = str(site_name)
    for platform, rate in PLATFORM_FEES.items():
        if platform in site_name:
            return rate
    return PLATFORM_FEES['ê¸°íƒ€']

# ==================== ë©´ì„¸ ìë£Œ ì •ë¦¬ í•¨ìˆ˜ ====================

def process_tax_free_files(files):
    """ì¿ íŒ¡ ë§¤ì¶œìë£Œì—ì„œ ë©´ì„¸(FREE) ë°ì´í„° ì¶”ì¶œ (ì¤‘ë³µ íŒŒì¼ ì²´í¬ í¬í•¨)"""
    import hashlib
    
    all_free_data = []
    monthly_stats = {}
    monthly_files = {}
    file_hashes = {}
    duplicate_files = []
    processed_files = []
    
    sales_cols = ['ì‹ ìš©ì¹´ë“œ(íŒë§¤)', 'í˜„ê¸ˆ(íŒë§¤)', 'ê¸°íƒ€(íŒë§¤)']
    refund_cols = ['ì‹ ìš©ì¹´ë“œ(í™˜ë¶ˆ)', 'í˜„ê¸ˆ(í™˜ë¶ˆ)', 'ê¸°íƒ€(í™˜ë¶ˆ)']
    
    for file in files:
        try:
            file_content = file.read()
            file.seek(0)
            
            file_hash = hashlib.md5(file_content).hexdigest()
            
            if file_hash in file_hashes:
                duplicate_files.append({
                    'filename': file.filename,
                    'duplicate_of': file_hashes[file_hash]
                })
                continue
            
            file_hashes[file_hash] = file.filename
            
            from io import BytesIO
            if file.filename.endswith('.xlsx'):
                df = pd.read_excel(BytesIO(file_content), engine='openpyxl')
            else:
                df = pd.read_excel(BytesIO(file_content), engine='xlrd')
            
            if 'ê³¼ì„¸ìœ í˜•' not in df.columns or 'ë§¤ì¶œì¸ì‹ì¼' not in df.columns:
                continue
            
            # ì›ë³¸ ë‚ ì§œ ë³´ì¡´ì„ ìœ„í•´ ë³„ë„ ì»¬ëŸ¼ìœ¼ë¡œ ë‚ ì§œ íŒŒì‹±
            df['_parsed_date'] = pd.to_datetime(df['ë§¤ì¶œì¸ì‹ì¼'])
            file_months = df['_parsed_date'].dt.to_period('M').unique()
            
            file_month = str(file_months[0]) if len(file_months) > 0 else None
            
            if file_month:
                if file_month in monthly_files:
                    duplicate_files.append({
                        'filename': file.filename,
                        'duplicate_of': monthly_files[file_month][0],
                        'month': file_month
                    })
                    continue
                
                monthly_files[file_month] = [file.filename]
            
            processed_files.append(file.filename)
            
            for col in sales_cols + refund_cols:
                if col not in df.columns:
                    df[col] = 0
            
            df['ì´ë§¤ì¶œ'] = df[sales_cols].sum(axis=1) - df[refund_cols].sum(axis=1)
            
            # ë²¡í„°í™” ì—°ì‚°ìœ¼ë¡œ ì›”ë³„ í†µê³„ ê³„ì‚° (ì„±ëŠ¥ ìµœì í™”)
            df['_month_key'] = df['_parsed_date'].dt.to_period('M').astype(str)
            df['_is_free'] = df['ê³¼ì„¸ìœ í˜•'].astype(str).str.strip().str.upper() == 'FREE'
            
            for month_key in df['_month_key'].unique():
                month_df = df[df['_month_key'] == month_key]
                
                if month_key not in monthly_stats:
                    monthly_stats[month_key] = {
                        'free_count': 0, 'free_sales': 0,
                        'total_count': 0, 'total_sales': 0,
                        'file_count': 0, 'files': []
                    }
                
                monthly_stats[month_key]['total_count'] += int(len(month_df))
                monthly_stats[month_key]['total_sales'] += float(month_df['ì´ë§¤ì¶œ'].sum())
                
                free_df_month = month_df[month_df['_is_free']]
                monthly_stats[month_key]['free_count'] += int(len(free_df_month))
                monthly_stats[month_key]['free_sales'] += float(free_df_month['ì´ë§¤ì¶œ'].sum())
            
            if file_month and file_month in monthly_stats:
                if file.filename not in monthly_stats[file_month]['files']:
                    monthly_stats[file_month]['files'].append(file.filename)
                    monthly_stats[file_month]['file_count'] = len(monthly_stats[file_month]['files'])
            
            free_mask = df['ê³¼ì„¸ìœ í˜•'].astype(str).str.strip().str.upper() == 'FREE'
            free_df = df[free_mask].copy()
            
            # ì„ì‹œ ì»¬ëŸ¼ë“¤ ì œê±°
            temp_cols = ['_parsed_date', '_month_key', '_is_free']
            free_df = free_df.drop(columns=[c for c in temp_cols if c in free_df.columns])
            
            if len(free_df) > 0:
                all_free_data.append(free_df)
                
        except Exception as e:
            print(f"íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜ ({file.filename}): {e}")
            import traceback
            traceback.print_exc()
            continue
    
    combined_df = pd.concat(all_free_data, ignore_index=True) if all_free_data else pd.DataFrame()
    
    # Unnamed ì»¬ëŸ¼ëª…ì„ ë¹ˆ ë¬¸ìì—´ë¡œ ë³€ê²½
    if not combined_df.empty:
        combined_df.columns = ['' if 'Unnamed' in str(col) else col for col in combined_df.columns]
    
    for month_key in monthly_stats:
        if month_key in monthly_files:
            monthly_stats[month_key]['files'] = monthly_files[month_key]
            monthly_stats[month_key]['file_count'] = len(monthly_files[month_key])
    
    return combined_df, monthly_stats, duplicate_files, processed_files


# ==================== ìŠ¤íƒ€ë°°ì†¡ í•„í„° í•¨ìˆ˜ ====================

def check_star_delivery(df):
    """ìŠ¤íƒ€ë°°ì†¡ ì£¼ë¬¸ ì¡´ì¬ ì—¬ë¶€ í™•ì¸"""
    target_col = None
    for col in df.columns:
        if 'ì£¼ì˜' in str(col) and 'ë©”' in str(col):
            target_col = col
            break
    
    if target_col is None:
        return {'has_column': False, 'star_count': 0}
    
    mask = df[target_col].astype(str).str.startswith('íŒë§¤ì ìŠ¤íƒ€ë°°ì†¡', na=False)
    star_count = int(mask.sum())
    
    return {'has_column': True, 'star_count': star_count, 'column': target_col, 'mask': mask}

def filter_star_delivery(df):
    """ìŠ¤íƒ€ë°°ì†¡ ì£¼ë¬¸ í•„í„°ë§ (ì œê±°)"""
    result = check_star_delivery(df)
    
    if not result['has_column']:
        return df, 0
    
    filtered_df = df[~result['mask']]
    deleted_count = int(result['star_count'])
    
    return filtered_df, deleted_count

# ==================== ê¸°ì¡´ ë¼ìš°íŠ¸ (100% ìœ ì§€) ====================

@app.route('/login', methods=['GET', 'POST'])
@limiter.limit("5 per minute", methods=["POST"])
def login():
    """ë¡œê·¸ì¸ í˜ì´ì§€"""
    if request.method == 'POST':
        data = request.get_json()
        user_id = data.get('id', '')
        user_pw = data.get('pw', '')
        
        # 1. DBì—ì„œ ì‚¬ìš©ì í™•ì¸ (ì¶œí‡´ê·¼ ì‹œìŠ¤í…œìš©)
        if DB_CONNECTED and supabase:
            try:
                response = supabase.table('users').select('*').eq('username', user_id).eq('password', user_pw).eq('enabled', True).execute()
                if response.data:
                    user = response.data[0]
                    session['logged_in'] = True
                    session['user_id'] = user['id']
                    session['user_role'] = user['role']
                    session['user_name'] = user['name']
                    session['username'] = user['username']
                    return jsonify({'success': True, 'role': user['role']})
            except Exception as e:
                print(f"DB ë¡œê·¸ì¸ í™•ì¸ ì˜¤ë¥˜: {e}")
        
        # 2. ê¸°ì¡´ í™˜ê²½ë³€ìˆ˜ ê´€ë¦¬ì ê³„ì • (í•˜ìœ„ í˜¸í™˜)
        if user_id == LOGIN_ID and user_pw == LOGIN_PW:
            session['logged_in'] = True
            session['user_id'] = 0
            session['user_role'] = 'admin'
            session['user_name'] = 'ê´€ë¦¬ì'
            session['username'] = user_id
            return jsonify({'success': True, 'role': 'admin'})
        
        # 3. ADMIN_ID/ADMIN_PW í™•ì¸
        if user_id == ADMIN_ID and user_pw == ADMIN_PW:
            session['logged_in'] = True
            session['user_id'] = 0
            session['user_role'] = 'admin'
            session['user_name'] = 'ê´€ë¦¬ì'
            session['username'] = user_id
            return jsonify({'success': True, 'role': 'admin'})
        
        return jsonify({'success': False, 'error': 'ì•„ì´ë”” ë˜ëŠ” ë¹„ë°€ë²ˆí˜¸ê°€ í‹€ë ¸ìŠµë‹ˆë‹¤'})
    
    if session.get('logged_in'):
        return redirect(url_for('index'))
    
    return render_template('login.html')

@app.route('/logout')
def logout():
    """ë¡œê·¸ì•„ì›ƒ"""
    session.clear()
    return redirect(url_for('login'))

@app.route('/')
@login_required
def index():
    # ì•Œë°”ìƒì€ ì¶œí‡´ê·¼ í˜ì´ì§€ë¡œ
    if session.get('user_role') == 'parttime':
        return render_template('parttime.html')
    return render_template('index.html')

@app.route('/api/session')
@login_required
def get_session_info():
    """í˜„ì¬ ì„¸ì…˜ ì •ë³´"""
    return jsonify({
        'user_id': session.get('user_id'),
        'user_role': session.get('user_role'),
        'user_name': session.get('user_name'),
        'username': session.get('username')
    })

@app.route('/health')
def health():
    """UptimeRobot í—¬ìŠ¤ì²´í¬ìš©"""
    return 'OK', 200

# ==================== ê¸°ì¡´ /settings ë¼ìš°íŠ¸ (ìœ ì§€) ====================

@app.route('/settings', methods=['GET'])
@login_required
def get_settings_legacy():
    """í˜„ì¬ ì„¤ì • ì¡°íšŒ (ê¸°ì¡´ ë°©ì‹ - í•˜ìœ„ í˜¸í™˜)"""
    if CURRENT_SETTINGS:
        total_products = sum(
            len(cfg.get('products', [])) 
            for cfg in CURRENT_SETTINGS.get('work_config', {}).values()
        )
        
        has_file = os.path.exists(SETTINGS_FILE)
        
        return jsonify({
            'status': 'loaded',
            'workers': list(CURRENT_SETTINGS.get('work_order', [])),
            'total_products': total_products,
            'source': 'file' if has_file else 'default',
            'db_connected': DB_CONNECTED
        })
    return jsonify({
        'status': 'not_loaded', 
        'error': 'ì„¤ì •ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤',
        'db_connected': DB_CONNECTED
    })

# ==================== ê¸°ì¡´ /api/margin ë¼ìš°íŠ¸ (ìœ ì§€ + í™•ì¥) ====================

@app.route('/api/margin', methods=['GET'])
@login_required
def get_margin_data():
    """ì›ê°€ ë§ˆì§„í‘œ ë°ì´í„° ì¡°íšŒ"""
    search = request.args.get('search', '').strip()
    
    # DB ëª¨ë“œ: Supabaseì—ì„œ ì¡°íšŒ
    if DB_CONNECTED and supabase:
        try:
            query = supabase.table('margin_products').select('*')
            if search:
                query = query.ilike('ìƒí’ˆëª…', f'%{search}%')
            response = query.order('ìƒí’ˆëª…').execute()
            
            # DB ì»¬ëŸ¼ëª… â†’ JSON í˜•ì‹ ë³€í™˜
            data = []
            for item in response.data:
                data.append({
                    'id': item['id'],
                    'ìƒí’ˆëª…': item['ìƒí’ˆëª…'],
                    'ì¸ìƒì „ ìƒí’ˆê°€': item.get('ì¸ìƒì „_ìƒí’ˆê°€', 0),
                    'ì¸ìƒí›„ ìƒí’ˆê°€': item.get('ì¸ìƒí›„_ìƒí’ˆê°€', 0),
                    'ë¬¼ëŸ‰ì§€ì›': item.get('ë¬¼ëŸ‰ì§€ì›', 1),
                    'í”„ë¡œëª¨ì…˜í• ì¸ë¥ ': item.get('í”„ë¡œëª¨ì…˜í• ì¸ë¥ ', 0),
                    'ì¥ë ¤ê¸ˆë¥ ': item.get('ì¥ë ¤ê¸ˆë¥ ', 0),
                    'ë°°ì†¡ë¹„': item.get('ë°°ì†¡ë¹„', 0),
                    'ë°•ìŠ¤ë¹„': item.get('ë°•ìŠ¤ë¹„', 0),
                    'ì¸ìƒì „ ì´ ì›ê°€': item.get('ì¸ìƒì „_ì´_ì›ê°€', 0),
                    'ì¸ìƒí›„ ì´ ì›ê°€': item.get('ì¸ìƒí›„_ì´_ì›ê°€', 0),
                    'ì¸ìƒì „ ì¬ê³ ': item.get('ì¸ìƒì „_ì¬ê³ ', ''),
                    '1ë°•ìŠ¤ ìµœëŒ€ ìˆ˜ëŸ‰': item.get('ë°•ìŠ¤_ìµœëŒ€_ìˆ˜ëŸ‰', ''),
                    'ê¸°íƒ€ì‚¬í•­': item.get('ê¸°íƒ€ì‚¬í•­', '')
                })
            return jsonify({'data': data, 'total': len(data), 'source': 'db'})
        except Exception as e:
            print(f"DB ì¡°íšŒ ì‹¤íŒ¨, JSON í´ë°±: {e}")
    
    # JSON ëª¨ë“œ: íŒŒì¼ì—ì„œ ì¡°íšŒ (ê¸°ì¡´ ë°©ì‹)
    if search:
        filtered = [item for item in MARGIN_DATA if search.lower() in item['ìƒí’ˆëª…'].lower()]
        return jsonify({'data': filtered, 'total': len(filtered), 'source': 'file'})
    
    return jsonify({'data': MARGIN_DATA, 'total': len(MARGIN_DATA), 'source': 'file'})

@app.route('/api/margin', methods=['POST'])
@login_required
def create_margin_product():
    """ì›ê°€ ë§ˆì§„í‘œ ìƒí’ˆ ì¶”ê°€ (DB ëª¨ë“œë§Œ)"""
    if not DB_CONNECTED or not supabase:
        return jsonify({'error': 'DB ì—°ê²°ì´ í•„ìš”í•©ë‹ˆë‹¤', 'db_connected': False}), 400
    
    data = request.get_json()
    
    try:
        new_product = {
            'ìƒí’ˆëª…': data.get('ìƒí’ˆëª…', ''),
            'ì¸ìƒì „_ìƒí’ˆê°€': float(data.get('ì¸ìƒì „ ìƒí’ˆê°€', 0) or 0),
            'ì¸ìƒí›„_ìƒí’ˆê°€': float(data.get('ì¸ìƒí›„ ìƒí’ˆê°€', 0) or 0),
            'ë¬¼ëŸ‰ì§€ì›': float(data.get('ë¬¼ëŸ‰ì§€ì›', 1) or 1),
            'í”„ë¡œëª¨ì…˜í• ì¸ë¥ ': float(data.get('í”„ë¡œëª¨ì…˜í• ì¸ë¥ ', 0) or 0),
            'ì¥ë ¤ê¸ˆë¥ ': float(data.get('ì¥ë ¤ê¸ˆë¥ ', 0) or 0),
            'ë°°ì†¡ë¹„': float(data.get('ë°°ì†¡ë¹„', 0) or 0),
            'ë°•ìŠ¤ë¹„': float(data.get('ë°•ìŠ¤ë¹„', 0) or 0),
            'ì¸ìƒì „_ì´_ì›ê°€': float(data.get('ì¸ìƒì „ ì´ ì›ê°€', 0) or 0),
            'ì¸ìƒí›„_ì´_ì›ê°€': float(data.get('ì¸ìƒí›„ ì´ ì›ê°€', 0) or 0),
            'ì¸ìƒì „_ì¬ê³ ': str(data.get('ì¸ìƒì „ ì¬ê³ ', '')),
            'ë°•ìŠ¤_ìµœëŒ€_ìˆ˜ëŸ‰': str(data.get('1ë°•ìŠ¤ ìµœëŒ€ ìˆ˜ëŸ‰', '')),
            'ê¸°íƒ€ì‚¬í•­': str(data.get('ê¸°íƒ€ì‚¬í•­', ''))
        }
        
        response = supabase.table('margin_products').insert(new_product).execute()
        return jsonify({'success': True, 'data': response.data[0]})
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/margin/<int:product_id>', methods=['PUT'])
@login_required
def update_margin_product(product_id):
    """ì›ê°€ ë§ˆì§„í‘œ ìƒí’ˆ ìˆ˜ì • (DB ëª¨ë“œë§Œ)"""
    if not DB_CONNECTED or not supabase:
        return jsonify({'error': 'DB ì—°ê²°ì´ í•„ìš”í•©ë‹ˆë‹¤', 'db_connected': False}), 400
    
    data = request.get_json()
    
    try:
        update_data = {
            'ìƒí’ˆëª…': data.get('ìƒí’ˆëª…', ''),
            'ì¸ìƒì „_ìƒí’ˆê°€': float(data.get('ì¸ìƒì „ ìƒí’ˆê°€', 0) or 0),
            'ì¸ìƒí›„_ìƒí’ˆê°€': float(data.get('ì¸ìƒí›„ ìƒí’ˆê°€', 0) or 0),
            'ë¬¼ëŸ‰ì§€ì›': float(data.get('ë¬¼ëŸ‰ì§€ì›', 1) or 1),
            'í”„ë¡œëª¨ì…˜í• ì¸ë¥ ': float(data.get('í”„ë¡œëª¨ì…˜í• ì¸ë¥ ', 0) or 0),
            'ì¥ë ¤ê¸ˆë¥ ': float(data.get('ì¥ë ¤ê¸ˆë¥ ', 0) or 0),
            'ë°°ì†¡ë¹„': float(data.get('ë°°ì†¡ë¹„', 0) or 0),
            'ë°•ìŠ¤ë¹„': float(data.get('ë°•ìŠ¤ë¹„', 0) or 0),
            'ì¸ìƒì „_ì´_ì›ê°€': float(data.get('ì¸ìƒì „ ì´ ì›ê°€', 0) or 0),
            'ì¸ìƒí›„_ì´_ì›ê°€': float(data.get('ì¸ìƒí›„ ì´ ì›ê°€', 0) or 0),
            'ì¸ìƒì „_ì¬ê³ ': str(data.get('ì¸ìƒì „ ì¬ê³ ', '')),
            'ë°•ìŠ¤_ìµœëŒ€_ìˆ˜ëŸ‰': str(data.get('1ë°•ìŠ¤ ìµœëŒ€ ìˆ˜ëŸ‰', '')),
            'ê¸°íƒ€ì‚¬í•­': str(data.get('ê¸°íƒ€ì‚¬í•­', '')),
            'updated_at': datetime.utcnow().isoformat()
        }
        
        response = supabase.table('margin_products').update(update_data).eq('id', product_id).execute()
        return jsonify({'success': True, 'data': response.data[0] if response.data else None})
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/margin/<int:product_id>', methods=['DELETE'])
@login_required
def delete_margin_product(product_id):
    """ì›ê°€ ë§ˆì§„í‘œ ìƒí’ˆ ì‚­ì œ (DB ëª¨ë“œë§Œ)"""
    if not DB_CONNECTED or not supabase:
        return jsonify({'error': 'DB ì—°ê²°ì´ í•„ìš”í•©ë‹ˆë‹¤', 'db_connected': False}), 400
    
    try:
        supabase.table('margin_products').delete().eq('id', product_id).execute()
        return jsonify({'success': True})
    except Exception as e:
        return jsonify({'error': str(e)}), 500

# ==================== ë‹´ë‹¹ì API (ìƒˆë¡œ ì¶”ê°€) ====================

@app.route('/api/workers', methods=['GET'])
@login_required
def get_workers():
    """ë‹´ë‹¹ì ëª©ë¡ ì¡°íšŒ"""
    # DB ëª¨ë“œ
    if DB_CONNECTED and supabase:
        try:
            response = supabase.table('workers').select('*').order('sort_order').execute()
            workers = response.data
            
            # ê° ë‹´ë‹¹ìë³„ ìƒí’ˆ ê°œìˆ˜ ì¶”ê°€
            for worker in workers:
                products_resp = supabase.table('worker_products').select('id').eq('worker_id', worker['id']).execute()
                worker['product_count'] = len(products_resp.data)
            
            return jsonify({'data': workers, 'source': 'db', 'db_connected': True})
        except Exception as e:
            print(f"ë‹´ë‹¹ì DB ì¡°íšŒ ì‹¤íŒ¨: {e}")
    
    # JSON ëª¨ë“œ (í´ë°±)
    if CURRENT_SETTINGS:
        workers = []
        icons = {
            'ì†¡ê³¼ì¥ë‹˜': 'ğŸ§', 'ì˜ì¬ì”¨': 'ğŸ¯', 'íš¨ìƒ': 'ğŸœ', 'ê°•ë¯¼ì”¨': 'ğŸœ',
            'ë¶€ëª¨ë‹˜': 'â˜•', 'í•©ë°°ì†¡': 'ğŸ“¦', 'ë³µìˆ˜ì£¼ë¬¸': 'ğŸ“‹', 'ë¶„ë¥˜ì‹¤íŒ¨': 'â“'
        }
        descriptions = {
            'ì†¡ê³¼ì¥ë‹˜': 'íŒ¥ë¹™ìˆ˜ì¬ë£Œ ë° íŠ¹ì • ìƒí’ˆ ë‹´ë‹¹',
            'ì˜ì¬ì”¨': 'ë¯¸ì—ë¡œí™”ì´ë°”, ê¿€ì°¨, íŒŒìš°ì¹˜ìŒë£Œ ë‹´ë‹¹',
            'íš¨ìƒ': 'ë°±ì œ ìŒ€êµ­ìˆ˜, ë–¡êµ­ ë‹´ë‹¹',
            'ê°•ë¯¼ì”¨': 'ë°±ì œ ë¸Œëœë“œ ëª¨ë“  ìƒí’ˆ ë‹´ë‹¹',
            'ë¶€ëª¨ë‹˜': 'ìŸˆë…, ë¶€êµ­, ë¦°ì €, ì¹´í˜ì¬ë£Œ ë‹´ë‹¹',
            'í•©ë°°ì†¡': 'í•œ ì£¼ë¬¸ë²ˆí˜¸ì— ì—¬ëŸ¬ ë‹¤ë¥¸ ìƒí’ˆ',
            'ë³µìˆ˜ì£¼ë¬¸': 'í•œ ìƒí’ˆì„ 2ê°œ ì´ìƒ ì£¼ë¬¸',
            'ë¶„ë¥˜ì‹¤íŒ¨': 'ë§¤ì¹­ë˜ì§€ ì•Šì€ ìƒí’ˆ (ìˆ˜ë™ ê²€í†  í•„ìš”)'
        }
        
        for i, name in enumerate(CURRENT_SETTINGS.get('work_order', [])):
            config = CURRENT_SETTINGS.get('work_config', {}).get(name, {})
            workers.append({
                'id': i + 1,
                'name': name,
                'type': config.get('type', 'product_specific'),
                'description': descriptions.get(name, config.get('description', '')),
                'icon': icons.get(name, config.get('icon', 'ğŸ“‹')),
                'enabled': config.get('enabled', True),
                'product_count': len(config.get('products', []))
            })
        return jsonify({'data': workers, 'source': 'file', 'db_connected': False})
    
    return jsonify({'data': [], 'source': 'none', 'db_connected': False})

@app.route('/api/workers/<int:worker_id>/products', methods=['GET'])
@login_required
def get_worker_products(worker_id):
    """ë‹´ë‹¹ìë³„ ìƒí’ˆ ê·œì¹™ ì¡°íšŒ"""
    # DB ëª¨ë“œ
    if DB_CONNECTED and supabase:
        try:
            response = supabase.table('worker_products').select('*').eq('worker_id', worker_id).order('product_name').execute()
            return jsonify({'data': response.data, 'source': 'db', 'db_connected': True})
        except Exception as e:
            print(f"ìƒí’ˆ ê·œì¹™ DB ì¡°íšŒ ì‹¤íŒ¨: {e}")
    
    # JSON ëª¨ë“œ (í´ë°±)
    if CURRENT_SETTINGS:
        work_order = CURRENT_SETTINGS.get('work_order', [])
        if 0 < worker_id <= len(work_order):
            worker_name = work_order[worker_id - 1]
            config = CURRENT_SETTINGS.get('work_config', {}).get(worker_name, {})
            products = config.get('products', [])
            
            # ìƒí’ˆëª…ìœ¼ë¡œ ì •ë ¬
            sorted_products = sorted(products, key=lambda x: x.get('product_name', ''))
            
            # ID ì¶”ê°€ (ì¸ë±ìŠ¤ ê¸°ë°˜)
            result = []
            for i, p in enumerate(sorted_products):
                result.append({
                    'id': i + 1,
                    'worker_id': worker_id,
                    'brand': p.get('brand', ''),
                    'product_name': p.get('product_name', ''),
                    'order_option': p.get('order_option', 'All')
                })
            return jsonify({'data': result, 'source': 'file', 'db_connected': False})
    
    return jsonify({'data': [], 'source': 'none', 'db_connected': False})

@app.route('/api/workers/<int:worker_id>/products', methods=['POST'])
@login_required
def create_worker_product(worker_id):
    """ë‹´ë‹¹ì ìƒí’ˆ ê·œì¹™ ì¶”ê°€ (DB ëª¨ë“œë§Œ)"""
    if not DB_CONNECTED or not supabase:
        return jsonify({'error': 'DB ì—°ê²°ì´ í•„ìš”í•©ë‹ˆë‹¤', 'db_connected': False}), 400
    
    data = request.get_json()
    
    try:
        new_product = {
            'worker_id': worker_id,
            'brand': data.get('brand', ''),
            'product_name': data.get('product_name', ''),
            'order_option': data.get('order_option', 'All')
        }
        
        response = supabase.table('worker_products').insert(new_product).execute()
        return jsonify({'success': True, 'data': response.data[0]})
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/workers/<int:worker_id>/products/<int:product_id>', methods=['PUT'])
@login_required
def update_worker_product(worker_id, product_id):
    """ë‹´ë‹¹ì ìƒí’ˆ ê·œì¹™ ìˆ˜ì • (DB ëª¨ë“œë§Œ)"""
    if not DB_CONNECTED or not supabase:
        return jsonify({'error': 'DB ì—°ê²°ì´ í•„ìš”í•©ë‹ˆë‹¤', 'db_connected': False}), 400
    
    data = request.get_json()
    
    try:
        update_data = {
            'brand': data.get('brand', ''),
            'product_name': data.get('product_name', ''),
            'order_option': data.get('order_option', 'All'),
            'updated_at': datetime.utcnow().isoformat()
        }
        
        response = supabase.table('worker_products').update(update_data).eq('id', product_id).execute()
        return jsonify({'success': True, 'data': response.data[0] if response.data else None})
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/workers/<int:worker_id>/products/<int:product_id>', methods=['DELETE'])
@login_required
def delete_worker_product(worker_id, product_id):
    """ë‹´ë‹¹ì ìƒí’ˆ ê·œì¹™ ì‚­ì œ (DB ëª¨ë“œë§Œ)"""
    if not DB_CONNECTED or not supabase:
        return jsonify({'error': 'DB ì—°ê²°ì´ í•„ìš”í•©ë‹ˆë‹¤', 'db_connected': False}), 400
    
    try:
        supabase.table('worker_products').delete().eq('id', product_id).execute()
        return jsonify({'success': True})
    except Exception as e:
        return jsonify({'error': str(e)}), 500

# ==================== DB ìƒíƒœ í™•ì¸ API ====================

@app.route('/api/db-status', methods=['GET'])
@login_required
def get_db_status():
    """DB ì—°ê²° ìƒíƒœ í™•ì¸"""
    return jsonify({
        'db_connected': DB_CONNECTED,
        'mode': 'db' if DB_CONNECTED else 'file'
    })

# ==================== ê¸°ì¡´ ìŠ¤íƒ€ë°°ì†¡ í•„í„° (100% ìœ ì§€) ====================

@app.route('/upload', methods=['POST'])
@login_required
def upload_file():
    """ìŠ¤íƒ€ë°°ì†¡ í•„í„°"""
    if 'file' not in request.files:
        return jsonify({'error': 'íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤'}), 400
    
    file = request.files['file']
    if file.filename == '':
        return jsonify({'error': 'íŒŒì¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”'}), 400
    
    if not allowed_file(file.filename):
        return jsonify({'error': '.xls ë˜ëŠ” .xlsx íŒŒì¼ë§Œ ê°€ëŠ¥í•©ë‹ˆë‹¤'}), 400
    
    try:
        ext = file.filename.rsplit('.', 1)[1].lower()
        if ext == 'xls':
            df = pd.read_excel(file, engine='xlrd')
        else:
            df = pd.read_excel(file, engine='openpyxl')
        
        original_count = len(df)
        
        target_col = None
        for col in df.columns:
            if 'ì£¼ì˜' in str(col) and 'ë©”' in str(col):
                target_col = col
                break
        
        if target_col is None:
            return jsonify({'error': "'ì£¼ì˜ë©”ì„¸ì§€' ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"}), 400
        
        mask = df[target_col].astype(str).str.startswith('íŒë§¤ì ìŠ¤íƒ€ë°°ì†¡', na=False)
        df_filtered = df[~mask]
        deleted_count = original_count - len(df_filtered)
        
        output = BytesIO()
        df_filtered.to_excel(output, index=False, engine='openpyxl')
        output.seek(0)
        
        original_name = secure_filename(file.filename).rsplit('.', 1)[0]
        output_filename = f"{original_name}_final.xlsx"
        
        return send_file(
            output,
            mimetype='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
            as_attachment=True,
            download_name=output_filename
        ), 200, {
            'X-Deleted-Count': str(deleted_count),
            'X-Original-Count': str(original_count)
        }
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500

# ==================== ê¸°ì¡´ ì†¡ì¥ ë¶„ë¥˜ (100% ìœ ì§€) ====================

@app.route('/classify', methods=['POST'])
@login_required
def classify_orders():
    """ì†¡ì¥ ë¶„ë¥˜ - í†µê³„ì™€ í•¨ê»˜ ê²°ê³¼ ë°˜í™˜ + DB ì €ì¥"""
    cleanup_old_sessions()  # ì˜¤ë˜ëœ ì„¸ì…˜ ì •ë¦¬
    if 'file' not in request.files:
        return jsonify({'error': 'íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤'}), 400

    file = request.files['file']
    if file.filename == '':
        return jsonify({'error': 'íŒŒì¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”'}), 400

    if not allowed_file(file.filename):
        return jsonify({'error': '.xls ë˜ëŠ” .xlsx íŒŒì¼ë§Œ ê°€ëŠ¥í•©ë‹ˆë‹¤'}), 400

    if not CURRENT_SETTINGS:
        return jsonify({'error': 'ì„¤ì • íŒŒì¼ì„ ë¨¼ì € ë¡œë“œí•´ì£¼ì„¸ìš”'}), 400

    filter_star = request.form.get('filter_star', 'false').lower() == 'true'

    try:
        ext = file.filename.rsplit('.', 1)[1].lower()
        if ext == 'xls':
            df = pd.read_excel(file, engine='xlrd')
        else:
            df = pd.read_excel(file, engine='openpyxl')

        # ë°ì´í„° ë¶„ì„ìš© DB ì €ì¥ (ì²´í¬ë°•ìŠ¤ë¡œ ì œì–´)
        collect_analytics = request.form.get('collect_analytics', 'false').lower() == 'true'
        
        if DB_CONNECTED and collect_analytics:
            try:
                df_copy = df.copy()
                saved_count = save_sales_data_to_db(df_copy)
                print(f"âœ… íŒë§¤ ë°ì´í„° {saved_count}ê±´ ì €ì¥ ì™„ë£Œ")
            except Exception as e:
                import traceback
                print(f"âš ï¸ íŒë§¤ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
                traceback.print_exc()

        star_deleted = 0
        if filter_star:
            df, star_deleted = filter_star_delivery(df)

        classifier = OrderClassifierV41(CURRENT_SETTINGS)
        result_df = classifier.classify_orders_optimized(df)
        stats = classifier.get_classification_stats(result_df)

        # ìŠ¤íƒ€ë°°ì†¡ í•„í„°ë§ ì²´í¬í•œ ê²½ìš° í•­ìƒ ì •ë³´ ì¶”ê°€ (0ê±´ì´ì–´ë„)
        if filter_star:
            stats['summary']['star_filtered'] = True
            stats['summary']['star_deleted'] = star_deleted
        else:
            stats['summary']['star_filtered'] = False

        session_id = secrets.token_urlsafe(16)
        TEMP_RESULTS[session_id] = {
            'df': result_df,
            'stats': stats,
            'filename': file.filename,
            'created_at': datetime.now()
        }

        return jsonify({
            'success': True,
            'session_id': session_id,
            'stats': stats
        })

    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500

@app.route('/download/<session_id>')
@login_required
def download_result(session_id):
    """ë¶„ë¥˜ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ"""
    if session_id not in TEMP_RESULTS:
        return jsonify({'error': 'ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤'}), 404
    
    result = TEMP_RESULTS[session_id]
    df = result['df']
    
    classifier = OrderClassifierV41(CURRENT_SETTINGS)
    output = classifier.export_single_sheet(df)
    
    original_name = result['filename'].rsplit('.', 1)[0]
    output_filename = f"{original_name}_ë¶„ë¥˜ì™„ë£Œ.xlsx"
    
    return send_file(
        output,
        mimetype='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
        as_attachment=True,
        download_name=output_filename
    )

# ==================== ë¶„ë¥˜ ì—”ì§„ (ì›ë³¸ 100% ìœ ì§€) ====================

class OrderClassifierV41:
    """
    í”Œë ˆì´ì˜¤í†  ì£¼ë¬¸ ë¶„ë¥˜ ì—”ì§„ v4.1
    ì›ë³¸ ë°ìŠ¤í¬í†± ì•±ì˜ ëª¨ë“  ë¡œì§ 100% ì¬í˜„
    """
    
    def __init__(self, settings):
        self.settings = settings
        self.work_order = settings.get('work_order', [])
        self.work_config = settings.get('work_config', {})
        self.quantity_threshold = settings.get('quantity_threshold', 2)
        self.auto_learn = settings.get('auto_learn', True)
        self.min_confidence = settings.get('min_confidence', 1.0)
        
    def classify_orders_optimized(self, df):
        """ìµœì í™”ëœ ì£¼ë¬¸ ë¶„ë¥˜ (ì›ë³¸ ë¡œì§)"""
        df = df.copy()
        
        # ì „ì²˜ë¦¬
        df = self._preprocess_data_optimized(df)
        
        # ë¶„ë¥˜ ì‹¤íŒ¨ ë‹´ë‹¹ìëª… ì°¾ê¸°
        failed_work = self._get_failed_work_name()
        
        # ì´ˆê¸°ê°’ ì„¤ì •
        df['ë‹´ë‹¹ì'] = failed_work
        df['ë¶„ë¥˜ê·¼ê±°'] = 'ë§¤ì¹­ ì—†ìŒ'
        df['ì‹ ë¢°ë„'] = 0.0
        
        # 1. í•©ë°°ì†¡ ì²˜ë¦¬ (ìš°ì„ ìˆœìœ„ 1)
        if 'ì£¼ë¬¸ê³ ìœ ë²ˆí˜¸' in df.columns:
            order_counts = df['ì£¼ë¬¸ê³ ìœ ë²ˆí˜¸'].value_counts()
            multi_orders = order_counts[order_counts >= 2].index
            is_multi_order = df['ì£¼ë¬¸ê³ ìœ ë²ˆí˜¸'].isin(multi_orders)
            
            combined_work = self._get_combined_work_name()
            if combined_work:
                df.loc[is_multi_order, 'ë‹´ë‹¹ì'] = combined_work
                df.loc[is_multi_order, 'ë¶„ë¥˜ê·¼ê±°'] = 'í•©ë°°ì†¡'
                df.loc[is_multi_order, 'ì‹ ë¢°ë„'] = 1.0
        
        # 2. ë³µìˆ˜ì£¼ë¬¸ ì²˜ë¦¬ (ìš°ì„ ìˆœìœ„ 2)
        multiple_work = self._get_multiple_work_name()
        if multiple_work:
            is_multiple = (df['ì£¼ë¬¸ìˆ˜ëŸ‰'] >= self.quantity_threshold) & (df['ë‹´ë‹¹ì'] == failed_work)
            df.loc[is_multiple, 'ë‹´ë‹¹ì'] = multiple_work
            df.loc[is_multiple, 'ë¶„ë¥˜ê·¼ê±°'] = 'ë³µìˆ˜ì£¼ë¬¸'
            df.loc[is_multiple, 'ì‹ ë¢°ë„'] = 1.0
        
        # 3. ìƒí’ˆë³„ ë§¤ì¹­ (ë¯¸ë¶„ë¥˜ë§Œ ëŒ€ìƒ)
        unmatched_mask = df['ë‹´ë‹¹ì'] == failed_work
        unmatched_indices = df[unmatched_mask].index
        
        if len(unmatched_indices) > 0:
            compiled_rules = self._compile_matching_rules()
            self._classify_batch(df, unmatched_indices, compiled_rules)
        
        # 4. ê²°ê³¼ ì •ë ¬
        df = self._sort_results_optimized(df)
        
        return df
    
    def _preprocess_data_optimized(self, df):
        """ë°ì´í„° ì „ì²˜ë¦¬"""
        # ìƒí’ˆëª… ì²˜ë¦¬
        if 'ìƒí’ˆëª…' in df.columns:
            df['ìƒí’ˆëª…'] = df['ìƒí’ˆëª…'].fillna('').astype(str)
        else:
            raise ValueError("í•„ìˆ˜ ì»¬ëŸ¼ 'ìƒí’ˆëª…' ì—†ìŒ")
        
        # ì£¼ë¬¸ìˆ˜ëŸ‰ ì²˜ë¦¬
        if 'ì£¼ë¬¸ìˆ˜ëŸ‰' in df.columns:
            df['ì£¼ë¬¸ìˆ˜ëŸ‰'] = pd.to_numeric(df['ì£¼ë¬¸ìˆ˜ëŸ‰'], errors='coerce').fillna(0).astype(int)
        else:
            df['ì£¼ë¬¸ìˆ˜ëŸ‰'] = 1
        
        # ì£¼ë¬¸ì„ íƒì‚¬í•­ ì²˜ë¦¬
        if 'ì£¼ë¬¸ì„ íƒì‚¬í•­' in df.columns:
            df['ì£¼ë¬¸ì„ íƒì‚¬í•­'] = df['ì£¼ë¬¸ì„ íƒì‚¬í•­'].fillna('').astype(str)
            df['full_product_name'] = df['ìƒí’ˆëª…'] + ' ' + df['ì£¼ë¬¸ì„ íƒì‚¬í•­']
        else:
            df['ì£¼ë¬¸ì„ íƒì‚¬í•­'] = ''
            df['full_product_name'] = df['ìƒí’ˆëª…']
        
        # ë¸Œëœë“œ ì¶”ì¶œ
        df['brand'] = df['ìƒí’ˆëª…'].str.split(n=1, expand=True)[0].fillna('')
        
        # ì£¼ë¬¸ê³ ìœ ë²ˆí˜¸ ì²˜ë¦¬
        if 'ì£¼ë¬¸ê³ ìœ ë²ˆí˜¸' in df.columns:
            df['ì£¼ë¬¸ê³ ìœ ë²ˆí˜¸'] = df['ì£¼ë¬¸ê³ ìœ ë²ˆí˜¸'].fillna('').astype(str)
        elif 'ì£¼ë¬¸ë²ˆí˜¸' in df.columns:
            df['ì£¼ë¬¸ê³ ìœ ë²ˆí˜¸'] = df['ì£¼ë¬¸ë²ˆí˜¸'].fillna('').astype(str)
        else:
            df['ì£¼ë¬¸ê³ ìœ ë²ˆí˜¸'] = np.arange(len(df)).astype(str)
        
        return df
    
    def _compile_matching_rules(self):
        """ë§¤ì¹­ ê·œì¹™ ì»´íŒŒì¼"""
        rules = []
        for work_name in self.work_order:
            work_config = self.work_config.get(work_name, {})
            if work_config.get('type') != 'product_specific':
                continue
            
            for product in work_config.get('products', []):
                rules.append({
                    'work_name': work_name,
                    'brand': product.get('brand', ''),
                    'product_name': product.get('product_name', ''),
                    'order_option': product.get('order_option', 'All')
                })
        return rules
    
    def _classify_batch(self, df, indices, rules):
        """ë°°ì¹˜ ë¶„ë¥˜"""
        for idx in indices:
            row = df.loc[idx]
            
            for rule in rules:
                if self._match_rule(row, rule):
                    df.at[idx, 'ë‹´ë‹¹ì'] = rule['work_name']
                    df.at[idx, 'ë¶„ë¥˜ê·¼ê±°'] = f"ë§¤ì¹­: {rule['brand']} {rule['product_name']}"
                    df.at[idx, 'ì‹ ë¢°ë„'] = 1.0
                    break
    
    def _match_rule(self, row, rule):
        """ê·œì¹™ ë§¤ì¹­"""
        # ë¸Œëœë“œ ì²´í¬
        if rule['brand'] and rule['brand'] != 'All':
            if rule['brand'] not in row['brand']:
                return False
        
        # ìƒí’ˆëª… ì²´í¬
        if rule['product_name'] != 'All':
            if rule['product_name'] not in row['ìƒí’ˆëª…']:
                return False
        
        # ì£¼ë¬¸ì„ íƒì‚¬í•­ ì²´í¬
        if rule['order_option'] != 'All':
            if rule['order_option'] not in row['ì£¼ë¬¸ì„ íƒì‚¬í•­']:
                return False
        
        return True
    
    def _sort_results_optimized(self, df):
        """ê²°ê³¼ ì •ë ¬"""
        priority_map = {name: i for i, name in enumerate(self.work_order)}
        df['priority'] = df['ë‹´ë‹¹ì'].map(priority_map)
        
        combined_work = self._get_combined_work_name()
        
        sorted_groups = []
        for work_name in self.work_order:
            work_df = df[df['ë‹´ë‹¹ì'] == work_name].copy()
            
            if len(work_df) == 0:
                continue
            
            if work_name == combined_work:
                work_df = work_df.sort_values(['ì£¼ë¬¸ê³ ìœ ë²ˆí˜¸'])
            else:
                work_df = work_df.sort_values(['full_product_name'])
            
            sorted_groups.append(work_df)
        
        if sorted_groups:
            sorted_df = pd.concat(sorted_groups, ignore_index=True)
            sorted_df = sorted_df.drop(['priority'], axis=1)
        else:
            sorted_df = df
        
        return sorted_df
    
    def get_classification_stats(self, df):
        """ë¶„ë¥˜ í†µê³„ ê³„ì‚°"""
        total_orders = len(df)
        stats = {
            'workers': [],
            'summary': {}
        }
        
        current_row = 1
        
        for work_name in self.work_order:
            work_data = df[df['ë‹´ë‹¹ì'] == work_name]
            count = len(work_data)
            
            config = self.work_config.get(work_name, {})
            icon = config.get('icon', 'ğŸ“‹')
            
            if count > 0:
                start_row = current_row
                end_row = current_row + count - 1
                row_range = f"{start_row} ~ {end_row}"
                current_row = end_row + 1
            else:
                row_range = "-"
            
            stats['workers'].append({
                'name': work_name,
                'count': count,
                'percentage': round(count / total_orders * 100, 1) if total_orders > 0 else 0,
                'icon': icon,
                'range': row_range
            })
        
        # ìš”ì•½ í†µê³„
        failed_work = self._get_failed_work_name()
        unmatched_count = len(df[df['ë‹´ë‹¹ì'] == failed_work])
        success_count = total_orders - unmatched_count
        auto_rate = round(success_count / total_orders * 100, 1) if total_orders > 0 else 0
        
        stats['summary'] = {
            'total_orders': total_orders,
            'success_count': success_count,
            'failed_count': unmatched_count,
            'auto_classification_rate': auto_rate
        }
        
        return stats
    
    def export_single_sheet(self, df):
        """ë‹¨ì¼ ì‹œíŠ¸ ì—‘ì…€ ë‚´ë³´ë‚´ê¸°"""
        output = BytesIO()
        
        export_df = df.copy()
        temp_cols = ['full_product_name', 'brand', 'priority', 'ë‹´ë‹¹ì', 'ë¶„ë¥˜ê·¼ê±°', 'ì‹ ë¢°ë„']
        for col in temp_cols:
            if col in export_df.columns:
                export_df = export_df.drop(columns=[col])
        
        export_df.to_excel(output, sheet_name='ë¶„ë¥˜ê²°ê³¼', index=False, engine='openpyxl')
        
        output.seek(0)
        return output
    
    def _get_failed_work_name(self):
        """ë¶„ë¥˜ì‹¤íŒ¨ ë‹´ë‹¹ìëª…"""
        for work_name, config in self.work_config.items():
            if config.get('type') == 'failed':
                return work_name
        return 'ë¶„ë¥˜ì‹¤íŒ¨'
    
    def _get_combined_work_name(self):
        """í•©ë°°ì†¡ ë‹´ë‹¹ìëª…"""
        for work_name, config in self.work_config.items():
            if config.get('type') == 'mixed_products':
                return work_name
        return None
    
    def _get_multiple_work_name(self):
        """ë³µìˆ˜ì£¼ë¬¸ ë‹´ë‹¹ìëª…"""
        for work_name, config in self.work_config.items():
            if config.get('type') == 'multiple_quantity':
                return work_name
        return None

# ==================== ë©´ì„¸ ìë£Œ ì •ë¦¬ API ====================

@app.route('/api/tax-free/process', methods=['POST'])
@admin_required
def process_tax_free():
    """ë©´ì„¸ ìë£Œ ì²˜ë¦¬"""
    cleanup_old_sessions()  # ì˜¤ë˜ëœ ì„¸ì…˜ ì •ë¦¬
    if 'files' not in request.files:
        return jsonify({'error': 'íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤'}), 400
    
    files = request.files.getlist('files')
    if not files or all(f.filename == '' for f in files):
        return jsonify({'error': 'íŒŒì¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”'}), 400
    
    try:
        combined_df, monthly_stats, duplicate_files, processed_files = process_tax_free_files(files)
        
        if combined_df.empty:
            return jsonify({'error': 'ë©´ì„¸(FREE) ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤'}), 400
        
        session_id = secrets.token_urlsafe(16)
        
        output = BytesIO()
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            combined_df.to_excel(writer, index=False, sheet_name='ë©´ì„¸ìë£Œ')
        output.seek(0)
        
        TEMP_RESULTS[session_id] = {
            'data': output.getvalue(),
            'stats': monthly_stats,
            'row_count': len(combined_df),
            'created_at': datetime.now()
        }
        
        yearly_free_count = sum(s['free_count'] for s in monthly_stats.values())
        yearly_free_sales = sum(s['free_sales'] for s in monthly_stats.values())
        yearly_total_count = sum(s['total_count'] for s in monthly_stats.values())
        yearly_total_sales = sum(s['total_sales'] for s in monthly_stats.values())
        
        return jsonify({
            'success': True,
            'session_id': session_id,
            'row_count': len(combined_df),
            'monthly_stats': monthly_stats,
            'yearly_summary': {
                'free_count': yearly_free_count,
                'free_sales': yearly_free_sales,
                'total_count': yearly_total_count,
                'total_sales': yearly_total_sales
            },
            'file_info': {
                'total_uploaded': len(files),
                'processed': len(processed_files),
                'duplicates': duplicate_files,
                'processed_files': processed_files,
                'total_months': len(monthly_stats)
            }
        })
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500


@app.route('/api/tax-free/download/<session_id>')
@admin_required
def download_tax_free(session_id):
    """ë©´ì„¸ ìë£Œ ë‹¤ìš´ë¡œë“œ"""
    if session_id not in TEMP_RESULTS:
        return jsonify({'error': 'ì„¸ì…˜ì´ ë§Œë£Œë˜ì—ˆìŠµë‹ˆë‹¤'}), 404
    
    result = TEMP_RESULTS[session_id]
    output = BytesIO(result['data'])
    
    filename = f"ë©´ì„¸ìë£Œ_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
    
    return send_file(
        output,
        mimetype='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
        as_attachment=True,
        download_name=filename
    )


# ==================== ì¶œí‡´ê·¼ ê´€ë¦¬ API (ì‹ ê·œ) ====================

@app.route('/api/employees', methods=['GET'])
@admin_required
def get_employees():
    """ì§ì› ëª©ë¡ ì¡°íšŒ (ê´€ë¦¬ììš©)"""
    if not DB_CONNECTED:
        return jsonify({'error': 'DB ì—°ê²° í•„ìš”'}), 400
    try:
        response = supabase.table('users').select('*').eq('role', 'parttime').order('created_at').execute()
        employees = []
        for emp in response.data:
            employees.append({
                'id': emp['id'],
                'username': emp['username'],
                'name': emp['name'],
                'hourly_wage': emp['hourly_wage'],
                'full_attendance_bonus': emp.get('full_attendance_bonus', 100000),
                'scheduled_days': emp.get('scheduled_days', '1,2,3,4,5'),
                'enabled': emp['enabled'],
                'created_at': emp['created_at']
            })
        return jsonify({'success': True, 'data': employees})
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/employees', methods=['POST'])
@admin_required
def create_employee():
    """ì§ì› ìƒì„±"""
    if not DB_CONNECTED:
        return jsonify({'error': 'DB ì—°ê²° í•„ìš”'}), 400
    data = request.get_json()
    try:
        existing = supabase.table('users').select('id').eq('username', data.get('username')).execute()
        if existing.data:
            return jsonify({'error': 'ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ì•„ì´ë””ì…ë‹ˆë‹¤'}), 400
        
        new_emp = {
            'username': data.get('username'),
            'password': data.get('password'),
            'name': data.get('name'),
            'role': 'parttime',
            'hourly_wage': int(data.get('hourly_wage', 10700)),
            'full_attendance_bonus': int(data.get('full_attendance_bonus', 100000)),
            'scheduled_days': data.get('scheduled_days', '1,2,3,4,5'),
            'enabled': True
        }
        response = supabase.table('users').insert(new_emp).execute()
        
        supabase.table('wage_history').insert({
            'employee_id': response.data[0]['id'],
            'hourly_wage': new_emp['hourly_wage'],
            'effective_date': date.today().isoformat()
        }).execute()
        
        return jsonify({'success': True, 'data': response.data[0]})
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/employees/<int:emp_id>', methods=['PUT'])
@admin_required
def update_employee(emp_id):
    """ì§ì› ì •ë³´ ìˆ˜ì •"""
    if not DB_CONNECTED:
        return jsonify({'error': 'DB ì—°ê²° í•„ìš”'}), 400
    data = request.get_json()
    try:
        old_emp = supabase.table('users').select('*').eq('id', emp_id).execute()
        if not old_emp.data:
            return jsonify({'error': 'ì§ì›ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤'}), 404
        
        old_data = old_emp.data[0]
        old_wage = old_data.get('hourly_wage', 0)
        new_wage = int(data.get('hourly_wage', old_wage))
        
        update_data = {
            'name': data.get('name', old_data.get('name')),
            'hourly_wage': new_wage,
            'full_attendance_bonus': int(data.get('full_attendance_bonus', old_data.get('full_attendance_bonus', 100000))),
            'scheduled_days': data.get('scheduled_days', old_data.get('scheduled_days', '1,2,3,4,5')),
            'enabled': data.get('enabled', old_data.get('enabled', True)),
            'updated_at': datetime.utcnow().isoformat()
        }
        
        if data.get('password'):
            update_data['password'] = data.get('password')
        
        supabase.table('users').update(update_data).eq('id', emp_id).execute()
        
        if new_wage != old_wage:
            supabase.table('wage_history').insert({
                'employee_id': emp_id,
                'hourly_wage': new_wage,
                'effective_date': date.today().isoformat()
            }).execute()
        
        return jsonify({'success': True})
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/employees/<int:emp_id>', methods=['DELETE'])
@admin_required
def delete_employee(emp_id):
    """ì§ì› ë¹„í™œì„±í™”"""
    if not DB_CONNECTED:
        return jsonify({'error': 'DB ì—°ê²° í•„ìš”'}), 400
    try:
        supabase.table('users').update({'enabled': False, 'updated_at': datetime.utcnow().isoformat()}).eq('id', emp_id).execute()
        return jsonify({'success': True})
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/holidays', methods=['GET'])
@login_required
def get_holidays():
    """ê³µíœ´ì¼ ëª©ë¡"""
    year = request.args.get('year', date.today().year)
    month = request.args.get('month', date.today().month)
    
    if not DB_CONNECTED:
        return jsonify({'data': []})
    
    try:
        start_date = f"{year}-{int(month):02d}-01"
        _, last_day = calendar.monthrange(int(year), int(month))
        end_date = f"{year}-{int(month):02d}-{last_day}"
        
        response = supabase.table('holidays').select('*').gte('holiday_date', start_date).lte('holiday_date', end_date).order('holiday_date').execute()
        return jsonify({'success': True, 'data': response.data})
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/holidays', methods=['POST'])
@admin_required
def create_holiday():
    """ê³µíœ´ì¼ ì¶”ê°€"""
    if not DB_CONNECTED:
        return jsonify({'error': 'DB ì—°ê²° í•„ìš”'}), 400
    data = request.get_json()
    try:
        response = supabase.table('holidays').insert({
            'holiday_date': data.get('date'),
            'name': data.get('name', 'ê³µíœ´ì¼')
        }).execute()
        return jsonify({'success': True, 'data': response.data[0]})
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/holidays/<int:holiday_id>', methods=['DELETE'])
@admin_required
def delete_holiday(holiday_id):
    """ê³µíœ´ì¼ ì‚­ì œ"""
    if not DB_CONNECTED:
        return jsonify({'error': 'DB ì—°ê²° í•„ìš”'}), 400
    try:
        supabase.table('holidays').delete().eq('id', holiday_id).execute()
        return jsonify({'success': True})
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/attendance', methods=['GET'])
@login_required
def get_attendance():
    """ì¶œí‡´ê·¼ ê¸°ë¡ ì¡°íšŒ"""
    if not DB_CONNECTED:
        return jsonify({'error': 'DB ì—°ê²° í•„ìš”'}), 400
    
    year = int(request.args.get('year', date.today().year))
    month = int(request.args.get('month', date.today().month))
    emp_id = request.args.get('employee_id')
    
    if session.get('user_role') == 'parttime':
        emp_id = session.get('user_id')
    elif not emp_id:
        return jsonify({'error': 'ì§ì› ID í•„ìš”'}), 400
    
    try:
        start_date = f"{year}-{month:02d}-01"
        _, last_day = calendar.monthrange(year, month)
        end_date = f"{year}-{month:02d}-{last_day}"
        
        response = supabase.table('attendance_logs').select('*').eq('employee_id', emp_id).gte('work_date', start_date).lte('work_date', end_date).order('work_date').execute()
        
        holidays_resp = supabase.table('holidays').select('holiday_date').gte('holiday_date', start_date).lte('holiday_date', end_date).execute()
        holidays = [h['holiday_date'] for h in holidays_resp.data]
        
        emp_resp = supabase.table('users').select('name, hourly_wage, full_attendance_bonus, scheduled_days').eq('id', emp_id).execute()
        emp_info = emp_resp.data[0] if emp_resp.data else {}
        
        approvals_resp = supabase.table('edit_approvals').select('approved_date, used').eq('employee_id', emp_id).execute()
        approvals = {a['approved_date']: not a['used'] for a in approvals_resp.data}
        
        confirm_resp = supabase.table('salary_confirmations').select('*').eq('employee_id', emp_id).eq('year_month', f"{year}-{month:02d}").execute()
        is_confirmed = len(confirm_resp.data) > 0
        confirmation_data = confirm_resp.data[0] if is_confirmed else None
        
        records = []
        # [ìˆ˜ì •ë¨] KST ê¸°ì¤€ ì˜¤ëŠ˜ ë‚ ì§œ ê³„ì‚°
        kst_today = get_kst_today().isoformat()

        for log in response.data:
            work_date = log['work_date']
            is_editable = work_date == kst_today or approvals.get(work_date, False)
            records.append({
                'id': log['id'],
                'work_date': work_date,
                'clock_in': log['clock_in'],
                'clock_out': log['clock_out'],
                'is_holiday_work': log.get('is_holiday_work', False),
                'is_editable': is_editable and not is_confirmed,
                'status': 'complete' if log['clock_in'] and log['clock_out'] else 'incomplete'
            })
        
        return jsonify({
            'success': True,
            'employee_id': emp_id,
            'employee_name': emp_info.get('name', ''),
            'hourly_wage': emp_info.get('hourly_wage', 10700),
            'full_attendance_bonus': emp_info.get('full_attendance_bonus', 100000),
            'scheduled_days': emp_info.get('scheduled_days', '1,2,3,4,5'),
            'year_month': f"{year}-{month:02d}",
            'records': records,
            'holidays': holidays,
            'is_confirmed': is_confirmed,
            'confirmation_data': confirmation_data
        })
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500

@app.route('/api/attendance', methods=['POST'])
@login_required
def create_attendance():
    """ì¶œí‡´ê·¼ ê¸°ë¡ ìƒì„±/ìˆ˜ì •"""
    if not DB_CONNECTED:
        return jsonify({'error': 'DB ì—°ê²° í•„ìš”'}), 400
    
    data = request.get_json()
    work_date = data.get('work_date')
    clock_in = data.get('clock_in')
    clock_out = data.get('clock_out')
    
    if session.get('user_role') == 'parttime':
        emp_id = session.get('user_id')
    else:
        emp_id = data.get('employee_id')
    
    if not emp_id or not work_date:
        return jsonify({'error': 'í•„ìˆ˜ ì •ë³´ ëˆ„ë½'}), 400
    
    # [ìˆ˜ì •ë¨] UTC ëŒ€ì‹  KST(í•œêµ­ì‹œê°„) ê¸°ì¤€ìœ¼ë¡œ ì˜¤ëŠ˜ ë‚ ì§œ ê³„ì‚°
    today = get_kst_today().isoformat()

    if work_date != today and session.get('user_role') == 'parttime':
        approval = supabase.table('edit_approvals').select('id, used').eq('employee_id', emp_id).eq('approved_date', work_date).execute()
        if not approval.data or approval.data[0]['used']:
            return jsonify({'error': 'ìˆ˜ì • ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤. ê´€ë¦¬ì ìŠ¹ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.'}), 403
        supabase.table('edit_approvals').update({'used': True}).eq('id', approval.data[0]['id']).execute()
    
    try:
        existing = supabase.table('attendance_logs').select('id').eq('employee_id', emp_id).eq('work_date', work_date).execute()
        
        work_date_obj = date.fromisoformat(work_date)
        is_weekend = work_date_obj.weekday() >= 5
        holiday_check = supabase.table('holidays').select('id').eq('holiday_date', work_date).execute()
        is_holiday = len(holiday_check.data) > 0
        
        record_data = {
            'employee_id': emp_id,
            'work_date': work_date,
            'clock_in': clock_in,
            'clock_out': clock_out,
            'is_holiday_work': is_weekend or is_holiday,
            'updated_at': datetime.utcnow().isoformat()
        }
        
        if existing.data:
            supabase.table('attendance_logs').update(record_data).eq('id', existing.data[0]['id']).execute()
        else:
            supabase.table('attendance_logs').insert(record_data).execute()
        
        return jsonify({'success': True})
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/edit-approval', methods=['POST'])
@admin_required
def approve_edit():
    """íŠ¹ì • ë‚ ì§œ ìˆ˜ì • ìŠ¹ì¸"""
    if not DB_CONNECTED:
        return jsonify({'error': 'DB ì—°ê²° í•„ìš”'}), 400
    
    data = request.get_json()
    emp_id = data.get('employee_id')
    approved_date = data.get('date')
    
    if not emp_id or not approved_date:
        return jsonify({'error': 'í•„ìˆ˜ ì •ë³´ ëˆ„ë½'}), 400
    
    try:
        existing = supabase.table('edit_approvals').select('id').eq('employee_id', emp_id).eq('approved_date', approved_date).execute()
        
        if existing.data:
            supabase.table('edit_approvals').update({'used': False, 'approved_at': datetime.utcnow().isoformat()}).eq('id', existing.data[0]['id']).execute()
        else:
            supabase.table('edit_approvals').insert({
                'employee_id': emp_id,
                'approved_date': approved_date,
                'used': False
            }).execute()
        
        return jsonify({'success': True, 'message': f'{approved_date} ìˆ˜ì • ìŠ¹ì¸ ì™„ë£Œ'})
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/salary/calculate', methods=['GET'])
@login_required
def calculate_salary():
    """ì›”ê¸‰ ê³„ì‚°"""
    if not DB_CONNECTED:
        return jsonify({'error': 'DB ì—°ê²° í•„ìš”'}), 400
    
    year = int(request.args.get('year', date.today().year))
    month = int(request.args.get('month', date.today().month))
    emp_id = request.args.get('employee_id')
    
    if session.get('user_role') == 'parttime':
        emp_id = session.get('user_id')
    elif not emp_id:
        return jsonify({'error': 'ì§ì› ID í•„ìš”'}), 400
    
    try:
        result = _calculate_monthly_salary(int(emp_id), year, month)
        return jsonify(result)
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500

def _calculate_monthly_salary(emp_id, year, month):
    """ì›”ê¸‰ ê³„ì‚° ë¡œì§"""
    start_date = f"{year}-{month:02d}-01"
    _, last_day = calendar.monthrange(year, month)
    end_date = f"{year}-{month:02d}-{last_day}"
    
    emp_resp = supabase.table('users').select('*').eq('id', emp_id).execute()
    if not emp_resp.data:
        return {'error': 'ì§ì› ì •ë³´ ì—†ìŒ'}
    emp = emp_resp.data[0]
    hourly_wage = emp['hourly_wage']
    full_bonus = emp.get('full_attendance_bonus', 100000)
    scheduled_days = emp.get('scheduled_days', '1,2,3,4,5')  # ì†Œì •ê·¼ë¡œì¼ (0=ì¼,1=ì›”,...,6=í† )
    scheduled_days_set = set(int(d) for d in scheduled_days.split(',') if d.strip())
    
    wage_history = supabase.table('wage_history').select('*').eq('employee_id', emp_id).lte('effective_date', end_date).order('effective_date', desc=True).execute()
    
    attendance_resp = supabase.table('attendance_logs').select('*').eq('employee_id', emp_id).gte('work_date', start_date).lte('work_date', end_date).order('work_date').execute()
    records = attendance_resp.data
    
    holidays_resp = supabase.table('holidays').select('holiday_date').gte('holiday_date', start_date).lte('holiday_date', end_date).execute()
    holidays = set(h['holiday_date'] for h in holidays_resp.data)
    
    incomplete_dates = []
    for r in records:
        if not r['clock_in'] or not r['clock_out']:
            incomplete_dates.append(r['work_date'])
    
    if incomplete_dates:
        return {
            'success': False,
            'error': 'INCOMPLETE_RECORDS',
            'message': 'ì¶œí‡´ê·¼ ê¸°ë¡ì´ ë¶ˆì™„ì „í•©ë‹ˆë‹¤.',
            'incomplete_dates': incomplete_dates
        }
    
    base_pay = 0
    overtime_pay = 0
    total_hours = 0
    total_regular_hours = 0
    total_overtime_hours = 0
    work_days = len(records)
    details = []
    
    for r in records:
        work_date = r['work_date']
        clock_in = r['clock_in']
        clock_out = r['clock_out']
        
        applicable_wage = hourly_wage
        for wh in wage_history.data:
            if wh['effective_date'] <= work_date:
                applicable_wage = wh['hourly_wage']
                break
        
        regular_hrs, overtime_hrs = _calculate_daily_hours(clock_in, clock_out)
        total_daily = regular_hrs + overtime_hrs
        total_hours += total_daily
        total_regular_hours += regular_hrs
        total_overtime_hours += overtime_hrs
        
        is_special = r.get('is_holiday_work', False)
        multiplier = 1.5 if is_special else 1.0
        
        day_base = int(regular_hrs * applicable_wage * multiplier)
        day_overtime = int(overtime_hrs * applicable_wage * 1.5 * multiplier)
        
        base_pay += day_base
        overtime_pay += day_overtime
        
        details.append({
            'date': work_date,
            'clock_in': clock_in,
            'clock_out': clock_out,
            'hours': round(total_daily, 2),
            'regular_hours': round(regular_hrs, 2),
            'overtime_hours': round(overtime_hrs, 2),
            'wage': applicable_wage,
            'is_special': is_special,
            'base': day_base,
            'overtime': day_overtime
        })
    
    # ì£¼íœ´ìˆ˜ë‹¹: í•´ë‹¹ ì£¼ì˜ ì¼ìš”ì¼ì´ ì†í•œ ë‹¬ì— ê·€ì†
    weekly_holiday_pay = 0
    weekly_details = []
    
    # í•´ë‹¹ ì›”ì˜ ëª¨ë“  ì¼ìš”ì¼ ì°¾ê¸°
    sundays_in_month = []
    for day in range(1, last_day + 1):
        d = date(year, month, day)
        if d.weekday() == 6:
            sundays_in_month.append(d)
    
    # ê° ì¼ìš”ì¼ ê¸°ì¤€ìœ¼ë¡œ ê·¸ ì£¼(ì›”~ì¼) ì „ì²´ ê·¼ë¬´ì‹œê°„ ê³„ì‚°
    for sunday in sundays_in_month:
        monday = sunday - timedelta(days=6)
        week_start = monday.isoformat()
        week_end = sunday.isoformat()
        
        week_attendance = supabase.table('attendance_logs').select('work_date, clock_in, clock_out').eq('employee_id', emp_id).gte('work_date', week_start).lte('work_date', week_end).execute()
        
        # í•´ë‹¹ ì£¼ì˜ ê³µíœ´ì¼ ì¡°íšŒ (ì›” ê²½ê³„ ì£¼ì—ì„œë„ ì •í™•íˆ ì²´í¬)
        week_holidays_resp = supabase.table('holidays').select('holiday_date').gte('holiday_date', week_start).lte('holiday_date', week_end).execute()
        week_holidays = set(h['holiday_date'] for h in week_holidays_resp.data)
        
        week_total_hours = 0
        worked_dates = set()
        week_work_days = 0
        for rec in week_attendance.data:
            if rec['clock_in'] and rec['clock_out']:
                reg, ot = _calculate_daily_hours(rec['clock_in'], rec['clock_out'])
                week_total_hours += reg + ot
                worked_dates.add(rec['work_date'])
                week_work_days += 1
        
        # ì†Œì •ê·¼ë¡œì¼ ê³„ì‚°
        required_work_dates = set()
        for i in range(7):
            d = monday + timedelta(days=i)
            # d.weekday(): ì›”=0, í™”=1, ..., ì¼=6 â†’ scheduled_daysëŠ” 0=ì¼, 1=ì›”, ..., 6=í† 
            # ë³€í™˜: (d.weekday() + 1) % 7 â†’ ì›”=1, í™”=2, ..., ì¼=0
            day_num = (d.weekday() + 1) % 7
            if day_num in scheduled_days_set and d.isoformat() not in week_holidays:
                required_work_dates.add(d.isoformat())
        
        # ì£¼íœ´ìˆ˜ë‹¹ ì¡°ê±´: 15ì‹œê°„ ì´ìƒ + ì†Œì •ê·¼ë¡œì¼ ê°œê·¼
        is_full_week_attendance = required_work_dates <= worked_dates
        is_eligible = week_total_hours >= 15 and is_full_week_attendance
        week_holiday_pay = int((week_total_hours / 5) * hourly_wage) if is_eligible else 0
        
        if is_eligible:
            weekly_holiday_pay += week_holiday_pay
        
        # ì£¼íœ´ìˆ˜ë‹¹ ìƒì„¸ ë‚´ì—­ ì €ì¥
        weekly_details.append({
            'week_start': week_start,
            'week_end': week_end,
            'sunday': sunday.isoformat(),
            'total_hours': round(week_total_hours, 2),
            'work_days': week_work_days,
            'required_days': len(required_work_dates),
            'is_full_attendance': is_full_week_attendance,
            'is_eligible': is_eligible,
            'holiday_pay': week_holiday_pay,
            'reason': '' if is_eligible else ('15ì‹œê°„ ë¯¸ë§Œ' if week_total_hours < 15 else 'ê°œê·¼ ë¯¸ì¶©ì¡±')
        })
    
    # ë§Œê·¼ìˆ˜ë‹¹ ê³„ì‚° (ì†Œì •ê·¼ë¡œì¼ ê¸°ì¤€)
    required_days = []
    for day in range(1, last_day + 1):
        d = date(year, month, day)
        # d.weekday(): ì›”=0, í™”=1, ..., ì¼=6 â†’ scheduled_daysëŠ” 0=ì¼, 1=ì›”, ..., 6=í† 
        day_num = (d.weekday() + 1) % 7
        if day_num in scheduled_days_set and d.isoformat() not in holidays:
            required_days.append(d.isoformat())
    
    worked_days = set(r['work_date'] for r in records if r['clock_in'] and r['clock_out'])
    is_full_attendance = set(required_days) <= worked_days
    full_attendance_bonus = full_bonus if is_full_attendance else 0
    
    total_pay = base_pay + overtime_pay + weekly_holiday_pay + full_attendance_bonus
    
    return {
        'success': True,
        'employee_id': emp_id,
        'employee_name': emp['name'],
        'year_month': f"{year}-{month:02d}",
        'breakdown': {
            'base_pay': base_pay,
            'overtime_pay': overtime_pay,
            'weekly_holiday_pay': weekly_holiday_pay,
            'full_attendance_bonus': full_attendance_bonus,
            'total_pay': total_pay,
            'total_hours': round(total_hours, 2),
            'total_regular_hours': round(total_regular_hours, 2),
            'total_overtime_hours': round(total_overtime_hours, 2),
            'work_days': work_days,
            'is_full_attendance': is_full_attendance,
            'hourly_wage': hourly_wage
        },
        'details': details,
        'weekly_details': weekly_details,
        'required_days': len(required_days),
        'worked_days': len(worked_days)
    }

def _calculate_daily_hours(clock_in_str, clock_out_str):
    """ì¼ì¼ ê·¼ë¬´ì‹œê°„ ê³„ì‚°"""
    if not clock_in_str or not clock_out_str:
        return 0.0, 0.0
    
    def time_to_minutes(t_str):
        parts = t_str.split(':')
        return int(parts[0]) * 60 + int(parts[1])
    
    start_min = time_to_minutes(clock_in_str)
    end_min = time_to_minutes(clock_out_str)
    
    if end_min <= start_min:
        return 0.0, 0.0
    
    total_min = end_min - start_min
    
    lunch_start = 12 * 60
    lunch_end = 13 * 60
    if start_min < lunch_end and end_min > lunch_start:
        overlap_start = max(start_min, lunch_start)
        overlap_end = min(end_min, lunch_end)
        total_min -= max(0, overlap_end - overlap_start)
    
    work_start = 9 * 60
    work_end = 18 * 60
    
    regular_start = max(start_min, work_start)
    regular_end = min(end_min, work_end)
    regular_min = max(0, regular_end - regular_start)
    
    if regular_start < lunch_end and regular_end > lunch_start:
        overlap_start = max(regular_start, lunch_start)
        overlap_end = min(regular_end, lunch_end)
        regular_min -= max(0, overlap_end - overlap_start)
    
    overtime_min = total_min - regular_min
    
    return regular_min / 60, max(0, overtime_min) / 60

@app.route('/api/salary/confirm', methods=['POST'])
@login_required
def confirm_salary():
    """ì›”ê¸‰ í™•ì •"""
    if not DB_CONNECTED:
        return jsonify({'error': 'DB ì—°ê²° í•„ìš”'}), 400
    
    data = request.get_json()
    year = int(data.get('year', date.today().year))
    month = int(data.get('month', date.today().month))
    
    emp_id = session.get('user_id') if session.get('user_role') == 'parttime' else data.get('employee_id')
    
    try:
        result = _calculate_monthly_salary(emp_id, year, month)
        if not result.get('success'):
            return jsonify(result), 400
        
        breakdown = result['breakdown']
        supabase.table('salary_confirmations').upsert({
            'employee_id': emp_id,
            'year_month': f"{year}-{month:02d}",
            'total_hours': breakdown['total_hours'],
            'base_pay': breakdown['base_pay'],
            'overtime_pay': breakdown['overtime_pay'],
            'weekly_holiday_pay': breakdown['weekly_holiday_pay'],
            'full_attendance_bonus': breakdown['full_attendance_bonus'],
            'total_amount': breakdown['total_pay'],
            'confirmed_at': datetime.utcnow().isoformat()
        }, on_conflict='employee_id,year_month').execute()
        
        return jsonify({'success': True, 'message': 'ì›”ê¸‰ í™•ì • ì™„ë£Œ', 'breakdown': breakdown})
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/salary/confirmations', methods=['GET'])
@admin_required
def get_confirmations():
    """ì›”ê¸‰ í™•ì • ëª©ë¡ ì¡°íšŒ"""
    if not DB_CONNECTED:
        return jsonify({'error': 'DB ì—°ê²° í•„ìš”'}), 400
    
    year = request.args.get('year', date.today().year)
    month = request.args.get('month', date.today().month)
    year_month = f"{year}-{int(month):02d}"
    
    try:
        response = supabase.table('salary_confirmations').select('*, users(name)').eq('year_month', year_month).execute()
        return jsonify({'success': True, 'data': response.data})
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/admin/attendance', methods=['GET'])
@admin_required
def admin_get_attendance():
    """ëª¨ë“  ì§ì› ì¶œí‡´ê·¼ ì¡°íšŒ"""
    if not DB_CONNECTED:
        return jsonify({'error': 'DB ì—°ê²° í•„ìš”'}), 400
    
    year = int(request.args.get('year', date.today().year))
    month = int(request.args.get('month', date.today().month))
    
    try:
        start_date = f"{year}-{month:02d}-01"
        _, last_day = calendar.monthrange(year, month)
        end_date = f"{year}-{month:02d}-{last_day}"
        
        employees = supabase.table('users').select('*').eq('role', 'parttime').eq('enabled', True).execute()
        
        result = []
        for emp in employees.data:
            attendance = supabase.table('attendance_logs').select('*').eq('employee_id', emp['id']).gte('work_date', start_date).lte('work_date', end_date).order('work_date').execute()
            confirmation = supabase.table('salary_confirmations').select('*').eq('employee_id', emp['id']).eq('year_month', f"{year}-{month:02d}").execute()
            
            # ê¸‰ì—¬ ê³„ì‚° ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
            salary_calc = _calculate_monthly_salary(emp['id'], year, month)
            salary_breakdown = salary_calc.get('breakdown') if salary_calc.get('success') else None
            
            result.append({
                'employee': {
                    'id': emp['id'],
                    'name': emp['name'],
                    'hourly_wage': emp['hourly_wage']
                },
                'records': attendance.data,
                'is_confirmed': len(confirmation.data) > 0,
                'confirmation': confirmation.data[0] if confirmation.data else None,
                'salary_breakdown': salary_breakdown
            })
        
        return jsonify({'success': True, 'data': result, 'year_month': f"{year}-{month:02d}"})
    except Exception as e:
        return jsonify({'error': str(e)}), 500


# ==================== ì¶œí‡´ê·¼ ìˆ˜ì • ìš”ì²­ API ====================

@app.route('/api/attendance-edit-request', methods=['POST'])
@login_required
def create_edit_request():
    """ì¶œí‡´ê·¼ ìˆ˜ì • ìš”ì²­ ìƒì„± (ì§ì›ìš©)"""
    if not DB_CONNECTED:
        return jsonify({'error': 'DB ì—°ê²° í•„ìš”'}), 400
    
    if session.get('user_role') != 'parttime':
        return jsonify({'error': 'ì§ì›ë§Œ ìš”ì²­í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤'}), 403
    
    data = request.get_json()
    request_date = data.get('request_date')
    new_clock_in = data.get('new_clock_in')
    new_clock_out = data.get('new_clock_out')
    reason = data.get('reason', '').strip()
    
    if not request_date or not reason:
        return jsonify({'error': 'ë‚ ì§œì™€ ìˆ˜ì • ì‚¬ìœ ëŠ” í•„ìˆ˜ì…ë‹ˆë‹¤'}), 400
    
    emp_id = session.get('user_id')
    today = date.today()
    req_date = date.fromisoformat(request_date)
    
    # ì´ì „ ë‹¬ ìˆ˜ì • ë¶ˆê°€ (ë‹¨, í˜„ì¬ ë‹¬ ì²«ì§¸ ì£¼ì— ì†í•˜ëŠ” ì´ì „ ë‹¬ ë‚ ì§œëŠ” í—ˆìš©)
    if req_date.year < today.year or (req_date.year == today.year and req_date.month < today.month):
        # í˜„ì¬ ë‹¬ì˜ ì²« ë²ˆì§¸ ì¼ìš”ì¼ ì°¾ê¸°
        first_day_of_month = date(today.year, today.month, 1)
        days_until_sunday = (6 - first_day_of_month.weekday()) % 7
        if days_until_sunday == 0 and first_day_of_month.weekday() != 6:
            days_until_sunday = 7
        first_sunday = first_day_of_month + timedelta(days=days_until_sunday)
        
        # ì²«ì§¸ ì£¼ì˜ ì›”ìš”ì¼ (ì¼ìš”ì¼ - 6ì¼)
        first_week_monday = first_sunday - timedelta(days=6)
        
        # ìš”ì²­ ë‚ ì§œê°€ ì²«ì§¸ ì£¼ ì›”ìš”ì¼ ì´ì „ì´ë©´ ê±°ì ˆ
        if req_date < first_week_monday:
            return jsonify({'error': 'ì´ì „ ë‹¬ì˜ ê¸°ë¡ì€ ìˆ˜ì • ìš”ì²­í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤'}), 400
    
    # ë¯¸ë˜ ë‚ ì§œ ìˆ˜ì • ë¶ˆê°€
    if req_date > today:
        return jsonify({'error': 'ë¯¸ë˜ ë‚ ì§œëŠ” ìˆ˜ì • ìš”ì²­í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤'}), 400
    
    # ì˜¤ëŠ˜ ë‚ ì§œëŠ” ì§ì ‘ ìˆ˜ì • ê°€ëŠ¥í•˜ë¯€ë¡œ ìš”ì²­ ë¶ˆí•„ìš”
    if req_date == today:
        return jsonify({'error': 'ì˜¤ëŠ˜ ë‚ ì§œëŠ” ì§ì ‘ ìˆ˜ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤'}), 400
    
    try:
        # ê¸°ì¡´ pending ìš”ì²­ í™•ì¸
        existing = supabase.table('attendance_edit_requests').select('id').eq('employee_id', emp_id).eq('request_date', request_date).eq('status', 'pending').execute()
        if existing.data:
            return jsonify({'error': 'ì´ë¯¸ í•´ë‹¹ ë‚ ì§œì— ëŒ€ê¸° ì¤‘ì¸ ìš”ì²­ì´ ìˆìŠµë‹ˆë‹¤'}), 400
        
        # ê¸°ì¡´ ì¶œí‡´ê·¼ ê¸°ë¡ ì¡°íšŒ
        old_record = supabase.table('attendance_logs').select('clock_in, clock_out').eq('employee_id', emp_id).eq('work_date', request_date).execute()
        old_clock_in = old_record.data[0]['clock_in'] if old_record.data else None
        old_clock_out = old_record.data[0]['clock_out'] if old_record.data else None
        
        # ìš”ì²­ ìƒì„±
        supabase.table('attendance_edit_requests').insert({
            'employee_id': emp_id,
            'request_date': request_date,
            'old_clock_in': old_clock_in,
            'old_clock_out': old_clock_out,
            'new_clock_in': new_clock_in,
            'new_clock_out': new_clock_out,
            'reason': reason,
            'status': 'pending'
        }).execute()
        
        return jsonify({'success': True, 'message': 'ìˆ˜ì • ìš”ì²­ì´ ì „ì†¡ë˜ì—ˆìŠµë‹ˆë‹¤'})
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/attendance-edit-requests', methods=['GET'])
@admin_required
def get_edit_requests():
    """ìˆ˜ì • ìš”ì²­ ëª©ë¡ ì¡°íšŒ (ê´€ë¦¬ììš©)"""
    if not DB_CONNECTED:
        return jsonify({'error': 'DB ì—°ê²° í•„ìš”'}), 400
    
    status = request.args.get('status', 'pending')
    
    try:
        response = supabase.table('attendance_edit_requests').select('*, users(name)').eq('status', status).order('created_at', desc=True).execute()
        return jsonify({'success': True, 'data': response.data})
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/attendance-edit-request/<int:request_id>/approve', methods=['POST'])
@admin_required
def approve_edit_request(request_id):
    """ìˆ˜ì • ìš”ì²­ ìŠ¹ì¸ (ê´€ë¦¬ììš©)"""
    if not DB_CONNECTED:
        return jsonify({'error': 'DB ì—°ê²° í•„ìš”'}), 400
    
    try:
        # ìš”ì²­ ì •ë³´ ì¡°íšŒ
        req_resp = supabase.table('attendance_edit_requests').select('*').eq('id', request_id).execute()
        if not req_resp.data:
            return jsonify({'error': 'ìš”ì²­ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤'}), 404
        
        req = req_resp.data[0]
        if req['status'] != 'pending':
            return jsonify({'error': 'ì´ë¯¸ ì²˜ë¦¬ëœ ìš”ì²­ì…ë‹ˆë‹¤'}), 400
        
        emp_id = req['employee_id']
        work_date = str(req['request_date'])[:10]  # YYYY-MM-DD í˜•ì‹ë§Œ ì¶”ì¶œ
        
        # ì‹œê°„ ê°’ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬ (HH:MM:SS í˜•ì‹ìœ¼ë¡œ ë³€í™˜)
        def safe_time(val):
            if not val or str(val) in ('None', 'null', ''):
                return None
            s = str(val)
            # HH:MM:SS+00 ë˜ëŠ” HH:MM:SS í˜•ì‹ì—ì„œ HH:MM:SSë§Œ ì¶”ì¶œ
            if '+' in s:
                s = s.split('+')[0]
            if len(s) >= 8:
                return s[:8]
            if len(s) == 5:  # HH:MM í˜•ì‹ì´ë©´ :00 ì¶”ê°€
                return s + ':00'
            return s
        
        new_clock_in = safe_time(req.get('new_clock_in'))
        new_clock_out = safe_time(req.get('new_clock_out'))
        
        # ê°™ì€ ë‚ ì§œì˜ ê¸°ì¡´ approved/rejected ìš”ì²­ ì‚­ì œ (UNIQUE ì œì•½ íšŒí”¼)
        supabase.table('attendance_edit_requests').delete().eq('employee_id', emp_id).eq('request_date', work_date).neq('id', request_id).neq('status', 'pending').execute()
        
        # ì¶œí‡´ê·¼ ê¸°ë¡ ì—…ë°ì´íŠ¸
        work_date_obj = date.fromisoformat(work_date)
        is_weekend = work_date_obj.weekday() >= 5
        holiday_check = supabase.table('holidays').select('id').eq('holiday_date', work_date).execute()
        is_holiday = len(holiday_check.data) > 0
        
        existing = supabase.table('attendance_logs').select('id').eq('employee_id', emp_id).eq('work_date', work_date).execute()
        
        record_data = {
            'employee_id': emp_id,
            'work_date': work_date,
            'clock_in': new_clock_in,
            'clock_out': new_clock_out,
            'is_holiday_work': is_weekend or is_holiday,
            'updated_at': datetime.utcnow().isoformat()
        }
        
        if existing.data:
            supabase.table('attendance_logs').update(record_data).eq('id', existing.data[0]['id']).execute()
        else:
            supabase.table('attendance_logs').insert(record_data).execute()
        
        # ìš”ì²­ ìƒíƒœ ì—…ë°ì´íŠ¸
        supabase.table('attendance_edit_requests').update({
            'status': 'approved',
            'processed_at': datetime.utcnow().isoformat()
        }).eq('id', request_id).execute()
        
        return jsonify({'success': True, 'message': 'ìˆ˜ì • ìš”ì²­ì´ ìŠ¹ì¸ë˜ì—ˆìŠµë‹ˆë‹¤'})
    except Exception as e:
        import traceback
        print(f"[ìŠ¹ì¸ ì˜¤ë¥˜] request_id={request_id}, error={str(e)}")
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500


@app.route('/api/attendance-edit-request/<int:request_id>/reject', methods=['POST'])
@admin_required
def reject_edit_request(request_id):
    """ìˆ˜ì • ìš”ì²­ ê±°ì ˆ (ê´€ë¦¬ììš©)"""
    if not DB_CONNECTED:
        return jsonify({'error': 'DB ì—°ê²° í•„ìš”'}), 400
    
    data = request.get_json()
    reject_reason = data.get('reject_reason', '').strip()
    
    if not reject_reason:
        return jsonify({'error': 'ê±°ì ˆ ì‚¬ìœ ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”'}), 400
    
    try:
        req_resp = supabase.table('attendance_edit_requests').select('status').eq('id', request_id).execute()
        if not req_resp.data:
            return jsonify({'error': 'ìš”ì²­ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤'}), 404
        
        if req_resp.data[0]['status'] != 'pending':
            return jsonify({'error': 'ì´ë¯¸ ì²˜ë¦¬ëœ ìš”ì²­ì…ë‹ˆë‹¤'}), 400
        
        supabase.table('attendance_edit_requests').update({
            'status': 'rejected',
            'reject_reason': reject_reason,
            'viewed_rejection': False,
            'processed_at': datetime.utcnow().isoformat()
        }).eq('id', request_id).execute()
        
        return jsonify({'success': True, 'message': 'ìˆ˜ì • ìš”ì²­ì´ ê±°ì ˆë˜ì—ˆìŠµë‹ˆë‹¤'})
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/attendance-edit-requests/my', methods=['GET'])
@login_required
def get_my_edit_requests():
    """ë‚´ ìˆ˜ì • ìš”ì²­ ëª©ë¡ ì¡°íšŒ (ì§ì›ìš©)"""
    if not DB_CONNECTED:
        return jsonify({'error': 'DB ì—°ê²° í•„ìš”'}), 400
    
    emp_id = session.get('user_id')
    
    try:
        # ë¯¸í™•ì¸ ê±°ì ˆ ìš”ì²­ ì¡°íšŒ
        rejected = supabase.table('attendance_edit_requests').select('*').eq('employee_id', emp_id).eq('status', 'rejected').eq('viewed_rejection', False).execute()
        
        # ëŒ€ê¸° ì¤‘ì¸ ìš”ì²­ ì¡°íšŒ
        pending = supabase.table('attendance_edit_requests').select('*').eq('employee_id', emp_id).eq('status', 'pending').execute()
        
        return jsonify({
            'success': True,
            'rejected_unviewed': rejected.data,
            'pending': pending.data
        })
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/attendance-edit-request/<int:request_id>/viewed', methods=['POST'])
@login_required
def mark_rejection_viewed(request_id):
    """ê±°ì ˆ ì‚¬ìœ  í™•ì¸ ì²˜ë¦¬ (ì§ì›ìš©)"""
    if not DB_CONNECTED:
        return jsonify({'error': 'DB ì—°ê²° í•„ìš”'}), 400
    
    emp_id = session.get('user_id')
    
    try:
        supabase.table('attendance_edit_requests').update({
            'viewed_rejection': True
        }).eq('id', request_id).eq('employee_id', emp_id).execute()
        
        return jsonify({'success': True})
    except Exception as e:
        return jsonify({'error': str(e)}), 500


# ==================== ë©”ëª¨ì¥ API ====================

@app.route('/api/memos', methods=['GET'])
@admin_required
def get_memos():
    """ë©”ëª¨ ëª©ë¡ ì¡°íšŒ"""
    if not DB_CONNECTED:
        return jsonify({'error': 'DB ì—°ê²° í•„ìš”'}), 400
    try:
        response = supabase.table('memos').select('*').order('is_pinned', desc=True).order('updated_at', desc=True).execute()
        return jsonify({'success': True, 'data': response.data})
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/memos', methods=['POST'])
@admin_required
def create_memo():
    """ë©”ëª¨ ìƒì„±"""
    if not DB_CONNECTED:
        return jsonify({'error': 'DB ì—°ê²° í•„ìš”'}), 400
    data = request.get_json()
    try:
        new_memo = {
            'title': data.get('title', '').strip() or 'ì œëª© ì—†ìŒ',
            'content': data.get('content', ''),
            'is_pinned': data.get('is_pinned', False)
        }
        response = supabase.table('memos').insert(new_memo).execute()
        return jsonify({'success': True, 'data': response.data[0]})
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/memos/<int:memo_id>', methods=['PUT'])
@admin_required
def update_memo(memo_id):
    """ë©”ëª¨ ìˆ˜ì •"""
    if not DB_CONNECTED:
        return jsonify({'error': 'DB ì—°ê²° í•„ìš”'}), 400
    data = request.get_json()
    try:
        update_data = {
            'title': data.get('title', '').strip() or 'ì œëª© ì—†ìŒ',
            'content': data.get('content', ''),
            'is_pinned': data.get('is_pinned', False),
            'updated_at': datetime.utcnow().isoformat()
        }
        response = supabase.table('memos').update(update_data).eq('id', memo_id).execute()
        return jsonify({'success': True, 'data': response.data[0] if response.data else None})
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/memos/<int:memo_id>', methods=['DELETE'])
@admin_required
def delete_memo(memo_id):
    """ë©”ëª¨ ì‚­ì œ"""
    if not DB_CONNECTED:
        return jsonify({'error': 'DB ì—°ê²° í•„ìš”'}), 400
    try:
        supabase.table('memos').delete().eq('id', memo_id).execute()
        return jsonify({'success': True})
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/memos/<int:memo_id>/pin', methods=['POST'])
@admin_required
def toggle_memo_pin(memo_id):
    """ë©”ëª¨ ê³ ì •/í•´ì œ"""
    if not DB_CONNECTED:
        return jsonify({'error': 'DB ì—°ê²° í•„ìš”'}), 400
    try:
        current = supabase.table('memos').select('is_pinned').eq('id', memo_id).execute()
        if not current.data:
            return jsonify({'error': 'ë©”ëª¨ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤'}), 404
        new_pinned = not current.data[0]['is_pinned']
        supabase.table('memos').update({'is_pinned': new_pinned, 'updated_at': datetime.utcnow().isoformat()}).eq('id', memo_id).execute()
        return jsonify({'success': True, 'is_pinned': new_pinned})
    except Exception as e:
        return jsonify({'error': str(e)}), 500


# ==================== í’ˆì ˆìƒí’ˆ API ====================

@app.route('/api/out-of-stock', methods=['GET'])
@admin_required
def get_out_of_stock():
    """í’ˆì ˆìƒí’ˆ ëª©ë¡ ì¡°íšŒ"""
    if not DB_CONNECTED:
        return jsonify({'error': 'DB ì—°ê²° í•„ìš”'}), 400
    try:
        show_restocked = request.args.get('show_restocked', 'false').lower() == 'true'
        query = supabase.table('out_of_stock').select('*')
        if not show_restocked:
            query = query.eq('is_restocked', False)
        response = query.order('out_date', desc=True).execute()
        return jsonify({'success': True, 'data': response.data})
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/out-of-stock', methods=['POST'])
@admin_required
def create_out_of_stock():
    """í’ˆì ˆìƒí’ˆ ë“±ë¡"""
    if not DB_CONNECTED:
        return jsonify({'error': 'DB ì—°ê²° í•„ìš”'}), 400
    data = request.get_json()
    try:
        new_item = {
            'product_name': data.get('product_name', '').strip(),
            'out_date': data.get('out_date') or date.today().isoformat(),
            'restock_date': data.get('restock_date') or None,
            'notes': data.get('notes', ''),
            'is_restocked': False
        }
        if not new_item['product_name']:
            return jsonify({'error': 'ìƒí’ˆëª…ì€ í•„ìˆ˜ì…ë‹ˆë‹¤'}), 400
        response = supabase.table('out_of_stock').insert(new_item).execute()
        return jsonify({'success': True, 'data': response.data[0]})
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/out-of-stock/<int:item_id>', methods=['PUT'])
@admin_required
def update_out_of_stock(item_id):
    """í’ˆì ˆìƒí’ˆ ìˆ˜ì •"""
    if not DB_CONNECTED:
        return jsonify({'error': 'DB ì—°ê²° í•„ìš”'}), 400
    data = request.get_json()
    try:
        update_data = {
            'product_name': data.get('product_name', '').strip(),
            'out_date': data.get('out_date'),
            'restock_date': data.get('restock_date') or None,
            'notes': data.get('notes', ''),
            'is_restocked': data.get('is_restocked', False),
            'updated_at': datetime.utcnow().isoformat()
        }
        if not update_data['product_name']:
            return jsonify({'error': 'ìƒí’ˆëª…ì€ í•„ìˆ˜ì…ë‹ˆë‹¤'}), 400
        response = supabase.table('out_of_stock').update(update_data).eq('id', item_id).execute()
        return jsonify({'success': True, 'data': response.data[0] if response.data else None})
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/out-of-stock/<int:item_id>', methods=['DELETE'])
@admin_required
def delete_out_of_stock(item_id):
    """í’ˆì ˆìƒí’ˆ ì‚­ì œ"""
    if not DB_CONNECTED:
        return jsonify({'error': 'DB ì—°ê²° í•„ìš”'}), 400
    try:
        supabase.table('out_of_stock').delete().eq('id', item_id).execute()
        return jsonify({'success': True})
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/out-of-stock/<int:item_id>/restock', methods=['POST'])
@admin_required
def mark_restocked(item_id):
    """ì¬ì…ê³  ì™„ë£Œ ì²˜ë¦¬"""
    if not DB_CONNECTED:
        return jsonify({'error': 'DB ì—°ê²° í•„ìš”'}), 400
    try:
        supabase.table('out_of_stock').update({
            'is_restocked': True,
            'restock_date': date.today().isoformat(),
            'updated_at': datetime.utcnow().isoformat()
        }).eq('id', item_id).execute()
        return jsonify({'success': True})
    except Exception as e:
        return jsonify({'error': str(e)}), 500


# ==================== ë„ì°©ë³´ì¥ ì…ê³ ë‚´ì—­ì„œ API ====================

@app.route('/api/arrival-products', methods=['GET'])
@admin_required
def get_arrival_products():
    """ë„ì°©ë³´ì¥ ìƒí’ˆ ëª©ë¡ ì¡°íšŒ"""
    if not DB_CONNECTED:
        return jsonify({'error': 'DB ì—°ê²° í•„ìš”'}), 400
    try:
        response = supabase.table('arrival_guarantee_products').select('*').order('product_name').execute()
        return jsonify({'success': True, 'data': response.data})
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/arrival-products', methods=['POST'])
@admin_required
def create_arrival_product():
    """ë„ì°©ë³´ì¥ ìƒí’ˆ ë“±ë¡"""
    if not DB_CONNECTED:
        return jsonify({'error': 'DB ì—°ê²° í•„ìš”'}), 400
    data = request.get_json()
    try:
        new_product = {
            'product_name': data.get('product_name', '').strip(),
            'barcode': data.get('barcode', '').strip()
        }
        if not new_product['product_name'] or not new_product['barcode']:
            return jsonify({'error': 'ìƒí’ˆëª…ê³¼ ë°”ì½”ë“œëŠ” í•„ìˆ˜ì…ë‹ˆë‹¤'}), 400
        response = supabase.table('arrival_guarantee_products').insert(new_product).execute()
        return jsonify({'success': True, 'data': response.data[0]})
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/arrival-products/<int:product_id>', methods=['PUT'])
@admin_required
def update_arrival_product(product_id):
    """ë„ì°©ë³´ì¥ ìƒí’ˆ ìˆ˜ì •"""
    if not DB_CONNECTED:
        return jsonify({'error': 'DB ì—°ê²° í•„ìš”'}), 400
    data = request.get_json()
    try:
        update_data = {
            'product_name': data.get('product_name', '').strip(),
            'barcode': data.get('barcode', '').strip(),
            'updated_at': datetime.utcnow().isoformat()
        }
        if not update_data['product_name'] or not update_data['barcode']:
            return jsonify({'error': 'ìƒí’ˆëª…ê³¼ ë°”ì½”ë“œëŠ” í•„ìˆ˜ì…ë‹ˆë‹¤'}), 400
        response = supabase.table('arrival_guarantee_products').update(update_data).eq('id', product_id).execute()
        return jsonify({'success': True, 'data': response.data[0] if response.data else None})
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/arrival-products/<int:product_id>', methods=['DELETE'])
@admin_required
def delete_arrival_product(product_id):
    """ë„ì°©ë³´ì¥ ìƒí’ˆ ì‚­ì œ"""
    if not DB_CONNECTED:
        return jsonify({'error': 'DB ì—°ê²° í•„ìš”'}), 400
    try:
        supabase.table('arrival_guarantee_products').delete().eq('id', product_id).execute()
        return jsonify({'success': True})
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/arrival-customer-id', methods=['GET'])
@admin_required
def get_arrival_customer_id():
    """ê³ ê°ID ì¡°íšŒ"""
    if not DB_CONNECTED:
        return jsonify({'error': 'DB ì—°ê²° í•„ìš”'}), 400
    try:
        response = supabase.table('system_settings').select('value').eq('key', 'arrival_customer_id').execute()
        customer_id = response.data[0]['value'] if response.data else ''
        return jsonify({'success': True, 'customer_id': customer_id})
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/arrival-customer-id', methods=['POST'])
@admin_required
def save_arrival_customer_id():
    """ê³ ê°ID ì €ì¥"""
    if not DB_CONNECTED:
        return jsonify({'error': 'DB ì—°ê²° í•„ìš”'}), 400
    data = request.get_json()
    customer_id = data.get('customer_id', '').strip()
    try:
        existing = supabase.table('system_settings').select('key').eq('key', 'arrival_customer_id').execute()
        if existing.data:
            supabase.table('system_settings').update({
                'value': customer_id,
                'updated_at': datetime.utcnow().isoformat()
            }).eq('key', 'arrival_customer_id').execute()
        else:
            supabase.table('system_settings').insert({
                'key': 'arrival_customer_id',
                'value': customer_id
            }).execute()
        return jsonify({'success': True})
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/arrival-invoice/generate', methods=['POST'])
@admin_required
def generate_arrival_invoice():
    """ì…ê³ ë‚´ì—­ì„œ PDF ìƒì„± (ë¡œì»¬ í°íŠ¸ íŒŒì¼ ì§ì ‘ ì‚¬ìš©)"""
    from weasyprint import HTML
    from weasyprint.text.fonts import FontConfiguration
    from urllib.parse import quote
    import zipfile
    import os
    
    data = request.get_json()
    items = data.get('items', [])
    delivery_type = data.get('delivery_type', 'í™”ë¬¼')
    generate_separate = data.get('generate_separate', False)
    
    if not items:
        return jsonify({'error': 'ìƒí’ˆ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤'}), 400
    
    # [ìˆ˜ì •ë¨] í”„ë¡œì íŠ¸ ë‚´ë¶€ì˜ fonts í´ë” ê²½ë¡œë¥¼ ì°¾ìŠµë‹ˆë‹¤.
    # í˜„ì¬ app.pyê°€ ìˆëŠ” ìœ„ì¹˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ fonts/NanumGothic.ttfë¥¼ ì°¾ìŠµë‹ˆë‹¤.
    base_dir = os.path.dirname(os.path.abspath(__file__))
    font_path = os.path.join(base_dir, 'fonts', 'NanumGothic.ttf')
    
    # í˜¹ì‹œ ëª¨ë¥¼ ê²½ë¡œ ì˜¤ë¥˜ ë°©ì§€ë¥¼ ìœ„í•´ ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
    if not os.path.exists(font_path):
        print(f"âš ï¸ ê²½ê³ : í°íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {font_path}")
        # íŒŒì¼ì´ ì—†ìœ¼ë©´ ì‹œìŠ¤í…œ í°íŠ¸ë¡œ í´ë°±ë˜ë„ë¡ ê²½ë¡œë¥¼ ë¹„ì›Œë‘¡ë‹ˆë‹¤ (ì—ëŸ¬ ë°©ì§€)
        font_url = ""
    else:
        # WeasyPrintëŠ” file:// í”„ë¡œí† ì½œì„ ì¢‹ì•„í•©ë‹ˆë‹¤.
        font_url = f"file://{font_path}"

    def create_pdf(item_list, doc_type):
        rows_html = ""
        for idx, item in enumerate(item_list, 1):
            rows_html += f"""
            <tr>
                <td>{idx}</td>
                <td>{item.get('customer_id', '')}</td>
                <td>{item.get('arrival_date', '')}</td>
                <td>{item.get('product_name', '')}</td>
                <td>{item.get('barcode', '')}</td>
                <td>{item.get('quantity', '')}</td>
                <td>{item.get('note', '')}</td>
            </tr>
            """
        
        for idx in range(len(item_list) + 1, 11):
            rows_html += f"""
            <tr>
                <td>{idx}</td>
                <td></td>
                <td></td>
                <td></td>
                <td></td>
                <td></td>
                <td></td>
            </tr>
            """
        
        # [ìˆ˜ì •ë¨] CSSì—ì„œ ë¡œì»¬ íŒŒì¼ ê²½ë¡œë¥¼ ì§ì ‘ srcë¡œ ì§€ì •í•©ë‹ˆë‹¤.
        html_content = f"""
        <!DOCTYPE html>
        <html lang="ko">
        <head>
            <meta charset="UTF-8">
            <style>
                /* ì—¬ê¸°ì„œ ë¡œì»¬ í°íŠ¸ë¥¼ ì •ì˜í•©ë‹ˆë‹¤ */
                @font-face {{
                    font-family: 'MyNanum';
                    src: url('{font_url}') format('truetype');
                }}
                
                @page {{
                    size: A4 landscape;
                    margin: 15mm;
                }}
                body {{
                    /* ì •ì˜í•œ 'MyNanum' í°íŠ¸ë¥¼ ìš°ì„  ì ìš© */
                    font-family: 'MyNanum', 'NanumGothic', sans-serif;
                    margin: 0;
                    padding: 0;
                    word-break: keep-all;
                }}
                h1 {{
                    text-align: center;
                    font-size: 24px;
                    margin-bottom: 20px;
                    font-weight: bold;
                }}
                table {{
                    width: 100%;
                    border-collapse: collapse;
                    font-size: 11px;
                }}
                th, td {{
                    border: 1px solid #000;
                    padding: 8px 5px;
                    text-align: center;
                    vertical-align: middle;
                }}
                th {{
                    background-color: #e0e0e0;
                    font-weight: bold;
                    font-size: 12px;
                }}
                tr {{
                    height: 28px;
                }}
            </style>
        </head>
        <body>
            <h1>ì…ê³  ë‚´ì—­ì„œ({doc_type})</h1>
            <table>
                <thead>
                    <tr>
                        <th style="width: 5%;">No.</th>
                        <th style="width: 12%;">ê³ ê°ID</th>
                        <th style="width: 12%;">ì…ê³ ì˜ˆì •ì¼</th>
                        <th style="width: 30%;">ìƒí’ˆëª…</th>
                        <th style="width: 18%;">ìƒí’ˆë°”ì½”ë“œ</th>
                        <th style="width: 10%;">ìˆ˜ëŸ‰(EA)</th>
                        <th style="width: 13%;">íŠ¹ì´ì‚¬í•­</th>
                    </tr>
                </thead>
                <tbody>
                    {rows_html}
                </tbody>
            </table>
        </body>
        </html>
        """
        
        font_config = FontConfiguration()
        pdf_buffer = BytesIO()
        HTML(string=html_content).write_pdf(pdf_buffer, font_config=font_config)
        pdf_buffer.seek(0)
        return pdf_buffer
    
    # ... (íŒŒì¼ëª… ìƒì„± ë° ë‹¤ìš´ë¡œë“œ ë¡œì§ì€ ê¸°ì¡´ê³¼ ë™ì¼) ...
    def get_filename(item_list):
        if item_list:
            arrival_date = item_list[0].get('arrival_date', '')
            if len(arrival_date) >= 8:
                mmdd = arrival_date[4:8]
            else:
                mmdd = datetime.now().strftime('%m%d')
            
            if len(item_list) == 1:
                product_name = item_list[0].get('product_name', 'ìƒí’ˆ').replace(' ', '')
            else:
                product_name = f"{len(item_list)}ê°œìƒí’ˆ"
            
            return f"{mmdd}ì…ê³ ë‚´ì—­ì„œ_{product_name}.pdf"
        return "ì…ê³ ë‚´ì—­ì„œ.pdf"
    
    def send_pdf_response(buffer, filename):
        buffer.seek(0)
        response = make_response(buffer.read())
        response.headers['Content-Type'] = 'application/pdf'
        encoded_filename = quote(filename)
        response.headers['Content-Disposition'] = f"attachment; filename*=UTF-8''{encoded_filename}"
        return response
    
    def send_zip_response(buffer, filename):
        buffer.seek(0)
        response = make_response(buffer.read())
        response.headers['Content-Type'] = 'application/zip'
        encoded_filename = quote(filename)
        response.headers['Content-Disposition'] = f"attachment; filename*=UTF-8''{encoded_filename}"
        return response
    
    try:
        if generate_separate and len(items) > 1:
            zip_buffer = BytesIO()
            with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
                for item in items:
                    pdf_buffer = create_pdf([item], delivery_type)
                    filename = get_filename([item])
                    zip_file.writestr(filename, pdf_buffer.getvalue())
            
            arrival_date = items[0].get('arrival_date', '')
            mmdd = arrival_date[4:8] if len(arrival_date) >= 8 else datetime.now().strftime('%m%d')
            zip_filename = f"{mmdd}ì…ê³ ë‚´ì—­ì„œ_{len(items)}ê°œìƒí’ˆ.zip"
            
            return send_zip_response(zip_buffer, zip_filename)
        else:
            pdf_buffer = create_pdf(items, delivery_type)
            filename = get_filename(items)
            return send_pdf_response(pdf_buffer, filename)
            
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500

# ==================== ë°•ìŠ¤ ì¬ê³  ê´€ë¦¬ API ====================

@app.route('/api/box-inventory', methods=['GET'])
@login_required
def get_box_inventory():
    """ë°•ìŠ¤ ì¬ê³  ëª©ë¡ ì¡°íšŒ"""
    if not DB_CONNECTED:
        return jsonify({'error': 'DB ì—°ê²° í•„ìš”'}), 400
    
    try:
        response = supabase.table('box_inventory').select('*').order('id').execute()
        return jsonify({'success': True, 'data': response.data})
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/box-inventory', methods=['POST'])
@login_required
def save_box_inventory():
    """ë°•ìŠ¤ ì¬ê³  ì €ì¥ (Upsert)"""
    if not DB_CONNECTED:
        return jsonify({'error': 'DB ì—°ê²° í•„ìš”'}), 400
    
    data = request.get_json()
    items = data.get('items', [])
    
    if not items:
        return jsonify({'error': 'ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤'}), 400
    
    try:
        saved_count = 0
        for item in items:
            record = {
                'name_cj': item.get('name_cj', ''),
                'name_box4u': item.get('name_box4u', ''),
                'name_official': item.get('name_official', ''),
                'spec': item.get('spec', ''),
                'material': item.get('material', ''),
                'strength': item.get('strength', ''),
                'print_type': item.get('print_type', 'ë¬´ì§€'),
                'price': int(item.get('price', 0) or 0),
                'vendor': item.get('vendor', 'CJ'),
                'moq_pallet': int(item.get('moq_pallet', 0) or 0),
                'moq_piece': int(item.get('moq_piece', 0) or 0),
                'stock_cj': float(item.get('stock_cj', 0) or 0),
                'stock_hyojin': float(item.get('stock_hyojin', 0) or 0),
                'purpose': item.get('purpose', ''),
                'updated_at': datetime.utcnow().isoformat()
            }
            
            item_id = item.get('id')
            if item_id and str(item_id).isdigit():
                supabase.table('box_inventory').update(record).eq('id', int(item_id)).execute()
            else:
                supabase.table('box_inventory').insert(record).execute()
            saved_count += 1
        
        return jsonify({'success': True, 'message': f'{saved_count}ê°œ í•­ëª© ì €ì¥ ì™„ë£Œ'})
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500


@app.route('/api/box-inventory/<int:item_id>', methods=['DELETE'])
@login_required
def delete_box_inventory(item_id):
    """ë°•ìŠ¤ ì¬ê³  ì‚­ì œ"""
    if not DB_CONNECTED:
        return jsonify({'error': 'DB ì—°ê²° í•„ìš”'}), 400
    
    try:
        supabase.table('box_inventory').delete().eq('id', item_id).execute()
        return jsonify({'success': True})
    except Exception as e:
        return jsonify({'error': str(e)}), 500


# ==================== ë°ì´í„° ë¶„ì„ ê¸°ëŠ¥ ====================

def save_sales_data_to_db(df):
    """ì—‘ì…€ ë°ì´í„°ë¥¼ DBì— ì €ì¥ (ë°°ì¹˜ ì²˜ë¦¬ë¡œ ìµœì í™”)"""
    if not DB_CONNECTED or not supabase:
        return 0

    column_mapping = {
        'íŒë§¤ì‚¬ì´íŠ¸ëª…': ['íŒë§¤ì‚¬ì´íŠ¸ëª…', 'íŒë§¤ì‚¬ì´íŠ¸', 'íŒë§¤ì²˜', 'ì±„ë„', 'ì‡¼í•‘ëª°ëª…', 'ì‡¼í•‘ëª°', 'ë§ˆì¼“'],
        'ìˆ˜ì§‘ì¼': ['ìˆ˜ì§‘ì¼', 'ìˆ˜ì§‘ì¼ì'],
        'ì£¼ë¬¸ì¼': ['ì£¼ë¬¸ì¼', 'ì£¼ë¬¸ì¼ì‹œ', 'ì£¼ë¬¸ì¼ì', 'ì£¼ë¬¸ ì¼ì‹œ', 'ê²°ì œì™„ë£Œì¼'],
        'ê²°ì œì¼': ['ê²°ì œì¼', 'ê²°ì œì¼ì‹œ', 'ê²°ì œì¼ì', 'ê²°ì œ ì¼ì‹œ'],
        'ìƒí’ˆëª…': ['ìƒí’ˆëª…', 'ìƒí’ˆëª…-í™ë³´', 'ìƒí’ˆëª…(ì˜µì…˜í¬í•¨)', 'ì‡¼í•‘ëª° ìƒí’ˆëª…', 'ì£¼ë¬¸ìƒí’ˆëª…', 'ìƒí’ˆ', 'í’ˆëª…'],
        'ì£¼ë¬¸ì„ íƒì‚¬í•­': ['ì£¼ë¬¸ì„ íƒì‚¬í•­', 'ì˜µì…˜', 'ì˜µì…˜ì •ë³´', 'ì˜µì…˜ëª…', 'ì„ íƒì˜µì…˜'],
        'íŒë§¤ê°€': ['íŒë§¤ê°€', 'ì´íŒë§¤ê°€', 'ìƒí’ˆê¸ˆì•¡', 'ê²°ì œê¸ˆì•¡', 'íŒë§¤ë‹¨ê°€', 'ë‹¨ê°€', 'ê¸ˆì•¡', 'ìƒí’ˆ ê¸ˆì•¡'],
        'ì£¼ë¬¸ìˆ˜ëŸ‰': ['ì£¼ë¬¸ìˆ˜ëŸ‰', 'ì´ì£¼ë¬¸ìˆ˜ëŸ‰', 'ìˆ˜ëŸ‰', 'ì£¼ë¬¸ ìˆ˜ëŸ‰'],
        'ë°°ì†¡ë¹„ê¸ˆì•¡': ['ë°°ì†¡ë¹„ê¸ˆì•¡', 'ì´ë°°ì†¡ë¹„ê¸ˆì•¡', 'ë°°ì†¡ë¹„', 'ë°°ì†¡ë¹„ ê¸ˆì•¡'],
        'êµ¬ë§¤ìID': ['êµ¬ë§¤ìID', 'êµ¬ë§¤ìì•„ì´ë””', 'êµ¬ë§¤ì ì•„ì´ë””', 'ì£¼ë¬¸ìID', 'ì£¼ë¬¸ìì•„ì´ë””'],
        'êµ¬ë§¤ìëª…': ['êµ¬ë§¤ìëª…', 'ì£¼ë¬¸ìëª…', 'ì£¼ë¬¸ì', 'êµ¬ë§¤ì', 'êµ¬ë§¤ì ì´ë¦„'],
        'êµ¬ë§¤ìíœ´ëŒ€í°ë²ˆí˜¸': ['êµ¬ë§¤ìíœ´ëŒ€í°ë²ˆí˜¸', 'êµ¬ë§¤ìíœ´ëŒ€í°', 'êµ¬ë§¤ìì—°ë½ì²˜', 'ì£¼ë¬¸ìì—°ë½ì²˜', 'ì£¼ë¬¸ìíœ´ëŒ€í°', 'êµ¬ë§¤ì ì—°ë½ì²˜'],
        'ìˆ˜ë ¹ìëª…': ['ìˆ˜ë ¹ìëª…', 'ë°›ëŠ”ë¶„', 'ìˆ˜ì·¨ì¸', 'ìˆ˜ì·¨ì¸ëª…', 'ë°›ëŠ”ë¶„ ì´ë¦„', 'ìˆ˜ë ¹ì'],
        'ìˆ˜ë ¹ìíœ´ëŒ€í°ë²ˆí˜¸': ['ìˆ˜ë ¹ìíœ´ëŒ€í°ë²ˆí˜¸', 'ìˆ˜ë ¹ìíœ´ëŒ€í°', 'ìˆ˜ë ¹ìì—°ë½ì²˜', 'ë°›ëŠ”ë¶„ì—°ë½ì²˜', 'ìˆ˜ì·¨ì¸íœ´ëŒ€í°', 'ë°›ëŠ”ë¶„ ì—°ë½ì²˜', 'ìˆ˜ë ¹ì ì—°ë½ì²˜'],
        'ë°°ì†¡ì§€ì£¼ì†Œ': ['ë°°ì†¡ì§€ì£¼ì†Œ', 'ë°°ì†¡ì§€', 'ì£¼ì†Œ', 'ë°°ì†¡ì£¼ì†Œ', 'ë°›ëŠ”ë¶„ ì£¼ì†Œ', 'ìˆ˜ë ¹ìì£¼ì†Œ'],
        'ì£¼ë¬¸ë²ˆí˜¸': ['ì£¼ë¬¸ë²ˆí˜¸', 'ì£¼ë¬¸ê³ ìœ ë²ˆí˜¸', 'ì£¼ë¬¸ID', 'ì£¼ë¬¸No', 'ì‡¼í•‘ëª° ì£¼ë¬¸ë²ˆí˜¸', 'ì‡¼í•‘ëª°ì£¼ë¬¸ë²ˆí˜¸', 'ì£¼ë¬¸ ë²ˆí˜¸']
    }

    def find_column(df_cols, possible_names):
        for name in possible_names:
            if name in df_cols:
                return name
        return None

    batch_id = datetime.now().strftime('%Y%m%d%H%M%S')
    sales_records = []
    customer_data = {}  # phone -> {êµ¬ë§¤ìëª…, êµ¬ë§¤ìID, ì£¼ë¬¸ìˆ˜, ì´ê¸ˆì•¡, ì„ ë¬¼ìˆ˜, ì£¼ì†Œ}
    df_cols = df.columns.tolist()

    # ë””ë²„ê¹…: ì—‘ì…€ ì»¬ëŸ¼ ì¶œë ¥
    print(f"ğŸ“‹ ì—‘ì…€ ì»¬ëŸ¼ ëª©ë¡: {df_cols}")

    # ë§¤í•‘ëœ ì»¬ëŸ¼ í™•ì¸
    mapped_cols = {}
    for target_col, source_cols in column_mapping.items():
        source_col = find_column(df_cols, source_cols)
        mapped_cols[target_col] = source_col
    print(f"ğŸ“‹ ì»¬ëŸ¼ ë§¤í•‘ ê²°ê³¼: {mapped_cols}")

    # í•„ìˆ˜ ì»¬ëŸ¼ ì²´í¬
    if not mapped_cols.get('ìƒí’ˆëª…'):
        print("âš ï¸ ìƒí’ˆëª… ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
    if not mapped_cols.get('íŒë§¤ê°€'):
        print("âš ï¸ íŒë§¤ê°€ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")

    # 1ë‹¨ê³„: íŒë§¤ ë°ì´í„° ì¤€ë¹„ + ê³ ê° ë°ì´í„° ì§‘ê³„ (DB í˜¸ì¶œ ì—†ìŒ)
    for _, row in df.iterrows():
        record = {'upload_batch_id': batch_id}

        for target_col, source_cols in column_mapping.items():
            source_col = find_column(df_cols, source_cols)
            if source_col:
                value = row.get(source_col)
                if pd.isna(value):
                    value = None
                elif target_col in ['íŒë§¤ê°€', 'ë°°ì†¡ë¹„ê¸ˆì•¡']:
                    value = float(value) if value else 0
                elif target_col == 'ì£¼ë¬¸ìˆ˜ëŸ‰':
                    value = int(value) if value else 1
                elif target_col in ['ì£¼ë¬¸ì¼', 'ê²°ì œì¼', 'ìˆ˜ì§‘ì¼']:
                    if value:
                        try:
                            # Excel datetime, Timestamp, ë¬¸ìì—´ ëª¨ë‘ ì²˜ë¦¬
                            if isinstance(value, datetime):
                                value = value.isoformat()
                            elif hasattr(value, 'isoformat'):
                                value = value.isoformat()
                            else:
                                # í•œêµ­ì–´ ì˜¤ì „/ì˜¤í›„ í˜•ì‹ ì²˜ë¦¬ (ì˜ˆ: "2026-01-23 ì˜¤ì „ 1:58:36")
                                str_value = str(value)
                                if 'ì˜¤ì „' in str_value or 'ì˜¤í›„' in str_value:
                                    import re
                                    # "2026-01-23 ì˜¤ì „ 1:58:36" ë˜ëŠ” "2026-01-23 ì˜¤í›„ 1:58:36"
                                    match = re.match(r'(\d{4}-\d{2}-\d{2})\s*(ì˜¤ì „|ì˜¤í›„)\s*(\d{1,2}):(\d{2}):?(\d{2})?', str_value)
                                    if match:
                                        date_part = match.group(1)
                                        ampm = match.group(2)
                                        hour = int(match.group(3))
                                        minute = match.group(4)
                                        second = match.group(5) or '00'

                                        # ì˜¤í›„ì´ê³  12ì‹œê°€ ì•„ë‹ˆë©´ +12, ì˜¤ì „ 12ì‹œë©´ 0ì‹œë¡œ
                                        if ampm == 'ì˜¤í›„' and hour != 12:
                                            hour += 12
                                        elif ampm == 'ì˜¤ì „' and hour == 12:
                                            hour = 0

                                        value = f"{date_part}T{hour:02d}:{minute}:{second}"
                                    else:
                                        value = None
                                else:
                                    parsed = pd.to_datetime(value, errors='coerce')
                                    if pd.notna(parsed):
                                        value = parsed.isoformat()
                                    else:
                                        value = None
                        except Exception as date_err:
                            print(f"ë‚ ì§œ íŒŒì‹± ì˜¤ë¥˜: {date_err}, ì›ë³¸ê°’: {value}")
                            value = None
                else:
                    value = str(value) if value else None
                record[target_col] = value

        product_name = record.get('ìƒí’ˆëª…', '')
        selling_price = record.get('íŒë§¤ê°€', 0) or 0
        quantity = record.get('ì£¼ë¬¸ìˆ˜ëŸ‰', 1) or 1
        site_name = record.get('íŒë§¤ì‚¬ì´íŠ¸ëª…', '')

        cost = find_matching_cost(product_name)
        fee_rate = get_platform_fee_rate(site_name)
        fee = selling_price * fee_rate
        profit = (selling_price - cost - fee) * quantity

        record['ì›ê°€'] = cost
        record['ìˆ˜ìˆ˜ë£Œ'] = round(fee, 2)
        record['ìˆœì´ìµ'] = round(profit, 2)

        buyer = (record.get('êµ¬ë§¤ìëª…') or '').strip()
        recipient = (record.get('ìˆ˜ë ¹ìëª…') or '').strip()
        record['is_gift'] = buyer != recipient if (buyer and recipient) else False

        # ê³ ê° ë°ì´í„° ì§‘ê³„
        phone = record.get('êµ¬ë§¤ìíœ´ëŒ€í°ë²ˆí˜¸')
        order_number = record.get('ì£¼ë¬¸ë²ˆí˜¸')
        if phone:
            if phone not in customer_data:
                customer_data[phone] = {
                    'êµ¬ë§¤ìëª…': record.get('êµ¬ë§¤ìëª…'),
                    'êµ¬ë§¤ìID': record.get('êµ¬ë§¤ìID'),
                    'ì£¼ë¬¸ìˆ˜': 0,
                    'ì´ê¸ˆì•¡': 0,
                    'ì„ ë¬¼ìˆ˜': 0,
                    'ì£¼ì†Œ': record.get('ë°°ì†¡ì§€ì£¼ì†Œ'),
                    'ì£¼ë¬¸ì¼': record.get('ì£¼ë¬¸ì¼'),
                    'ì²˜ë¦¬ëœ_ì£¼ë¬¸ë²ˆí˜¸': set()  # ì£¼ë¬¸ë²ˆí˜¸ ì¤‘ë³µ ì²´í¬ìš©
                }
            # ì£¼ë¬¸ë²ˆí˜¸ ê¸°ì¤€ìœ¼ë¡œ ì£¼ë¬¸ìˆ˜ ì¹´ìš´íŠ¸ (ê°™ì€ ì£¼ë¬¸ë²ˆí˜¸ëŠ” 1íšŒë¡œ)
            if order_number and order_number not in customer_data[phone]['ì²˜ë¦¬ëœ_ì£¼ë¬¸ë²ˆí˜¸']:
                customer_data[phone]['ì£¼ë¬¸ìˆ˜'] += 1
                customer_data[phone]['ì²˜ë¦¬ëœ_ì£¼ë¬¸ë²ˆí˜¸'].add(order_number)
            elif not order_number:
                # ì£¼ë¬¸ë²ˆí˜¸ê°€ ì—†ëŠ” ê²½ìš° ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ ì¹´ìš´íŠ¸
                customer_data[phone]['ì£¼ë¬¸ìˆ˜'] += 1
            customer_data[phone]['ì´ê¸ˆì•¡'] += selling_price * quantity
            if record['is_gift']:
                customer_data[phone]['ì„ ë¬¼ìˆ˜'] += 1

        sales_records.append(record)

    # 2ë‹¨ê³„: ê¸°ì¡´ ê³ ê° í•œë²ˆì— ì¡°íšŒ (1ë²ˆ ì¿¼ë¦¬)
    existing_customers = {}
    if customer_data:
        try:
            phones = list(customer_data.keys())
            response = supabase.table('customers').select('*').in_('íœ´ëŒ€í°ë²ˆí˜¸', phones).execute()
            for c in (response.data or []):
                existing_customers[c['íœ´ëŒ€í°ë²ˆí˜¸']] = c
        except Exception as e:
            print(f"ê³ ê° ì¡°íšŒ ì˜¤ë¥˜: {e}")

    # 3ë‹¨ê³„: ê³ ê° ë°ì´í„° ì²˜ë¦¬ (upsert ë°©ì‹ìœ¼ë¡œ ìµœì í™”)
    upsert_customers = []
    
    for phone, data in customer_data.items():
        if phone not in existing_customers:
            # ì‹ ê·œ ê³ ê°
            upsert_customers.append({
                'íœ´ëŒ€í°ë²ˆí˜¸': phone,
                'êµ¬ë§¤ìëª…': data['êµ¬ë§¤ìëª…'],
                'êµ¬ë§¤ìID': data['êµ¬ë§¤ìID'],
                'ì²«êµ¬ë§¤ì¼': data['ì£¼ë¬¸ì¼'],
                'ìµœê·¼êµ¬ë§¤ì¼': data['ì£¼ë¬¸ì¼'],
                'ì´ì£¼ë¬¸íšŸìˆ˜': data['ì£¼ë¬¸ìˆ˜'],
                'ì´êµ¬ë§¤ê¸ˆì•¡': data['ì´ê¸ˆì•¡'],
                'ì„ ë¬¼ë°œì†¡íšŸìˆ˜': data['ì„ ë¬¼ìˆ˜'],
                'ì£¼ìš”ë°°ì†¡ì§€': data['ì£¼ì†Œ']
            })
        else:
            # ê¸°ì¡´ ê³ ê° - ëˆ„ì  ê°’ìœ¼ë¡œ upsert
            existing = existing_customers[phone]
            upsert_customers.append({
                'íœ´ëŒ€í°ë²ˆí˜¸': phone,
                'êµ¬ë§¤ìëª…': data['êµ¬ë§¤ìëª…'] or existing.get('êµ¬ë§¤ìëª…'),
                'êµ¬ë§¤ìID': data['êµ¬ë§¤ìID'] or existing.get('êµ¬ë§¤ìID'),
                'ì²«êµ¬ë§¤ì¼': existing.get('ì²«êµ¬ë§¤ì¼'),  # ê¸°ì¡´ ê°’ ìœ ì§€
                'ìµœê·¼êµ¬ë§¤ì¼': data['ì£¼ë¬¸ì¼'],
                'ì´ì£¼ë¬¸íšŸìˆ˜': (existing.get('ì´ì£¼ë¬¸íšŸìˆ˜') or 0) + data['ì£¼ë¬¸ìˆ˜'],
                'ì´êµ¬ë§¤ê¸ˆì•¡': (existing.get('ì´êµ¬ë§¤ê¸ˆì•¡') or 0) + data['ì´ê¸ˆì•¡'],
                'ì„ ë¬¼ë°œì†¡íšŸìˆ˜': (existing.get('ì„ ë¬¼ë°œì†¡íšŸìˆ˜') or 0) + data['ì„ ë¬¼ìˆ˜'],
                'ì£¼ìš”ë°°ì†¡ì§€': data['ì£¼ì†Œ'] or existing.get('ì£¼ìš”ë°°ì†¡ì§€')
            })

    # ë°°ì¹˜ upsert (1ë²ˆ ì¿¼ë¦¬ë¡œ ì²˜ë¦¬)
    if upsert_customers:
        try:
            supabase.table('customers').upsert(upsert_customers, on_conflict='íœ´ëŒ€í°ë²ˆí˜¸').execute()
            print(f"ğŸ‘¥ ê³ ê° ë°ì´í„° {len(upsert_customers)}ê±´ upsert ì™„ë£Œ")
        except Exception as e:
            print(f"ê³ ê° upsert ì˜¤ë¥˜: {e}")

    # 4ë‹¨ê³„: ì¤‘ë³µ ì²´í¬ ë° íŒë§¤ ë°ì´í„° ì €ì¥
    try:
        if not sales_records:
            return 0
            
        # ì£¼ë¬¸ë²ˆí˜¸ ê¸°ë°˜ ì¤‘ë³µ ì²´í¬ (ìµœê·¼ 7ì¼ ë°ì´í„°ë§Œ)
        order_nums = list(set([r.get('ì£¼ë¬¸ë²ˆí˜¸') for r in sales_records if r.get('ì£¼ë¬¸ë²ˆí˜¸')]))
        existing_orders = set()
        
        if order_nums:
            try:
                week_ago = (datetime.now() - timedelta(days=7)).isoformat()
                # 500ê°œì”© ë‚˜ëˆ ì„œ ì¡°íšŒ (Supabase ì œí•œ)
                for i in range(0, len(order_nums), 500):
                    batch_nums = order_nums[i:i+500]
                    response = supabase.table('sales_data').select('ì£¼ë¬¸ë²ˆí˜¸').gte('ì£¼ë¬¸ì¼', week_ago).in_('ì£¼ë¬¸ë²ˆí˜¸', batch_nums).execute()
                    for d in (response.data or []):
                        if d.get('ì£¼ë¬¸ë²ˆí˜¸'):
                            existing_orders.add(d['ì£¼ë¬¸ë²ˆí˜¸'])
            except Exception as e:
                print(f"ì¤‘ë³µ ì²´í¬ ì˜¤ë¥˜ (ë¬´ì‹œí•˜ê³  ì§„í–‰): {e}")

        # ì¤‘ë³µ ì œê±°
        if existing_orders:
            original_count = len(sales_records)
            sales_records = [r for r in sales_records if r.get('ì£¼ë¬¸ë²ˆí˜¸') not in existing_orders]
            skipped = original_count - len(sales_records)
            if skipped > 0:
                print(f"âš ï¸ ì¤‘ë³µ ì£¼ë¬¸ {skipped}ê±´ ìŠ¤í‚µ")

        if not sales_records:
            print("â„¹ï¸ ì €ì¥í•  ìƒˆ ë°ì´í„° ì—†ìŒ (ëª¨ë‘ ì¤‘ë³µ)")
            return 0

        print(f"ğŸ“Š íŒë§¤ ë°ì´í„° {len(sales_records)}ê±´ ì €ì¥ ì‹œë„...")
        if sales_records:
            sample = sales_records[0]
            print(f"   ìƒ˜í”Œ: ìƒí’ˆëª…={str(sample.get('ìƒí’ˆëª…', 'N/A'))[:30]}, ì£¼ë¬¸ì¼={sample.get('ì£¼ë¬¸ì¼', 'N/A')}")
        
        # 500ê±´ì”© ë°°ì¹˜ ì²˜ë¦¬
        batch_size = 500
        for i in range(0, len(sales_records), batch_size):
            batch = sales_records[i:i+batch_size]
            supabase.table('sales_data').insert(batch).execute()
        
        print(f"âœ… íŒë§¤ ë°ì´í„° {len(sales_records)}ê±´ DB ì €ì¥ ì„±ê³µ!")
        return len(sales_records)
    except Exception as e:
        import traceback
        print(f"âŒ íŒë§¤ ë°ì´í„° ì €ì¥ ì˜¤ë¥˜: {e}")
        traceback.print_exc()
        return 0


@app.route('/api/analytics/summary', methods=['GET'])
@admin_required
def get_analytics_summary():
    """KPI ìš”ì•½ ë°ì´í„° (í”„ë¦¬ì…‹ ë˜ëŠ” ì»¤ìŠ¤í…€ ë‚ ì§œ ë²”ìœ„)"""
    if not DB_CONNECTED:
        return jsonify({'error': 'DB ì—°ê²° í•„ìš”'}), 400

    period = request.args.get('period', 'month')
    custom_start = request.args.get('start_date')  # YYYY-MM-DD
    custom_end = request.args.get('end_date')      # YYYY-MM-DD

    try:
        today = get_kst_today()
        start_date = None
        end_date = None
        
        # ì»¤ìŠ¤í…€ ë‚ ì§œ ë²”ìœ„ê°€ ìˆìœ¼ë©´ ì‚¬ìš©
        if custom_start:
            start_date = datetime.strptime(custom_start, '%Y-%m-%d').date()
        elif period == 'day':
            start_date = today
        elif period == 'week':
            start_date = today - timedelta(days=7)
        elif period == 'month':
            start_date = today - timedelta(days=30)
        elif period == 'quarter':
            start_date = today - timedelta(days=90)
        elif period == 'half':
            start_date = today - timedelta(days=180)
        elif period == 'year':
            start_date = today - timedelta(days=365)
        # period == 'all' ì´ë©´ start_date = None
        
        if custom_end:
            end_date = datetime.strptime(custom_end, '%Y-%m-%d').date()

        query = supabase.table('sales_data').select('íŒë§¤ê°€, ì£¼ë¬¸ìˆ˜ëŸ‰, ìˆœì´ìµ, ì£¼ë¬¸ì¼')
        if start_date:
            query = query.gte('ì£¼ë¬¸ì¼', start_date.isoformat())
        if end_date:
            # end_dateì˜ ë‹¤ìŒë‚  00:00 ì´ì „ê¹Œì§€
            end_date_next = end_date + timedelta(days=1)
            query = query.lt('ì£¼ë¬¸ì¼', end_date_next.isoformat())

        response = query.execute()
        data = response.data or []

        total_revenue = sum(float(d.get('íŒë§¤ê°€', 0) or 0) * int(d.get('ì£¼ë¬¸ìˆ˜ëŸ‰', 1) or 1) for d in data)
        total_profit = sum(float(d.get('ìˆœì´ìµ', 0) or 0) for d in data)
        total_orders = len(data)
        aov = total_revenue / total_orders if total_orders > 0 else 0
        margin_rate = (total_profit / total_revenue * 100) if total_revenue > 0 else 0

        return jsonify({
            'success': True,
            'data': {
                'total_revenue': round(total_revenue, 0),
                'total_profit': round(total_profit, 0),
                'total_orders': total_orders,
                'aov': round(aov, 0),
                'margin_rate': round(margin_rate, 1)
            }
        })
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/analytics/platform', methods=['GET'])
@admin_required
def get_analytics_platform():
    """í”Œë«í¼ë³„ ë§¤ì¶œ/ìˆœì´ìµ ë¹„êµ"""
    if not DB_CONNECTED:
        return jsonify({'error': 'DB ì—°ê²° í•„ìš”'}), 400

    try:
        response = supabase.table('sales_data').select('íŒë§¤ì‚¬ì´íŠ¸ëª…, íŒë§¤ê°€, ì£¼ë¬¸ìˆ˜ëŸ‰, ìˆœì´ìµ').execute()
        data = response.data or []

        platform_stats = {}
        for d in data:
            site = d.get('íŒë§¤ì‚¬ì´íŠ¸ëª…') or 'ê¸°íƒ€'
            if site not in platform_stats:
                platform_stats[site] = {'revenue': 0, 'profit': 0, 'orders': 0}

            revenue = float(d.get('íŒë§¤ê°€', 0) or 0) * int(d.get('ì£¼ë¬¸ìˆ˜ëŸ‰', 1) or 1)
            profit = float(d.get('ìˆœì´ìµ', 0) or 0)

            platform_stats[site]['revenue'] += revenue
            platform_stats[site]['profit'] += profit
            platform_stats[site]['orders'] += 1

        result = [{'platform': k, **v} for k, v in platform_stats.items()]
        result.sort(key=lambda x: x['revenue'], reverse=True)

        return jsonify({'success': True, 'data': result})
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/analytics/time-heatmap', methods=['GET'])
@admin_required
def get_analytics_time_heatmap():
    """ìš”ì¼/ì‹œê°„ëŒ€ë³„ ì£¼ë¬¸ëŸ‰"""
    if not DB_CONNECTED:
        return jsonify({'error': 'DB ì—°ê²° í•„ìš”'}), 400

    try:
        response = supabase.table('sales_data').select('ì£¼ë¬¸ì¼').execute()
        data = response.data or []

        heatmap = {}
        days = ['ì›”', 'í™”', 'ìˆ˜', 'ëª©', 'ê¸ˆ', 'í† ', 'ì¼']

        for d in data:
            order_date = d.get('ì£¼ë¬¸ì¼')
            if order_date:
                try:
                    dt = datetime.fromisoformat(order_date.replace('Z', '+00:00'))
                    day = days[dt.weekday()]
                    hour = dt.hour

                    if day not in heatmap:
                        heatmap[day] = {}
                    if hour not in heatmap[day]:
                        heatmap[day][hour] = 0
                    heatmap[day][hour] += 1
                except:
                    pass

        return jsonify({'success': True, 'data': heatmap})
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/analytics/repurchase', methods=['GET'])
@admin_required
def get_analytics_repurchase():
    """ì¬êµ¬ë§¤ìœ¨ ë¶„ì„ (sales_data ê¸°ë°˜)"""
    if not DB_CONNECTED:
        return jsonify({'error': 'DB ì—°ê²° í•„ìš”'}), 400

    try:
        response = supabase.table('sales_data').select('êµ¬ë§¤ìíœ´ëŒ€í°ë²ˆí˜¸').execute()
        data = response.data or []

        # íœ´ëŒ€í°ë²ˆí˜¸ë³„ ì£¼ë¬¸ íšŸìˆ˜ ì§‘ê³„
        phone_counts = {}
        for d in data:
            phone = d.get('êµ¬ë§¤ìíœ´ëŒ€í°ë²ˆí˜¸')
            if phone:
                phone_counts[phone] = phone_counts.get(phone, 0) + 1

        new_customers = sum(1 for count in phone_counts.values() if count == 1)
        repeat_customers = sum(1 for count in phone_counts.values() if count > 1)

        total = new_customers + repeat_customers
        return jsonify({
            'success': True,
            'data': {
                'new_customers': new_customers,
                'repeat_customers': repeat_customers,
                'repeat_rate': round(repeat_customers / total * 100, 1) if total > 0 else 0
            }
        })
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/analytics/gift', methods=['GET'])
@admin_required
def get_analytics_gift():
    """ì„ ë¬¼í•˜ê¸° ë¹„ìœ¨ ë¶„ì„"""
    if not DB_CONNECTED:
        return jsonify({'error': 'DB ì—°ê²° í•„ìš”'}), 400

    try:
        response = supabase.table('sales_data').select('is_gift').execute()
        data = response.data or []

        self_purchase = sum(1 for d in data if not d.get('is_gift'))
        gift_purchase = sum(1 for d in data if d.get('is_gift'))

        total = self_purchase + gift_purchase
        return jsonify({
            'success': True,
            'data': {
                'self_purchase': self_purchase,
                'gift_purchase': gift_purchase,
                'gift_rate': round(gift_purchase / total * 100, 1) if total > 0 else 0
            }
        })
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/analytics/top-products', methods=['GET'])
@admin_required
def get_analytics_top_products():
    """ìƒí’ˆ+ì˜µì…˜ ë¶„ì„ (ìƒì„¸/ì „ì²´, í˜ì´ì§€ë„¤ì´ì…˜)"""
    if not DB_CONNECTED:
        return jsonify({'error': 'DB ì—°ê²° í•„ìš”'}), 400

    mode = request.args.get('mode', 'all')  # 'all' or 'detail'
    page = int(request.args.get('page', 1))
    per_page = int(request.args.get('per_page', 10))

    try:
        response = supabase.table('sales_data').select('ìƒí’ˆëª…, ì£¼ë¬¸ì„ íƒì‚¬í•­, ì£¼ë¬¸ìˆ˜ëŸ‰, íŒë§¤ê°€, íŒë§¤ì‚¬ì´íŠ¸ëª…').execute()
        data = response.data or []

        if mode == 'detail':
            # ìƒì„¸: í”Œë«í¼ë³„ë¡œ êµ¬ë¶„
            product_stats = {}
            for d in data:
                product = d.get('ìƒí’ˆëª…') or 'ì•Œ ìˆ˜ ì—†ìŒ'
                option = d.get('ì£¼ë¬¸ì„ íƒì‚¬í•­') or ''
                platform = d.get('íŒë§¤ì‚¬ì´íŠ¸ëª…') or 'ê¸°íƒ€'
                
                # í”Œë«í¼ ê°„ì†Œí™”
                if 'ì¿ íŒ¡' in platform:
                    platform = 'ì¿ íŒ¡'
                elif 'ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´' in platform or 'ë„¤ì´ë²„' in platform:
                    platform = 'ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´'
                elif '11ë²ˆê°€' in platform:
                    platform = '11ë²ˆê°€'
                elif 'ESM' in platform or 'Gë§ˆì¼“' in platform or 'ì˜¥ì…˜' in platform:
                    platform = 'ESM'
                else:
                    platform = 'ê¸°íƒ€'
                
                key = f"{product}|{option}|{platform}"
                qty = int(d.get('ì£¼ë¬¸ìˆ˜ëŸ‰', 1) or 1)
                price = float(d.get('íŒë§¤ê°€', 0) or 0)
                revenue = price * qty

                if key not in product_stats:
                    product_stats[key] = {
                        'product': f"{product} | {option}" if option else product,
                        'platform': platform,
                        'quantity': 0,
                        'revenue': 0
                    }
                product_stats[key]['quantity'] += qty
                product_stats[key]['revenue'] += revenue

            sorted_products = sorted(product_stats.values(), key=lambda x: x['quantity'], reverse=True)
        else:
            # ì „ì²´: í”Œë«í¼ êµ¬ë¶„ ì—†ì´
            product_stats = {}
            for d in data:
                product = d.get('ìƒí’ˆëª…') or 'ì•Œ ìˆ˜ ì—†ìŒ'
                option = d.get('ì£¼ë¬¸ì„ íƒì‚¬í•­') or ''
                key = f"{product} | {option}" if option else product
                qty = int(d.get('ì£¼ë¬¸ìˆ˜ëŸ‰', 1) or 1)
                price = float(d.get('íŒë§¤ê°€', 0) or 0)
                revenue = price * qty

                if key not in product_stats:
                    product_stats[key] = {'product': key, 'quantity': 0, 'revenue': 0}
                product_stats[key]['quantity'] += qty
                product_stats[key]['revenue'] += revenue

            sorted_products = sorted(product_stats.values(), key=lambda x: x['quantity'], reverse=True)

        # í˜ì´ì§€ë„¤ì´ì…˜
        total = len(sorted_products)
        total_pages = (total + per_page - 1) // per_page
        start = (page - 1) * per_page
        end = start + per_page
        paginated = sorted_products[start:end]

        # ìˆœìœ„ ì¶”ê°€
        result = []
        for i, item in enumerate(paginated):
            item['rank'] = start + i + 1
            item['revenue'] = round(item['revenue'], 0)
            result.append(item)

        return jsonify({
            'success': True,
            'data': result,
            'pagination': {
                'page': page,
                'per_page': per_page,
                'total': total,
                'total_pages': total_pages
            }
        })
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/analytics/regions', methods=['GET'])
@admin_required
def get_analytics_regions():
    """ì§€ì—­ë³„ í˜„í™© (ìˆœìœ„, ì§€ì—­, íŒë§¤ëŸ‰, ë§¤ì¶œ)"""
    if not DB_CONNECTED:
        return jsonify({'error': 'DB ì—°ê²° í•„ìš”'}), 400

    try:
        response = supabase.table('sales_data').select('ë°°ì†¡ì§€ì£¼ì†Œ, ì£¼ë¬¸ìˆ˜ëŸ‰, íŒë§¤ê°€').execute()
        data = response.data or []

        region_stats = {}
        for d in data:
            address = d.get('ë°°ì†¡ì§€ì£¼ì†Œ') or ''
            parts = address.split()
            if len(parts) >= 2:
                region = f"{parts[0]} {parts[1]}"
            elif len(parts) == 1:
                region = parts[0]
            else:
                region = 'ê¸°íƒ€'

            qty = int(d.get('ì£¼ë¬¸ìˆ˜ëŸ‰', 1) or 1)
            price = float(d.get('íŒë§¤ê°€', 0) or 0)
            revenue = price * qty

            if region not in region_stats:
                region_stats[region] = {'quantity': 0, 'revenue': 0}
            region_stats[region]['quantity'] += qty
            region_stats[region]['revenue'] += revenue

        sorted_regions = sorted(region_stats.items(), key=lambda x: x[1]['quantity'], reverse=True)[:10]
        result = [{'rank': i+1, 'region': k, 'quantity': v['quantity'], 'revenue': round(v['revenue'], 0)} for i, (k, v) in enumerate(sorted_regions)]

        return jsonify({'success': True, 'data': result})
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/analytics/hourly', methods=['GET'])
@admin_required
def get_analytics_hourly():
    """ì‹œê°„ëŒ€ë³„ í˜„í™© (ìˆœìœ„, ì‹œê°„ëŒ€, íŒë§¤ëŸ‰, ë§¤ì¶œ)"""
    if not DB_CONNECTED:
        return jsonify({'error': 'DB ì—°ê²° í•„ìš”'}), 400

    try:
        response = supabase.table('sales_data').select('ì£¼ë¬¸ì¼, ì£¼ë¬¸ìˆ˜ëŸ‰, íŒë§¤ê°€').execute()
        data = response.data or []

        hourly_stats = {}
        for d in data:
            order_date = d.get('ì£¼ë¬¸ì¼')
            if order_date:
                try:
                    dt = datetime.fromisoformat(order_date.replace('Z', '+00:00'))
                    hour = dt.hour
                    hour_key = f"{hour:02d}:00~{hour:02d}:59"

                    qty = int(d.get('ì£¼ë¬¸ìˆ˜ëŸ‰', 1) or 1)
                    price = float(d.get('íŒë§¤ê°€', 0) or 0)
                    revenue = price * qty

                    if hour_key not in hourly_stats:
                        hourly_stats[hour_key] = {'hour': hour, 'quantity': 0, 'revenue': 0}
                    hourly_stats[hour_key]['quantity'] += qty
                    hourly_stats[hour_key]['revenue'] += revenue
                except:
                    pass

        sorted_hourly = sorted(hourly_stats.items(), key=lambda x: x[1]['quantity'], reverse=True)[:10]
        result = [{'rank': i+1, 'hour': k, 'quantity': v['quantity'], 'revenue': round(v['revenue'], 0)} for i, (k, v) in enumerate(sorted_hourly)]

        return jsonify({'success': True, 'data': result})
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/analytics/customers', methods=['GET'])
@admin_required
def get_analytics_customers():
    """ê³ ê° ëª©ë¡ ì¡°íšŒ (ê²€ìƒ‰, ì •ë ¬, í˜ì´ì§€ë„¤ì´ì…˜)"""
    if not DB_CONNECTED:
        return jsonify({'error': 'DB ì—°ê²° í•„ìš”'}), 400

    search = request.args.get('search', '').strip()
    sort_by = request.args.get('sort_by', 'ì´ì£¼ë¬¸íšŸìˆ˜')
    sort_order = request.args.get('sort_order', 'desc')
    page = int(request.args.get('page', 1))
    per_page = int(request.args.get('per_page', 50))

    try:
        # ê¸°ë³¸ ì¿¼ë¦¬
        query = supabase.table('customers').select('*')
        
        # ê²€ìƒ‰ (íœ´ëŒ€í°ë²ˆí˜¸ ë˜ëŠ” êµ¬ë§¤ìëª…)
        if search:
            # Supabaseì—ì„œ or í•„í„°ë§
            query = query.or_(f"íœ´ëŒ€í°ë²ˆí˜¸.ilike.%{search}%,êµ¬ë§¤ìëª….ilike.%{search}%")
        
        # ì •ë ¬
        is_desc = sort_order == 'desc'
        query = query.order(sort_by, desc=is_desc)
        
        response = query.execute()
        all_data = response.data or []
        
        # í˜ì´ì§€ë„¤ì´ì…˜
        total = len(all_data)
        total_pages = (total + per_page - 1) // per_page
        start = (page - 1) * per_page
        end = start + per_page
        paginated = all_data[start:end]
        
        return jsonify({
            'success': True,
            'data': paginated,
            'pagination': {
                'page': page,
                'per_page': per_page,
                'total': total,
                'total_pages': total_pages
            }
        })
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500

# ==================== ë°ì´í„° ê´€ë¦¬ (ì´ˆê¸°í™”/ë¡¤ë°±) API [ì‹ ê·œ ì¶”ê°€] ====================

@app.route('/api/analytics/batches', methods=['GET'])
@admin_required
def get_analytics_batches():
    """ì—…ë¡œë“œëœ ë°ì´í„° ë°°ì¹˜ ëª©ë¡ ì¡°íšŒ (ìµœê·¼ 5000ê±´ ë°ì´í„° ê¸°ì¤€ ì§‘ê³„)"""
    if not DB_CONNECTED:
        return jsonify({'error': 'DB ì—°ê²° í•„ìš”'}), 400

    try:
        # Supabaseì—ì„œ ìµœê·¼ ë°ì´í„°ì˜ ë°°ì¹˜ IDë§Œ ê°€ì ¸ì™€ì„œ íŒŒì´ì¬ì—ì„œ ê·¸ë£¹í™” (GROUP BY ì œì•½ íšŒí”¼)
        response = supabase.table('sales_data').select('upload_batch_id, created_at').order('created_at', desc=True).limit(5000).execute()
        data = response.data or []

        batch_map = {}
        for row in data:
            batch_id = row.get('upload_batch_id')
            if not batch_id: continue
            
            if batch_id not in batch_map:
                batch_map[batch_id] = {
                    'batch_id': batch_id,
                    'created_at': row.get('created_at'),
                    'count': 0
                }
            batch_map[batch_id]['count'] += 1

        # ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜ ë° ì •ë ¬ (ìµœì‹ ìˆœ)
        result = list(batch_map.values())
        result.sort(key=lambda x: x['batch_id'], reverse=True)

        return jsonify({'success': True, 'data': result})
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/analytics/batches/<batch_id>', methods=['DELETE'])
@admin_required
def delete_analytics_batch(batch_id):
    """íŠ¹ì • ì—…ë¡œë“œ ë°°ì¹˜ ë°ì´í„° ì‚­ì œ"""
    if not DB_CONNECTED:
        return jsonify({'error': 'DB ì—°ê²° í•„ìš”'}), 400

    try:
        # 1. íŒë§¤ ë°ì´í„° ì‚­ì œ
        supabase.table('sales_data').delete().eq('upload_batch_id', batch_id).execute()
        
        return jsonify({'success': True, 'message': 'ì„ íƒí•œ ì—…ë¡œë“œ ë°ì´í„°ê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.'})
    except Exception as e:
        return jsonify({'error': str(e)}), 500
    
if __name__ == '__main__':
    port = int(os.environ.get('PORT', 5000))
    app.run(host='0.0.0.0', port=port, debug=True)