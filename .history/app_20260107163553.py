from flask import Flask, render_template, request, send_file, jsonify, session, redirect, url_for
from werkzeug.utils import secure_filename
import pandas as pd
from io import BytesIO
from datetime import datetime
import os
import json
from collections import defaultdict, OrderedDict
import numpy as np
import time
from functools import wraps

app = Flask(__name__)
app.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024  # 16MB
app.secret_key = os.environ.get('SECRET_KEY', 'playauto-secret-key-2024')

# ==================== Supabase ì„¤ì • (ì„ íƒì ) ====================
SUPABASE_URL = os.environ.get('SUPABASE_URL', '')
SUPABASE_KEY = os.environ.get('SUPABASE_KEY', '')

supabase = None
DB_CONNECTED = False

# Supabase ì—°ê²° ì‹œë„ (ì‹¤íŒ¨í•´ë„ ì•±ì€ ì •ìƒ ì‘ë™)
if SUPABASE_URL and SUPABASE_KEY:
    try:
        from supabase import create_client, Client
        supabase = create_client(SUPABASE_URL, SUPABASE_KEY)
        # ì—°ê²° í…ŒìŠ¤íŠ¸
        supabase.table('workers').select('id').limit(1).execute()
        DB_CONNECTED = True
        print("âœ… Supabase ì—°ê²° ì„±ê³µ - DB ëª¨ë“œë¡œ ì‘ë™")
    except Exception as e:
        print(f"âš ï¸  Supabase ì—°ê²° ì‹¤íŒ¨ ({e}) - JSON íŒŒì¼ ëª¨ë“œë¡œ ì‘ë™")
        supabase = None
        DB_CONNECTED = False
else:
    print("â„¹ï¸  Supabase í™˜ê²½ë³€ìˆ˜ ì—†ìŒ - JSON íŒŒì¼ ëª¨ë“œë¡œ ì‘ë™")

# ==================== ë¡œê·¸ì¸ ì„¤ì • ====================
LOGIN_ID = os.environ.get('LOGIN_ID', 'abc')
LOGIN_PW = os.environ.get('LOGIN_PW', '1234')

def login_required(f):
    """ë¡œê·¸ì¸ í•„ìˆ˜ ë°ì½”ë ˆì´í„°"""
    @wraps(f)
    def decorated_function(*args, **kwargs):
        if not session.get('logged_in'):
            return redirect(url_for('login'))
        return f(*args, **kwargs)
    return decorated_function

ALLOWED_EXTENSIONS = {'xls', 'xlsx'}
SETTINGS_FILE = 'playauto_settings_v4.json'
MARGIN_DATA_FILE = 'margin_data.json'

# ì„ì‹œ ì €ì¥ì†Œ (ì„¸ì…˜ë³„ ë¶„ë¥˜ ê²°ê³¼)
TEMP_RESULTS = {}

# ==================== ì„¤ì • ê´€ë¦¬ (ê¸°ì¡´ ë°©ì‹ ìœ ì§€) ====================

def load_settings_from_file():
    """JSON íŒŒì¼ì—ì„œ ì„¤ì • ë¡œë“œ"""
    if os.path.exists(SETTINGS_FILE):
        with open(SETTINGS_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
    return None

def save_settings_to_file(settings):
    """JSON íŒŒì¼ì— ì„¤ì • ì €ì¥"""
    with open(SETTINGS_FILE, 'w', encoding='utf-8') as f:
        json.dump(settings, f, ensure_ascii=False, indent=2)

def load_settings():
    """ì„¤ì • ë¡œë“œ (ê¸°ì¡´ ë°©ì‹ ìœ ì§€)"""
    return load_settings_from_file()

def save_settings(settings):
    """ì„¤ì • ì €ì¥ (ê¸°ì¡´ ë°©ì‹ ìœ ì§€)"""
    save_settings_to_file(settings)

# ì´ˆê¸° ì„¤ì • ë¡œë“œ
try:
    CURRENT_SETTINGS = load_settings()
    if not CURRENT_SETTINGS:
        print("âš ï¸  ê²½ê³ : playauto_settings_v4.json íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")
        CURRENT_SETTINGS = {
            "work_order": ["ì†¡ê³¼ì¥ë‹˜", "ì˜ì¬ì”¨", "ê°•ë¯¼ì”¨", "ë¶€ëª¨ë‹˜", "í•©ë°°ì†¡", "ë³µìˆ˜ì£¼ë¬¸", "ë¶„ë¥˜ì‹¤íŒ¨"],
            "work_config": {
                "ì†¡ê³¼ì¥ë‹˜": {"type": "product_specific", "products": [], "enabled": True},
                "ì˜ì¬ì”¨": {"type": "product_specific", "products": [], "enabled": True},
                "ê°•ë¯¼ì”¨": {"type": "product_specific", "products": [], "enabled": True},
                "ë¶€ëª¨ë‹˜": {"type": "product_specific", "products": [], "enabled": True},
                "í•©ë°°ì†¡": {"type": "mixed_products", "products": [], "enabled": True},
                "ë³µìˆ˜ì£¼ë¬¸": {"type": "multiple_quantity", "products": [], "enabled": True},
                "ë¶„ë¥˜ì‹¤íŒ¨": {"type": "failed", "products": [], "enabled": True}
            },
            "quantity_threshold": 2,
            "auto_learn": True,
            "min_confidence": 1.0
        }
    else:
        print(f"âœ… ì„¤ì • ë¡œë“œ ì™„ë£Œ: {len(CURRENT_SETTINGS.get('work_order', []))}ëª…ì˜ ë‹´ë‹¹ì")
except Exception as e:
    print(f"âŒ ì„¤ì • ë¡œë“œ ì˜¤ë¥˜: {e}")
    CURRENT_SETTINGS = None

def allowed_file(filename):
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS

# ==================== ì›ê°€ ë§ˆì§„í‘œ (ê¸°ì¡´ ë°©ì‹ ìœ ì§€) ====================

MARGIN_DATA = []

def load_margin_data():
    """ì›ê°€ ë§ˆì§„í‘œ ë°ì´í„° ë¡œë“œ (JSON íŒŒì¼)"""
    global MARGIN_DATA
    if os.path.exists(MARGIN_DATA_FILE):
        with open(MARGIN_DATA_FILE, 'r', encoding='utf-8') as f:
            MARGIN_DATA = json.load(f)
        print(f"âœ… ì›ê°€ ë§ˆì§„í‘œ ë¡œë“œ ì™„ë£Œ: {len(MARGIN_DATA)}ê°œ ìƒí’ˆ")
    else:
        print("âš ï¸  ê²½ê³ : margin_data.json íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")

def save_margin_data():
    """ì›ê°€ ë§ˆì§„í‘œ JSON íŒŒì¼ ì €ì¥"""
    with open(MARGIN_DATA_FILE, 'w', encoding='utf-8') as f:
        json.dump(MARGIN_DATA, f, ensure_ascii=False, indent=2)

# ì‹œì‘ ì‹œ ë¡œë“œ
load_margin_data()

# ==================== ìŠ¤íƒ€ë°°ì†¡ í•„í„° í•¨ìˆ˜ ====================

def check_star_delivery(df):
    """ìŠ¤íƒ€ë°°ì†¡ ì£¼ë¬¸ ì¡´ì¬ ì—¬ë¶€ í™•ì¸"""
    target_col = None
    for col in df.columns:
        if 'ì£¼ì˜' in str(col) and 'ë©”' in str(col):
            target_col = col
            break
    
    if target_col is None:
        return {'has_column': False, 'star_count': 0}
    
    mask = df[target_col].astype(str).str.startswith('íŒë§¤ì ìŠ¤íƒ€ë°°ì†¡', na=False)
    star_count = int(mask.sum())
    
    return {'has_column': True, 'star_count': star_count, 'column': target_col, 'mask': mask}

def filter_star_delivery(df):
    """ìŠ¤íƒ€ë°°ì†¡ ì£¼ë¬¸ í•„í„°ë§ (ì œê±°)"""
    result = check_star_delivery(df)
    
    if not result['has_column']:
        return df, 0
    
    filtered_df = df[~result['mask']]
    deleted_count = int(result['star_count'])
    
    return filtered_df, deleted_count

# ==================== ê¸°ì¡´ ë¼ìš°íŠ¸ (100% ìœ ì§€) ====================

@app.route('/login', methods=['GET', 'POST'])
def login():
    """ë¡œê·¸ì¸ í˜ì´ì§€"""
    if request.method == 'POST':
        data = request.get_json()
        user_id = data.get('id', '')
        user_pw = data.get('pw', '')
        
        if user_id == LOGIN_ID and user_pw == LOGIN_PW:
            session['logged_in'] = True
            return jsonify({'success': True})
        else:
            return jsonify({'success': False, 'error': 'ì•„ì´ë”” ë˜ëŠ” ë¹„ë°€ë²ˆí˜¸ê°€ í‹€ë ¸ìŠµë‹ˆë‹¤'})
    
    if session.get('logged_in'):
        return redirect(url_for('index'))
    
    return render_template('login.html')

@app.route('/logout')
def logout():
    """ë¡œê·¸ì•„ì›ƒ"""
    session.pop('logged_in', None)
    return redirect(url_for('login'))

@app.route('/')
@login_required
def index():
    return render_template('index.html')

@app.route('/health')
def health():
    """UptimeRobot í—¬ìŠ¤ì²´í¬ìš©"""
    return 'OK', 200

# ==================== ê¸°ì¡´ /settings ë¼ìš°íŠ¸ (ìœ ì§€) ====================

@app.route('/settings', methods=['GET'])
def get_settings_legacy():
    """í˜„ì¬ ì„¤ì • ì¡°íšŒ (ê¸°ì¡´ ë°©ì‹ - í•˜ìœ„ í˜¸í™˜)"""
    if CURRENT_SETTINGS:
        total_products = sum(
            len(cfg.get('products', [])) 
            for cfg in CURRENT_SETTINGS.get('work_config', {}).values()
        )
        
        has_file = os.path.exists(SETTINGS_FILE)
        
        return jsonify({
            'status': 'loaded',
            'workers': list(CURRENT_SETTINGS.get('work_order', [])),
            'total_products': total_products,
            'source': 'file' if has_file else 'default',
            'db_connected': DB_CONNECTED
        })
    return jsonify({
        'status': 'not_loaded', 
        'error': 'ì„¤ì •ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤',
        'db_connected': DB_CONNECTED
    })

# ==================== ê¸°ì¡´ /api/margin ë¼ìš°íŠ¸ (ìœ ì§€ + í™•ì¥) ====================

@app.route('/api/margin', methods=['GET'])
@login_required
def get_margin_data():
    """ì›ê°€ ë§ˆì§„í‘œ ë°ì´í„° ì¡°íšŒ"""
    search = request.args.get('search', '').strip()
    
    # DB ëª¨ë“œ: Supabaseì—ì„œ ì¡°íšŒ
    if DB_CONNECTED and supabase:
        try:
            query = supabase.table('margin_products').select('*')
            if search:
                query = query.ilike('ìƒí’ˆëª…', f'%{search}%')
            response = query.order('ìƒí’ˆëª…').execute()
            
            # DB ì»¬ëŸ¼ëª… â†’ JSON í˜•ì‹ ë³€í™˜
            data = []
            for item in response.data:
                data.append({
                    'id': item['id'],
                    'ìƒí’ˆëª…': item['ìƒí’ˆëª…'],
                    'ì¸ìƒì „ ìƒí’ˆê°€': item.get('ì¸ìƒì „_ìƒí’ˆê°€', 0),
                    'ì¸ìƒí›„ ìƒí’ˆê°€': item.get('ì¸ìƒí›„_ìƒí’ˆê°€', 0),
                    'ë¬¼ëŸ‰ì§€ì›': item.get('ë¬¼ëŸ‰ì§€ì›', 1),
                    'í”„ë¡œëª¨ì…˜í• ì¸ë¥ ': item.get('í”„ë¡œëª¨ì…˜í• ì¸ë¥ ', 0),
                    'ì¥ë ¤ê¸ˆë¥ ': item.get('ì¥ë ¤ê¸ˆë¥ ', 0),
                    'ë°°ì†¡ë¹„': item.get('ë°°ì†¡ë¹„', 0),
                    'ë°•ìŠ¤ë¹„': item.get('ë°•ìŠ¤ë¹„', 0),
                    'ì¸ìƒì „ ì´ ì›ê°€': item.get('ì¸ìƒì „_ì´_ì›ê°€', 0),
                    'ì¸ìƒí›„ ì´ ì›ê°€': item.get('ì¸ìƒí›„_ì´_ì›ê°€', 0),
                    'ì¸ìƒì „ ì¬ê³ ': item.get('ì¸ìƒì „_ì¬ê³ ', ''),
                    '1ë°•ìŠ¤ ìµœëŒ€ ìˆ˜ëŸ‰': item.get('ë°•ìŠ¤_ìµœëŒ€_ìˆ˜ëŸ‰', ''),
                    'ê¸°íƒ€ì‚¬í•­': item.get('ê¸°íƒ€ì‚¬í•­', '')
                })
            return jsonify({'data': data, 'total': len(data), 'source': 'db'})
        except Exception as e:
            print(f"DB ì¡°íšŒ ì‹¤íŒ¨, JSON í´ë°±: {e}")
    
    # JSON ëª¨ë“œ: íŒŒì¼ì—ì„œ ì¡°íšŒ (ê¸°ì¡´ ë°©ì‹)
    if search:
        filtered = [item for item in MARGIN_DATA if search.lower() in item['ìƒí’ˆëª…'].lower()]
        return jsonify({'data': filtered, 'total': len(filtered), 'source': 'file'})
    
    return jsonify({'data': MARGIN_DATA, 'total': len(MARGIN_DATA), 'source': 'file'})

@app.route('/api/margin', methods=['POST'])
@login_required
def create_margin_product():
    """ì›ê°€ ë§ˆì§„í‘œ ìƒí’ˆ ì¶”ê°€ (DB ëª¨ë“œë§Œ)"""
    if not DB_CONNECTED or not supabase:
        return jsonify({'error': 'DB ì—°ê²°ì´ í•„ìš”í•©ë‹ˆë‹¤', 'db_connected': False}), 400
    
    data = request.get_json()
    
    try:
        new_product = {
            'ìƒí’ˆëª…': data.get('ìƒí’ˆëª…', ''),
            'ì¸ìƒì „_ìƒí’ˆê°€': float(data.get('ì¸ìƒì „ ìƒí’ˆê°€', 0) or 0),
            'ì¸ìƒí›„_ìƒí’ˆê°€': float(data.get('ì¸ìƒí›„ ìƒí’ˆê°€', 0) or 0),
            'ë¬¼ëŸ‰ì§€ì›': float(data.get('ë¬¼ëŸ‰ì§€ì›', 1) or 1),
            'í”„ë¡œëª¨ì…˜í• ì¸ë¥ ': float(data.get('í”„ë¡œëª¨ì…˜í• ì¸ë¥ ', 0) or 0),
            'ì¥ë ¤ê¸ˆë¥ ': float(data.get('ì¥ë ¤ê¸ˆë¥ ', 0) or 0),
            'ë°°ì†¡ë¹„': float(data.get('ë°°ì†¡ë¹„', 0) or 0),
            'ë°•ìŠ¤ë¹„': float(data.get('ë°•ìŠ¤ë¹„', 0) or 0),
            'ì¸ìƒì „_ì´_ì›ê°€': float(data.get('ì¸ìƒì „ ì´ ì›ê°€', 0) or 0),
            'ì¸ìƒí›„_ì´_ì›ê°€': float(data.get('ì¸ìƒí›„ ì´ ì›ê°€', 0) or 0),
            'ì¸ìƒì „_ì¬ê³ ': str(data.get('ì¸ìƒì „ ì¬ê³ ', '')),
            'ë°•ìŠ¤_ìµœëŒ€_ìˆ˜ëŸ‰': str(data.get('1ë°•ìŠ¤ ìµœëŒ€ ìˆ˜ëŸ‰', '')),
            'ê¸°íƒ€ì‚¬í•­': str(data.get('ê¸°íƒ€ì‚¬í•­', ''))
        }
        
        response = supabase.table('margin_products').insert(new_product).execute()
        return jsonify({'success': True, 'data': response.data[0]})
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/margin/<int:product_id>', methods=['PUT'])
@login_required
def update_margin_product(product_id):
    """ì›ê°€ ë§ˆì§„í‘œ ìƒí’ˆ ìˆ˜ì • (DB ëª¨ë“œë§Œ)"""
    if not DB_CONNECTED or not supabase:
        return jsonify({'error': 'DB ì—°ê²°ì´ í•„ìš”í•©ë‹ˆë‹¤', 'db_connected': False}), 400
    
    data = request.get_json()
    
    try:
        update_data = {
            'ìƒí’ˆëª…': data.get('ìƒí’ˆëª…', ''),
            'ì¸ìƒì „_ìƒí’ˆê°€': float(data.get('ì¸ìƒì „ ìƒí’ˆê°€', 0) or 0),
            'ì¸ìƒí›„_ìƒí’ˆê°€': float(data.get('ì¸ìƒí›„ ìƒí’ˆê°€', 0) or 0),
            'ë¬¼ëŸ‰ì§€ì›': float(data.get('ë¬¼ëŸ‰ì§€ì›', 1) or 1),
            'í”„ë¡œëª¨ì…˜í• ì¸ë¥ ': float(data.get('í”„ë¡œëª¨ì…˜í• ì¸ë¥ ', 0) or 0),
            'ì¥ë ¤ê¸ˆë¥ ': float(data.get('ì¥ë ¤ê¸ˆë¥ ', 0) or 0),
            'ë°°ì†¡ë¹„': float(data.get('ë°°ì†¡ë¹„', 0) or 0),
            'ë°•ìŠ¤ë¹„': float(data.get('ë°•ìŠ¤ë¹„', 0) or 0),
            'ì¸ìƒì „_ì´_ì›ê°€': float(data.get('ì¸ìƒì „ ì´ ì›ê°€', 0) or 0),
            'ì¸ìƒí›„_ì´_ì›ê°€': float(data.get('ì¸ìƒí›„ ì´ ì›ê°€', 0) or 0),
            'ì¸ìƒì „_ì¬ê³ ': str(data.get('ì¸ìƒì „ ì¬ê³ ', '')),
            'ë°•ìŠ¤_ìµœëŒ€_ìˆ˜ëŸ‰': str(data.get('1ë°•ìŠ¤ ìµœëŒ€ ìˆ˜ëŸ‰', '')),
            'ê¸°íƒ€ì‚¬í•­': str(data.get('ê¸°íƒ€ì‚¬í•­', '')),
            'updated_at': datetime.utcnow().isoformat()
        }
        
        response = supabase.table('margin_products').update(update_data).eq('id', product_id).execute()
        return jsonify({'success': True, 'data': response.data[0] if response.data else None})
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/margin/<int:product_id>', methods=['DELETE'])
@login_required
def delete_margin_product(product_id):
    """ì›ê°€ ë§ˆì§„í‘œ ìƒí’ˆ ì‚­ì œ (DB ëª¨ë“œë§Œ)"""
    if not DB_CONNECTED or not supabase:
        return jsonify({'error': 'DB ì—°ê²°ì´ í•„ìš”í•©ë‹ˆë‹¤', 'db_connected': False}), 400
    
    try:
        supabase.table('margin_products').delete().eq('id', product_id).execute()
        return jsonify({'success': True})
    except Exception as e:
        return jsonify({'error': str(e)}), 500

# ==================== ë‹´ë‹¹ì API (ìƒˆë¡œ ì¶”ê°€) ====================

@app.route('/api/workers', methods=['GET'])
@login_required
def get_workers():
    """ë‹´ë‹¹ì ëª©ë¡ ì¡°íšŒ"""
    # DB ëª¨ë“œ
    if DB_CONNECTED and supabase:
        try:
            response = supabase.table('workers').select('*').order('sort_order').execute()
            workers = response.data
            
            # ê° ë‹´ë‹¹ìë³„ ìƒí’ˆ ê°œìˆ˜ ì¶”ê°€
            for worker in workers:
                products_resp = supabase.table('worker_products').select('id').eq('worker_id', worker['id']).execute()
                worker['product_count'] = len(products_resp.data)
            
            return jsonify({'data': workers, 'source': 'db', 'db_connected': True})
        except Exception as e:
            print(f"ë‹´ë‹¹ì DB ì¡°íšŒ ì‹¤íŒ¨: {e}")
    
    # JSON ëª¨ë“œ (í´ë°±)
    if CURRENT_SETTINGS:
        workers = []
        icons = {
            'ì†¡ê³¼ì¥ë‹˜': 'ğŸ§', 'ì˜ì¬ì”¨': 'ğŸ¯', 'íš¨ìƒ': 'ğŸœ', 'ê°•ë¯¼ì”¨': 'ğŸœ',
            'ë¶€ëª¨ë‹˜': 'â˜•', 'í•©ë°°ì†¡': 'ğŸ“¦', 'ë³µìˆ˜ì£¼ë¬¸': 'ğŸ“‹', 'ë¶„ë¥˜ì‹¤íŒ¨': 'â“'
        }
        descriptions = {
            'ì†¡ê³¼ì¥ë‹˜': 'íŒ¥ë¹™ìˆ˜ì¬ë£Œ ë° íŠ¹ì • ìƒí’ˆ ë‹´ë‹¹',
            'ì˜ì¬ì”¨': 'ë¯¸ì—ë¡œí™”ì´ë°”, ê¿€ì°¨, íŒŒìš°ì¹˜ìŒë£Œ ë‹´ë‹¹',
            'íš¨ìƒ': 'ë°±ì œ ìŒ€êµ­ìˆ˜, ë–¡êµ­ ë‹´ë‹¹',
            'ê°•ë¯¼ì”¨': 'ë°±ì œ ë¸Œëœë“œ ëª¨ë“  ìƒí’ˆ ë‹´ë‹¹',
            'ë¶€ëª¨ë‹˜': 'ìŸˆë…, ë¶€êµ­, ë¦°ì €, ì¹´í˜ì¬ë£Œ ë‹´ë‹¹',
            'í•©ë°°ì†¡': 'í•œ ì£¼ë¬¸ë²ˆí˜¸ì— ì—¬ëŸ¬ ë‹¤ë¥¸ ìƒí’ˆ',
            'ë³µìˆ˜ì£¼ë¬¸': 'í•œ ìƒí’ˆì„ 2ê°œ ì´ìƒ ì£¼ë¬¸',
            'ë¶„ë¥˜ì‹¤íŒ¨': 'ë§¤ì¹­ë˜ì§€ ì•Šì€ ìƒí’ˆ (ìˆ˜ë™ ê²€í†  í•„ìš”)'
        }
        
        for i, name in enumerate(CURRENT_SETTINGS.get('work_order', [])):
            config = CURRENT_SETTINGS.get('work_config', {}).get(name, {})
            workers.append({
                'id': i + 1,
                'name': name,
                'type': config.get('type', 'product_specific'),
                'description': descriptions.get(name, config.get('description', '')),
                'icon': icons.get(name, config.get('icon', 'ğŸ“‹')),
                'enabled': config.get('enabled', True),
                'product_count': len(config.get('products', []))
            })
        return jsonify({'data': workers, 'source': 'file', 'db_connected': False})
    
    return jsonify({'data': [], 'source': 'none', 'db_connected': False})

@app.route('/api/workers/<int:worker_id>/products', methods=['GET'])
@login_required
def get_worker_products(worker_id):
    """ë‹´ë‹¹ìë³„ ìƒí’ˆ ê·œì¹™ ì¡°íšŒ"""
    # DB ëª¨ë“œ
    if DB_CONNECTED and supabase:
        try:
            response = supabase.table('worker_products').select('*').eq('worker_id', worker_id).order('product_name').execute()
            return jsonify({'data': response.data, 'source': 'db', 'db_connected': True})
        except Exception as e:
            print(f"ìƒí’ˆ ê·œì¹™ DB ì¡°íšŒ ì‹¤íŒ¨: {e}")
    
    # JSON ëª¨ë“œ (í´ë°±)
    if CURRENT_SETTINGS:
        work_order = CURRENT_SETTINGS.get('work_order', [])
        if 0 < worker_id <= len(work_order):
            worker_name = work_order[worker_id - 1]
            config = CURRENT_SETTINGS.get('work_config', {}).get(worker_name, {})
            products = config.get('products', [])
            
            # ìƒí’ˆëª…ìœ¼ë¡œ ì •ë ¬
            sorted_products = sorted(products, key=lambda x: x.get('product_name', ''))
            
            # ID ì¶”ê°€ (ì¸ë±ìŠ¤ ê¸°ë°˜)
            result = []
            for i, p in enumerate(sorted_products):
                result.append({
                    'id': i + 1,
                    'worker_id': worker_id,
                    'brand': p.get('brand', ''),
                    'product_name': p.get('product_name', ''),
                    'order_option': p.get('order_option', 'All')
                })
            return jsonify({'data': result, 'source': 'file', 'db_connected': False})
    
    return jsonify({'data': [], 'source': 'none', 'db_connected': False})

@app.route('/api/workers/<int:worker_id>/products', methods=['POST'])
@login_required
def create_worker_product(worker_id):
    """ë‹´ë‹¹ì ìƒí’ˆ ê·œì¹™ ì¶”ê°€ (DB ëª¨ë“œë§Œ)"""
    if not DB_CONNECTED or not supabase:
        return jsonify({'error': 'DB ì—°ê²°ì´ í•„ìš”í•©ë‹ˆë‹¤', 'db_connected': False}), 400
    
    data = request.get_json()
    
    try:
        new_product = {
            'worker_id': worker_id,
            'brand': data.get('brand', ''),
            'product_name': data.get('product_name', ''),
            'order_option': data.get('order_option', 'All')
        }
        
        response = supabase.table('worker_products').insert(new_product).execute()
        return jsonify({'success': True, 'data': response.data[0]})
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/workers/<int:worker_id>/products/<int:product_id>', methods=['PUT'])
@login_required
def update_worker_product(worker_id, product_id):
    """ë‹´ë‹¹ì ìƒí’ˆ ê·œì¹™ ìˆ˜ì • (DB ëª¨ë“œë§Œ)"""
    if not DB_CONNECTED or not supabase:
        return jsonify({'error': 'DB ì—°ê²°ì´ í•„ìš”í•©ë‹ˆë‹¤', 'db_connected': False}), 400
    
    data = request.get_json()
    
    try:
        update_data = {
            'brand': data.get('brand', ''),
            'product_name': data.get('product_name', ''),
            'order_option': data.get('order_option', 'All'),
            'updated_at': datetime.utcnow().isoformat()
        }
        
        response = supabase.table('worker_products').update(update_data).eq('id', product_id).execute()
        return jsonify({'success': True, 'data': response.data[0] if response.data else None})
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/workers/<int:worker_id>/products/<int:product_id>', methods=['DELETE'])
@login_required
def delete_worker_product(worker_id, product_id):
    """ë‹´ë‹¹ì ìƒí’ˆ ê·œì¹™ ì‚­ì œ (DB ëª¨ë“œë§Œ)"""
    if not DB_CONNECTED or not supabase:
        return jsonify({'error': 'DB ì—°ê²°ì´ í•„ìš”í•©ë‹ˆë‹¤', 'db_connected': False}), 400
    
    try:
        supabase.table('worker_products').delete().eq('id', product_id).execute()
        return jsonify({'success': True})
    except Exception as e:
        return jsonify({'error': str(e)}), 500

# ==================== DB ìƒíƒœ í™•ì¸ API ====================

@app.route('/api/db-status', methods=['GET'])
@login_required
def get_db_status():
    """DB ì—°ê²° ìƒíƒœ í™•ì¸"""
    return jsonify({
        'db_connected': DB_CONNECTED,
        'mode': 'db' if DB_CONNECTED else 'file'
    })

# ==================== ê¸°ì¡´ ìŠ¤íƒ€ë°°ì†¡ í•„í„° (100% ìœ ì§€) ====================

@app.route('/upload', methods=['POST'])
def upload_file():
    """ìŠ¤íƒ€ë°°ì†¡ í•„í„°"""
    if 'file' not in request.files:
        return jsonify({'error': 'íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤'}), 400
    
    file = request.files['file']
    if file.filename == '':
        return jsonify({'error': 'íŒŒì¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”'}), 400
    
    if not allowed_file(file.filename):
        return jsonify({'error': '.xls ë˜ëŠ” .xlsx íŒŒì¼ë§Œ ê°€ëŠ¥í•©ë‹ˆë‹¤'}), 400
    
    try:
        ext = file.filename.rsplit('.', 1)[1].lower()
        if ext == 'xls':
            df = pd.read_excel(file, engine='xlrd')
        else:
            df = pd.read_excel(file, engine='openpyxl')
        
        original_count = len(df)
        
        target_col = None
        for col in df.columns:
            if 'ì£¼ì˜' in str(col) and 'ë©”' in str(col):
                target_col = col
                break
        
        if target_col is None:
            return jsonify({'error': "'ì£¼ì˜ë©”ì„¸ì§€' ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"}), 400
        
        mask = df[target_col].astype(str).str.startswith('íŒë§¤ì ìŠ¤íƒ€ë°°ì†¡', na=False)
        df_filtered = df[~mask]
        deleted_count = original_count - len(df_filtered)
        
        output = BytesIO()
        df_filtered.to_excel(output, index=False, engine='openpyxl')
        output.seek(0)
        
        original_name = secure_filename(file.filename).rsplit('.', 1)[0]
        output_filename = f"{original_name}_final.xlsx"
        
        return send_file(
            output,
            mimetype='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
            as_attachment=True,
            download_name=output_filename
        ), 200, {
            'X-Deleted-Count': str(deleted_count),
            'X-Original-Count': str(original_count)
        }
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500

# ==================== ê¸°ì¡´ ì†¡ì¥ ë¶„ë¥˜ (100% ìœ ì§€) ====================

@app.route('/classify', methods=['POST'])
def classify_orders():
    """ì†¡ì¥ ë¶„ë¥˜ - í†µê³„ì™€ í•¨ê»˜ ê²°ê³¼ ë°˜í™˜"""
    if 'file' not in request.files:
        return jsonify({'error': 'íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤'}), 400
    
    file = request.files['file']
    if file.filename == '':
        return jsonify({'error': 'íŒŒì¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”'}), 400
    
    if not allowed_file(file.filename):
        return jsonify({'error': '.xls ë˜ëŠ” .xlsx íŒŒì¼ë§Œ ê°€ëŠ¥í•©ë‹ˆë‹¤'}), 400
    
    if not CURRENT_SETTINGS:
        return jsonify({'error': 'ì„¤ì • íŒŒì¼ì„ ë¨¼ì € ë¡œë“œí•´ì£¼ì„¸ìš”'}), 400
    
    filter_star = request.form.get('filter_star', 'false').lower() == 'true'
    
    try:
        ext = file.filename.rsplit('.', 1)[1].lower()
        if ext == 'xls':
            df = pd.read_excel(file, engine='xlrd')
        else:
            df = pd.read_excel(file, engine='openpyxl')
        
        star_deleted = 0
        if filter_star:
            df, star_deleted = filter_star_delivery(df)
        
        classifier = OrderClassifierV41(CURRENT_SETTINGS)
        result_df = classifier.classify_orders_optimized(df)
        stats = classifier.get_classification_stats(result_df)
        
        if star_deleted > 0:
            stats['summary']['star_deleted'] = star_deleted
        
        session_id = f"{datetime.now().strftime('%Y%m%d%H%M%S')}_{id(result_df)}"
        TEMP_RESULTS[session_id] = {
            'df': result_df,
            'stats': stats,
            'filename': file.filename,
            'created_at': datetime.now()
        }
        
        return jsonify({
            'success': True,
            'session_id': session_id,
            'stats': stats
        })
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500

@app.route('/download/<session_id>')
def download_result(session_id):
    """ë¶„ë¥˜ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ"""
    if session_id not in TEMP_RESULTS:
        return jsonify({'error': 'ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤'}), 404
    
    result = TEMP_RESULTS[session_id]
    df = result['df']
    
    classifier = OrderClassifierV41(CURRENT_SETTINGS)
    output = classifier.export_single_sheet(df)
    
    original_name = result['filename'].rsplit('.', 1)[0]
    output_filename = f"{original_name}_ë¶„ë¥˜ì™„ë£Œ.xlsx"
    
    return send_file(
        output,
        mimetype='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
        as_attachment=True,
        download_name=output_filename
    )

# ==================== ë¶„ë¥˜ ì—”ì§„ (ì›ë³¸ 100% ìœ ì§€) ====================

class OrderClassifierV41:
    """
    í”Œë ˆì´ì˜¤í†  ì£¼ë¬¸ ë¶„ë¥˜ ì—”ì§„ v4.1
    ì›ë³¸ ë°ìŠ¤í¬í†± ì•±ì˜ ëª¨ë“  ë¡œì§ 100% ì¬í˜„
    """
    
    def __init__(self, settings):
        self.settings = settings
        self.work_order = settings.get('work_order', [])
        self.work_config = settings.get('work_config', {})
        self.quantity_threshold = settings.get('quantity_threshold', 2)
        self.auto_learn = settings.get('auto_learn', True)
        self.min_confidence = settings.get('min_confidence', 1.0)
        
    def classify_orders_optimized(self, df):
        """ìµœì í™”ëœ ì£¼ë¬¸ ë¶„ë¥˜ (ì›ë³¸ ë¡œì§)"""
        df = df.copy()
        
        # ì „ì²˜ë¦¬
        df = self._preprocess_data_optimized(df)
        
        # ë¶„ë¥˜ ì‹¤íŒ¨ ë‹´ë‹¹ìëª… ì°¾ê¸°
        failed_work = self._get_failed_work_name()
        
        # ì´ˆê¸°ê°’ ì„¤ì •
        df['ë‹´ë‹¹ì'] = failed_work
        df['ë¶„ë¥˜ê·¼ê±°'] = 'ë§¤ì¹­ ì—†ìŒ'
        df['ì‹ ë¢°ë„'] = 0.0
        
        # 1. í•©ë°°ì†¡ ì²˜ë¦¬ (ìš°ì„ ìˆœìœ„ 1)
        if 'ì£¼ë¬¸ê³ ìœ ë²ˆí˜¸' in df.columns:
            order_counts = df['ì£¼ë¬¸ê³ ìœ ë²ˆí˜¸'].value_counts()
            multi_orders = order_counts[order_counts >= 2].index
            is_multi_order = df['ì£¼ë¬¸ê³ ìœ ë²ˆí˜¸'].isin(multi_orders)
            
            combined_work = self._get_combined_work_name()
            if combined_work:
                df.loc[is_multi_order, 'ë‹´ë‹¹ì'] = combined_work
                df.loc[is_multi_order, 'ë¶„ë¥˜ê·¼ê±°'] = 'í•©ë°°ì†¡'
                df.loc[is_multi_order, 'ì‹ ë¢°ë„'] = 1.0
        
        # 2. ë³µìˆ˜ì£¼ë¬¸ ì²˜ë¦¬ (ìš°ì„ ìˆœìœ„ 2)
        multiple_work = self._get_multiple_work_name()
        if multiple_work:
            is_multiple = (df['ì£¼ë¬¸ìˆ˜ëŸ‰'] >= self.quantity_threshold) & (df['ë‹´ë‹¹ì'] == failed_work)
            df.loc[is_multiple, 'ë‹´ë‹¹ì'] = multiple_work
            df.loc[is_multiple, 'ë¶„ë¥˜ê·¼ê±°'] = 'ë³µìˆ˜ì£¼ë¬¸'
            df.loc[is_multiple, 'ì‹ ë¢°ë„'] = 1.0
        
        # 3. ìƒí’ˆë³„ ë§¤ì¹­ (ë¯¸ë¶„ë¥˜ë§Œ ëŒ€ìƒ)
        unmatched_mask = df['ë‹´ë‹¹ì'] == failed_work
        unmatched_indices = df[unmatched_mask].index
        
        if len(unmatched_indices) > 0:
            compiled_rules = self._compile_matching_rules()
            self._classify_batch(df, unmatched_indices, compiled_rules)
        
        # 4. ê²°ê³¼ ì •ë ¬
        df = self._sort_results_optimized(df)
        
        return df
    
    def _preprocess_data_optimized(self, df):
        """ë°ì´í„° ì „ì²˜ë¦¬"""
        # ìƒí’ˆëª… ì²˜ë¦¬
        if 'ìƒí’ˆëª…' in df.columns:
            df['ìƒí’ˆëª…'] = df['ìƒí’ˆëª…'].fillna('').astype(str)
        else:
            raise ValueError("í•„ìˆ˜ ì»¬ëŸ¼ 'ìƒí’ˆëª…' ì—†ìŒ")
        
        # ì£¼ë¬¸ìˆ˜ëŸ‰ ì²˜ë¦¬
        if 'ì£¼ë¬¸ìˆ˜ëŸ‰' in df.columns:
            df['ì£¼ë¬¸ìˆ˜ëŸ‰'] = pd.to_numeric(df['ì£¼ë¬¸ìˆ˜ëŸ‰'], errors='coerce').fillna(0).astype(int)
        else:
            df['ì£¼ë¬¸ìˆ˜ëŸ‰'] = 1
        
        # ì£¼ë¬¸ì„ íƒì‚¬í•­ ì²˜ë¦¬
        if 'ì£¼ë¬¸ì„ íƒì‚¬í•­' in df.columns:
            df['ì£¼ë¬¸ì„ íƒì‚¬í•­'] = df['ì£¼ë¬¸ì„ íƒì‚¬í•­'].fillna('').astype(str)
            df['full_product_name'] = df['ìƒí’ˆëª…'] + ' ' + df['ì£¼ë¬¸ì„ íƒì‚¬í•­']
        else:
            df['ì£¼ë¬¸ì„ íƒì‚¬í•­'] = ''
            df['full_product_name'] = df['ìƒí’ˆëª…']
        
        # ë¸Œëœë“œ ì¶”ì¶œ
        df['brand'] = df['ìƒí’ˆëª…'].str.split(n=1, expand=True)[0].fillna('')
        
        # ì£¼ë¬¸ê³ ìœ ë²ˆí˜¸ ì²˜ë¦¬
        if 'ì£¼ë¬¸ê³ ìœ ë²ˆí˜¸' in df.columns:
            df['ì£¼ë¬¸ê³ ìœ ë²ˆí˜¸'] = df['ì£¼ë¬¸ê³ ìœ ë²ˆí˜¸'].fillna('').astype(str)
        elif 'ì£¼ë¬¸ë²ˆí˜¸' in df.columns:
            df['ì£¼ë¬¸ê³ ìœ ë²ˆí˜¸'] = df['ì£¼ë¬¸ë²ˆí˜¸'].fillna('').astype(str)
        else:
            df['ì£¼ë¬¸ê³ ìœ ë²ˆí˜¸'] = np.arange(len(df)).astype(str)
        
        return df
    
    def _compile_matching_rules(self):
        """ë§¤ì¹­ ê·œì¹™ ì»´íŒŒì¼"""
        rules = []
        for work_name in self.work_order:
            work_config = self.work_config.get(work_name, {})
            if work_config.get('type') != 'product_specific':
                continue
            
            for product in work_config.get('products', []):
                rules.append({
                    'work_name': work_name,
                    'brand': product.get('brand', ''),
                    'product_name': product.get('product_name', ''),
                    'order_option': product.get('order_option', 'All')
                })
        return rules
    
    def _classify_batch(self, df, indices, rules):
        """ë°°ì¹˜ ë¶„ë¥˜"""
        for idx in indices:
            row = df.loc[idx]
            
            for rule in rules:
                if self._match_rule(row, rule):
                    df.at[idx, 'ë‹´ë‹¹ì'] = rule['work_name']
                    df.at[idx, 'ë¶„ë¥˜ê·¼ê±°'] = f"ë§¤ì¹­: {rule['brand']} {rule['product_name']}"
                    df.at[idx, 'ì‹ ë¢°ë„'] = 1.0
                    break
    
    def _match_rule(self, row, rule):
        """ê·œì¹™ ë§¤ì¹­"""
        # ë¸Œëœë“œ ì²´í¬
        if rule['brand'] and rule['brand'] != 'All':
            if rule['brand'] not in row['brand']:
                return False
        
        # ìƒí’ˆëª… ì²´í¬
        if rule['product_name'] != 'All':
            if rule['product_name'] not in row['ìƒí’ˆëª…']:
                return False
        
        # ì£¼ë¬¸ì„ íƒì‚¬í•­ ì²´í¬
        if rule['order_option'] != 'All':
            if rule['order_option'] not in row['ì£¼ë¬¸ì„ íƒì‚¬í•­']:
                return False
        
        return True
    
    def _sort_results_optimized(self, df):
        """ê²°ê³¼ ì •ë ¬"""
        priority_map = {name: i for i, name in enumerate(self.work_order)}
        df['priority'] = df['ë‹´ë‹¹ì'].map(priority_map)
        
        combined_work = self._get_combined_work_name()
        
        sorted_groups = []
        for work_name in self.work_order:
            work_df = df[df['ë‹´ë‹¹ì'] == work_name].copy()
            
            if len(work_df) == 0:
                continue
            
            if work_name == combined_work:
                work_df = work_df.sort_values(['ì£¼ë¬¸ê³ ìœ ë²ˆí˜¸'])
            else:
                work_df = work_df.sort_values(['full_product_name'])
            
            sorted_groups.append(work_df)
        
        if sorted_groups:
            sorted_df = pd.concat(sorted_groups, ignore_index=True)
            sorted_df = sorted_df.drop(['priority'], axis=1)
        else:
            sorted_df = df
        
        return sorted_df
    
    def get_classification_stats(self, df):
        """ë¶„ë¥˜ í†µê³„ ê³„ì‚°"""
        total_orders = len(df)
        stats = {
            'workers': [],
            'summary': {}
        }
        
        current_row = 1
        
        for work_name in self.work_order:
            work_data = df[df['ë‹´ë‹¹ì'] == work_name]
            count = len(work_data)
            
            config = self.work_config.get(work_name, {})
            icon = config.get('icon', 'ğŸ“‹')
            
            if count > 0:
                start_row = current_row
                end_row = current_row + count - 1
                row_range = f"{start_row} ~ {end_row}"
                current_row = end_row + 1
            else:
                row_range = "-"
            
            stats['workers'].append({
                'name': work_name,
                'count': count,
                'percentage': round(count / total_orders * 100, 1) if total_orders > 0 else 0,
                'icon': icon,
                'range': row_range
            })
        
        # ìš”ì•½ í†µê³„
        failed_work = self._get_failed_work_name()
        unmatched_count = len(df[df['ë‹´ë‹¹ì'] == failed_work])
        success_count = total_orders - unmatched_count
        auto_rate = round(success_count / total_orders * 100, 1) if total_orders > 0 else 0
        
        stats['summary'] = {
            'total_orders': total_orders,
            'success_count': success_count,
            'failed_count': unmatched_count,
            'auto_classification_rate': auto_rate
        }
        
        return stats
    
    def export_single_sheet(self, df):
        """ë‹¨ì¼ ì‹œíŠ¸ ì—‘ì…€ ë‚´ë³´ë‚´ê¸°"""
        output = BytesIO()
        
        export_df = df.copy()
        temp_cols = ['full_product_name', 'brand', 'priority', 'ë‹´ë‹¹ì', 'ë¶„ë¥˜ê·¼ê±°', 'ì‹ ë¢°ë„']
        for col in temp_cols:
            if col in export_df.columns:
                export_df = export_df.drop(columns=[col])
        
        export_df.to_excel(output, sheet_name='ë¶„ë¥˜ê²°ê³¼', index=False, engine='openpyxl')
        
        output.seek(0)
        return output
    
    def _get_failed_work_name(self):
        """ë¶„ë¥˜ì‹¤íŒ¨ ë‹´ë‹¹ìëª…"""
        for work_name, config in self.work_config.items():
            if config.get('type') == 'failed':
                return work_name
        return 'ë¶„ë¥˜ì‹¤íŒ¨'
    
    def _get_combined_work_name(self):
        """í•©ë°°ì†¡ ë‹´ë‹¹ìëª…"""
        for work_name, config in self.work_config.items():
            if config.get('type') == 'mixed_products':
                return work_name
        return None
    
    def _get_multiple_work_name(self):
        """ë³µìˆ˜ì£¼ë¬¸ ë‹´ë‹¹ìëª…"""
        for work_name, config in self.work_config.items():
            if config.get('type') == 'multiple_quantity':
                return work_name
        return None


if __name__ == '__main__':
    port = int(os.environ.get('PORT', 5000))
    app.run(host='0.0.0.0', port=port, debug=True)