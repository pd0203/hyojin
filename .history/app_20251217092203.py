from flask import Flask, render_template, request, send_file, jsonify, session
from werkzeug.utils import secure_filename
import pandas as pd
from io import BytesIO
from datetime import datetime
import os
import json
from collections import defaultdict, OrderedDict
import numpy as np
import time

app = Flask(__name__)
app.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024  # 16MB
app.secret_key = os.environ.get('SECRET_KEY', 'playauto-secret-key-2024')

ALLOWED_EXTENSIONS = {'xls', 'xlsx'}
SETTINGS_FILE = 'playauto_settings_v4.json'

# ì„ì‹œ ì €ì¥ì†Œ (ì„¸ì…˜ë³„ ë¶„ë¥˜ ê²°ê³¼)
TEMP_RESULTS = {}

# ==================== ì„¤ì • ê´€ë¦¬ ====================

def load_settings():
    """ì„¤ì • íŒŒì¼ ë¡œë“œ"""
    if os.path.exists(SETTINGS_FILE):
        with open(SETTINGS_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
    return None

def save_settings(settings):
    """ì„¤ì • íŒŒì¼ ì €ì¥"""
    with open(SETTINGS_FILE, 'w', encoding='utf-8') as f:
        json.dump(settings, f, ensure_ascii=False, indent=2)

# ì´ˆê¸° ì„¤ì • ë¡œë“œ
try:
    CURRENT_SETTINGS = load_settings()
    if not CURRENT_SETTINGS:
        print("âš ï¸  ê²½ê³ : playauto_settings_v4.json íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")
        CURRENT_SETTINGS = {
            "work_order": ["ì†¡ê³¼ì¥ë‹˜", "ì˜ì¬ì”¨", "ê°•ë¯¼ì”¨", "ë¶€ëª¨ë‹˜", "í•©ë°°ì†¡", "ë³µìˆ˜ì£¼ë¬¸", "ë¶„ë¥˜ì‹¤íŒ¨"],
            "work_config": {
                "ì†¡ê³¼ì¥ë‹˜": {"type": "product_specific", "products": [], "enabled": True},
                "ì˜ì¬ì”¨": {"type": "product_specific", "products": [], "enabled": True},
                "ê°•ë¯¼ì”¨": {"type": "product_specific", "products": [], "enabled": True},
                "ë¶€ëª¨ë‹˜": {"type": "product_specific", "products": [], "enabled": True},
                "í•©ë°°ì†¡": {"type": "mixed_products", "products": [], "enabled": True},
                "ë³µìˆ˜ì£¼ë¬¸": {"type": "multiple_quantity", "products": [], "enabled": True},
                "ë¶„ë¥˜ì‹¤íŒ¨": {"type": "failed", "products": [], "enabled": True}
            },
            "quantity_threshold": 2,
            "auto_learn": True,
            "min_confidence": 1.0
        }
    else:
        print(f"âœ… ì„¤ì • ë¡œë“œ ì™„ë£Œ: {len(CURRENT_SETTINGS.get('work_order', []))}ëª…ì˜ ë‹´ë‹¹ì")
except Exception as e:
    print(f"âŒ ì„¤ì • ë¡œë“œ ì˜¤ë¥˜: {e}")
    CURRENT_SETTINGS = None

def allowed_file(filename):
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS

# ==================== ë¼ìš°íŠ¸ ====================

@app.route('/')
def index():
    return render_template('index.html')

@app.route('/health')
def health():
    """UptimeRobot í—¬ìŠ¤ì²´í¬ìš©"""
    return 'OK', 200

@app.route('/upload', methods=['POST'])
def upload_file():
    """ìŠ¤íƒ€ë°°ì†¡ í•„í„°"""
    if 'file' not in request.files:
        return jsonify({'error': 'íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤'}), 400
    
    file = request.files['file']
    if file.filename == '':
        return jsonify({'error': 'íŒŒì¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”'}), 400
    
    if not allowed_file(file.filename):
        return jsonify({'error': '.xls ë˜ëŠ” .xlsx íŒŒì¼ë§Œ ê°€ëŠ¥í•©ë‹ˆë‹¤'}), 400
    
    try:
        ext = file.filename.rsplit('.', 1)[1].lower()
        if ext == 'xls':
            df = pd.read_excel(file, engine='xlrd')
        else:
            df = pd.read_excel(file, engine='openpyxl')
        
        original_count = len(df)
        
        target_col = None
        for col in df.columns:
            if 'ì£¼ì˜' in str(col) and 'ë©”' in str(col):
                target_col = col
                break
        
        if target_col is None:
            return jsonify({'error': "'ì£¼ì˜ë©”ì„¸ì§€' ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"}), 400
        
        mask = df[target_col].astype(str).str.startswith('íŒë§¤ì ìŠ¤íƒ€ë°°ì†¡', na=False)
        df_filtered = df[~mask]
        deleted_count = original_count - len(df_filtered)
        
        output = BytesIO()
        df_filtered.to_excel(output, index=False, engine='openpyxl')
        output.seek(0)
        
        original_name = secure_filename(file.filename).rsplit('.', 1)[0]
        timestamp = datetime.now().strftime("%H%M%S")
        output_filename = f"{original_name}_filtered_{timestamp}.xlsx"
        
        return send_file(
            output,
            mimetype='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
            as_attachment=True,
            download_name=output_filename
        ), 200, {
            'X-Deleted-Count': str(deleted_count),
            'X-Original-Count': str(original_count)
        }
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/classify', methods=['POST'])
def classify_orders():
    """ì†¡ì¥ ë¶„ë¥˜ - í†µê³„ì™€ í•¨ê»˜ ê²°ê³¼ ë°˜í™˜"""
    if 'file' not in request.files:
        return jsonify({'error': 'íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤'}), 400
    
    file = request.files['file']
    if file.filename == '':
        return jsonify({'error': 'íŒŒì¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”'}), 400
    
    if not allowed_file(file.filename):
        return jsonify({'error': '.xls ë˜ëŠ” .xlsx íŒŒì¼ë§Œ ê°€ëŠ¥í•©ë‹ˆë‹¤'}), 400
    
    if not CURRENT_SETTINGS:
        return jsonify({'error': 'ì„¤ì • íŒŒì¼ì„ ë¨¼ì € ë¡œë“œí•´ì£¼ì„¸ìš”'}), 400
    
    try:
        ext = file.filename.rsplit('.', 1)[1].lower()
        if ext == 'xls':
            df = pd.read_excel(file, engine='xlrd')
        else:
            df = pd.read_excel(file, engine='openpyxl')
        
        # ì›ë³¸ ë¶„ë¥˜ ì—”ì§„ ì‚¬ìš©
        classifier = OrderClassifierV41(CURRENT_SETTINGS)
        classified_df = classifier.classify_orders_optimized(df)
        
        # í†µê³„ ê³„ì‚°
        stats = classifier.calculate_statistics(classified_df)
        
        # ì—‘ì…€ íŒŒì¼ ìƒì„±
        output = classifier.export_to_excel(classified_df)
        
        original_name = secure_filename(file.filename).rsplit('.', 1)[0]
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_filename = f"{original_name}_classified.xlsx"
        
        # ì„ì‹œ ì €ì¥ (ë‹¤ìš´ë¡œë“œìš©)
        result_id = f"{timestamp}_{id(output)}"
        output_copy = BytesIO(output.getvalue())
        TEMP_RESULTS[result_id] = {
            'file': output_copy,
            'filename': output_filename,
            'created': datetime.now()
        }
        
        # ì˜¤ë˜ëœ ê²°ê³¼ ì •ë¦¬ (1ì‹œê°„ ì´ìƒ)
        cleanup_old_results()
        
        return jsonify({
            'success': True,
            'result_id': result_id,
            'filename': output_filename,
            'stats': stats
        })
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/download/<result_id>')
def download_result(result_id):
    """ë¶„ë¥˜ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ"""
    if result_id not in TEMP_RESULTS:
        return jsonify({'error': 'ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ë¶„ë¥˜í•´ì£¼ì„¸ìš”.'}), 404
    
    result = TEMP_RESULTS[result_id]
    result['file'].seek(0)
    
    return send_file(
        BytesIO(result['file'].getvalue()),
        mimetype='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
        as_attachment=True,
        download_name=result['filename']
    )


def cleanup_old_results():
    """1ì‹œê°„ ì´ìƒ ëœ ê²°ê³¼ ì •ë¦¬"""
    now = datetime.now()
    to_delete = []
    for result_id, result in TEMP_RESULTS.items():
        if (now - result['created']).seconds > 3600:
            to_delete.append(result_id)
    for result_id in to_delete:
        del TEMP_RESULTS[result_id]


@app.route('/settings', methods=['GET'])
def get_settings():
    """í˜„ì¬ ì„¤ì • ì¡°íšŒ"""
    if CURRENT_SETTINGS:
        total_products = sum(
            len(cfg.get('products', [])) 
            for cfg in CURRENT_SETTINGS.get('work_config', {}).values()
        )
        
        has_file = os.path.exists(SETTINGS_FILE)
        
        return jsonify({
            'status': 'loaded',
            'workers': list(CURRENT_SETTINGS.get('work_order', [])),
            'total_products': total_products,
            'source': 'file' if has_file else 'default'
        })
    return jsonify({
        'status': 'not_loaded', 
        'error': 'ì„¤ì •ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤'
    })


# ==================== ë¶„ë¥˜ ì—”ì§„ (ì›ë³¸ 100% ì¬í˜„) ====================

class OrderClassifierV41:
    """
    í”Œë ˆì´ì˜¤í†  ì£¼ë¬¸ ë¶„ë¥˜ ì—”ì§„ v4.1
    ì›ë³¸ ë°ìŠ¤í¬í†± ì•±ì˜ ëª¨ë“  ë¡œì§ 100% ì¬í˜„
    """
    
    def __init__(self, settings):
        self.settings = settings
        self.work_order = settings.get('work_order', [])
        self.work_config = settings.get('work_config', {})
        self.quantity_threshold = settings.get('quantity_threshold', 2)
        self.auto_learn = settings.get('auto_learn', True)
        self.min_confidence = settings.get('min_confidence', 1.0)
        
    def classify_orders_optimized(self, df):
        """ìµœì í™”ëœ ì£¼ë¬¸ ë¶„ë¥˜ (ì›ë³¸ ë¡œì§)"""
        df = df.copy()
        
        # ì „ì²˜ë¦¬
        df = self._preprocess_data_optimized(df)
        
        # ê¸°ë³¸ê°’ ì„¤ì •
        failed_work = self._get_failed_work_name()
        df['ë‹´ë‹¹ì'] = failed_work
        df['ë¶„ë¥˜ê·¼ê±°'] = 'ë§¤ì¹­ ì—†ìŒ'
        df['ì‹ ë¢°ë„'] = 0.0
        
        # 1. í•©ë°°ì†¡ íŒë³„
        if 'ì£¼ë¬¸ê³ ìœ ë²ˆí˜¸' in df.columns:
            order_counts = df['ì£¼ë¬¸ê³ ìœ ë²ˆí˜¸'].value_counts()
            multi_orders = order_counts[order_counts >= 2].index
            is_multi_order = df['ì£¼ë¬¸ê³ ìœ ë²ˆí˜¸'].isin(multi_orders)
            
            combined_work = self._get_combined_work_name()
            if combined_work:
                df.loc[is_multi_order, 'ë‹´ë‹¹ì'] = combined_work
                df.loc[is_multi_order, 'ë¶„ë¥˜ê·¼ê±°'] = 'í•©ë°°ì†¡'
                df.loc[is_multi_order, 'ì‹ ë¢°ë„'] = 1.0
        
        # 2. ë³µìˆ˜ì£¼ë¬¸ íŒë³„
        multiple_work = self._get_multiple_work_name()
        if multiple_work:
            is_multiple = (df['ì£¼ë¬¸ìˆ˜ëŸ‰'] >= self.quantity_threshold) & (df['ë‹´ë‹¹ì'] == failed_work)
            df.loc[is_multiple, 'ë‹´ë‹¹ì'] = multiple_work
            df.loc[is_multiple, 'ë¶„ë¥˜ê·¼ê±°'] = 'ë³µìˆ˜ì£¼ë¬¸'
            df.loc[is_multiple, 'ì‹ ë¢°ë„'] = 1.0
        
        # 3. ìƒí’ˆë³„ ë§¤ì¹­
        unmatched_mask = df['ë‹´ë‹¹ì'] == failed_work
        unmatched_indices = df[unmatched_mask].index
        
        if len(unmatched_indices) > 0:
            compiled_rules = self._compile_matching_rules()
            self._classify_batch(df, unmatched_indices, compiled_rules)
        
        # 4. ì •ë ¬ (work_order ìˆœì„œ + ê° ë‹´ë‹¹ìë³„ ê°€ë‚˜ë‹¤ìˆœ)
        df = self._sort_results_optimized(df)
        
        return df
    
    def _preprocess_data_optimized(self, df):
        """ë°ì´í„° ì „ì²˜ë¦¬"""
        # ìƒí’ˆëª… ì²˜ë¦¬
        if 'ìƒí’ˆëª…' in df.columns:
            df['ìƒí’ˆëª…'] = df['ìƒí’ˆëª…'].fillna('').astype(str)
        else:
            raise ValueError("í•„ìˆ˜ ì»¬ëŸ¼ 'ìƒí’ˆëª…' ì—†ìŒ")
        
        # ì£¼ë¬¸ìˆ˜ëŸ‰ ì²˜ë¦¬
        if 'ì£¼ë¬¸ìˆ˜ëŸ‰' in df.columns:
            df['ì£¼ë¬¸ìˆ˜ëŸ‰'] = pd.to_numeric(df['ì£¼ë¬¸ìˆ˜ëŸ‰'], errors='coerce').fillna(0).astype(int)
        else:
            df['ì£¼ë¬¸ìˆ˜ëŸ‰'] = 1
        
        # ì£¼ë¬¸ì„ íƒì‚¬í•­ ì²˜ë¦¬
        if 'ì£¼ë¬¸ì„ íƒì‚¬í•­' in df.columns:
            df['ì£¼ë¬¸ì„ íƒì‚¬í•­'] = df['ì£¼ë¬¸ì„ íƒì‚¬í•­'].fillna('').astype(str)
            df['full_product_name'] = df['ìƒí’ˆëª…'] + ' ' + df['ì£¼ë¬¸ì„ íƒì‚¬í•­']
        else:
            df['ì£¼ë¬¸ì„ íƒì‚¬í•­'] = ''
            df['full_product_name'] = df['ìƒí’ˆëª…']
        
        # ë¸Œëœë“œ ì¶”ì¶œ
        df['brand'] = df['ìƒí’ˆëª…'].str.split(n=1, expand=True)[0].fillna('')
        
        # ì£¼ë¬¸ë²ˆí˜¸ ì²˜ë¦¬
        if 'ì£¼ë¬¸ê³ ìœ ë²ˆí˜¸' in df.columns:
            df['ì£¼ë¬¸ê³ ìœ ë²ˆí˜¸'] = df['ì£¼ë¬¸ê³ ìœ ë²ˆí˜¸'].fillna('').astype(str)
        elif 'ì£¼ë¬¸ë²ˆí˜¸' in df.columns:
            df['ì£¼ë¬¸ê³ ìœ ë²ˆí˜¸'] = df['ì£¼ë¬¸ë²ˆí˜¸'].fillna('').astype(str)
        else:
            df['ì£¼ë¬¸ê³ ìœ ë²ˆí˜¸'] = np.arange(len(df)).astype(str)
        
        return df
    
    def _compile_matching_rules(self):
        """ë§¤ì¹­ ê·œì¹™ ì»´íŒŒì¼"""
        rules = []
        for work_name in self.work_order:
            work_config = self.work_config[work_name]
            if work_config.get('type') != 'product_specific':
                continue
            
            for product in work_config.get('products', []):
                rules.append({
                    'work_name': work_name,
                    'brand': product.get('brand', ''),
                    'product_name': product.get('product_name', ''),
                    'order_option': product.get('order_option', 'All')
                })
        return rules
    
    def _classify_batch(self, df, indices, rules):
        """ë°°ì¹˜ ë¶„ë¥˜"""
        for idx in indices:
            row = df.loc[idx]
            
            for rule in rules:
                if self._match_rule(row, rule):
                    df.at[idx, 'ë‹´ë‹¹ì'] = rule['work_name']
                    df.at[idx, 'ë¶„ë¥˜ê·¼ê±°'] = f"ë§¤ì¹­: {rule['brand']} {rule['product_name']}"
                    df.at[idx, 'ì‹ ë¢°ë„'] = 1.0
                    break
    
    def _match_rule(self, row, rule):
        """ê·œì¹™ ë§¤ì¹­ (ì›ë³¸ ë¡œì§)"""
        # ë¸Œëœë“œ ì²´í¬
        if rule['brand'] and rule['brand'] != 'All':
            if rule['brand'] not in row['brand']:
                return False
        
        # ìƒí’ˆëª… ì²´í¬
        if rule['product_name'] != 'All':
            if rule['product_name'] not in row['ìƒí’ˆëª…']:
                return False
        
        # ì˜µì…˜ ì²´í¬
        if rule['order_option'] != 'All':
            if rule['order_option'] not in row['ì£¼ë¬¸ì„ íƒì‚¬í•­']:
                return False
        
        return True
    
    def _sort_results_optimized(self, df):
        """ê²°ê³¼ ì •ë ¬ - work_order ìˆœì„œ + ê° ë‹´ë‹¹ìë³„ ê°€ë‚˜ë‹¤ìˆœ"""
        priority_map = {name: i for i, name in enumerate(self.work_order)}
        df['priority'] = df['ë‹´ë‹¹ì'].map(priority_map)
        
        combined_work = self._get_combined_work_name()
        
        sorted_groups = []
        for work_name in self.work_order:
            work_df = df[df['ë‹´ë‹¹ì'] == work_name].copy()
            
            if len(work_df) == 0:
                continue
            
            # í•©ë°°ì†¡ì€ ì£¼ë¬¸ë²ˆí˜¸ìˆœ, ë‚˜ë¨¸ì§€ëŠ” ìƒí’ˆëª… ê°€ë‚˜ë‹¤ìˆœ
            if work_name == combined_work:
                work_df = work_df.sort_values(['ì£¼ë¬¸ê³ ìœ ë²ˆí˜¸'])
            else:
                work_df = work_df.sort_values(['full_product_name'])
            
            sorted_groups.append(work_df)
        
        if sorted_groups:
            sorted_df = pd.concat(sorted_groups, ignore_index=True)
            sorted_df = sorted_df.drop(['priority'], axis=1)
        else:
            sorted_df = df
        
        return sorted_df
    
    def calculate_statistics(self, df):
        """í†µê³„ ê³„ì‚° - ë‹´ë‹¹ìë³„ ì£¼ë¬¸ ë²”ìœ„ í¬í•¨ (work_order ìˆœì„œ ìœ ì§€)"""
        total_orders = len(df)
        stats = {
            'workers': [],  # ìˆœì„œ ìœ ì§€ë¥¼ ìœ„í•´ ë°°ì—´ë¡œ ë³€ê²½
            'summary': {}
        }
        
        # ì •ë ¬ëœ df ê¸°ì¤€ìœ¼ë¡œ ê° ë‹´ë‹¹ìë³„ ì‹œì‘/ë í–‰ ë²ˆí˜¸ ê³„ì‚°
        current_row = 1  # ì—‘ì…€ì€ 1ë¶€í„° ì‹œì‘ (í—¤ë” ì œì™¸í•˜ë©´ 2ë¶€í„°ì§€ë§Œ, ì£¼ë¬¸ë²ˆí˜¸ë¡œ í‘œì‹œ)
        
        for work_name in self.work_order:
            work_data = df[df['ë‹´ë‹¹ì'] == work_name]
            count = len(work_data)
            
            config = self.work_config.get(work_name, {})
            icon = config.get('icon', 'ğŸ“‹')
            
            if count > 0:
                start_row = current_row
                end_row = current_row + count - 1
                row_range = f"{start_row} ~ {end_row}"
                current_row = end_row + 1
            else:
                row_range = "-"
            
            # ë°°ì—´ë¡œ ìˆœì„œëŒ€ë¡œ ì¶”ê°€
            stats['workers'].append({
                'name': work_name,
                'count': count,
                'percentage': round(count / total_orders * 100, 1) if total_orders > 0 else 0,
                'icon': icon,
                'range': row_range
            })
        
        failed_work = self._get_failed_work_name()
        unmatched_count = len(df[df['ë‹´ë‹¹ì'] == failed_work])
        success_count = total_orders - unmatched_count
        auto_rate = round(success_count / total_orders * 100, 1) if total_orders > 0 else 0
        
        stats['summary'] = {
            'total_orders': total_orders,
            'success_count': success_count,
            'failed_count': unmatched_count,
            'auto_classification_rate': auto_rate
        }
        
        return stats
    
    def export_to_excel(self, df):
        """ì—‘ì…€ ë‚´ë³´ë‚´ê¸° - í•˜ë‚˜ì˜ ì‹œíŠ¸ë¡œ í†µí•© (work_order ìˆœì„œëŒ€ë¡œ ì •ë ¬ë¨)"""
        output = BytesIO()
        
        # ë‚´ë³´ë‚´ê¸° ì „ì— ì„ì‹œ ì»¬ëŸ¼ ì œê±° (ë‚´ë¶€ìš© ì»¬ëŸ¼ ëª¨ë‘ ì œê±°)
        export_df = df.copy()
        temp_cols = ['full_product_name', 'brand', 'priority', 'ë‹´ë‹¹ì', 'ë¶„ë¥˜ê·¼ê±°', 'ì‹ ë¢°ë„']
        for col in temp_cols:
            if col in export_df.columns:
                export_df = export_df.drop(columns=[col])
        
        # í•˜ë‚˜ì˜ ì‹œíŠ¸ë¡œ í†µí•© ì €ì¥
        export_df.to_excel(output, sheet_name='ë¶„ë¥˜ê²°ê³¼', index=False, engine='openpyxl')
        
        output.seek(0)
        return output
    
    def _get_failed_work_name(self):
        """ë¶„ë¥˜ì‹¤íŒ¨ ë‹´ë‹¹ìëª…"""
        for work_name, config in self.work_config.items():
            if config.get('type') == 'failed':
                return work_name
        return 'ë¶„ë¥˜ì‹¤íŒ¨'
    
    def _get_combined_work_name(self):
        """í•©ë°°ì†¡ ë‹´ë‹¹ìëª…"""
        for work_name, config in self.work_config.items():
            if config.get('type') == 'mixed_products':
                return work_name
        return None
    
    def _get_multiple_work_name(self):
        """ë³µìˆ˜ì£¼ë¬¸ ë‹´ë‹¹ìëª…"""
        for work_name, config in self.work_config.items():
            if config.get('type') == 'multiple_quantity':
                return work_name
        return None


if __name__ == '__main__':
    port = int(os.environ.get('PORT', 5000))
    app.run(host='0.0.0.0', port=port, debug=True)